\documentclass[letterpaper,12pt,peerreviewca,draftcls]{IEEEtran}
\usepackage{csm16}
\usepackage[margin=1in]{geometry}
\usepackage[nolists,nomarkers,tablesfirst]{endfloat} % put figures at end
\usepackage{amsmath} % for \eqref
\usepackage{mathtools}

% added for CSMAG only
\usepackage{url}
\usepackage{graphicx,xcolor}
\usepackage{verbatim}% http://ctan.org/pkg/verbatim
\makeatletter
\newcommand{\verbatimfont}[1]{\def\verbatim@font{#1}}%
\makeatother
\verbatimfont{\ttfamily\small}
\newcommand{\XX}[1]{{\bf XX #1 XX}}
\newcommand{\bi}{\begin{itemize}}\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{equation}}\newcommand{\ee}{\end{equation}}
\newcommand{\bee}{\begin{enumerate}}\newcommand{\eee}{\end{enumerate}}
\newcommand{\bea}{\begin{eqnarray}}\newcommand{\eea}{\end{eqnarray}}
\newcommand{\beas}{\begin{eqnarray*}}\newcommand{\eeas}{\end{eqnarray*}}
\newcommand{\bc}{\begin{center}}\newcommand{\ec}{\end{center}}
%
\usepackage[left,pagewise]{lineno} 
\usepackage[english]{babel} 
\usepackage{blindtext}
% added for CSMAG only

\usepackage{amssymb,amsmath,bm,booktabs}%,amsthm}
\usepackage[sort,compress]{cite}
\usepackage{algorithm}
\usepackage{algorithmic}


\usepackage{eqparbox}
\renewcommand\algorithmiccomment[1]{%
  \hfill\#\ \eqparbox{COMMENT}{#1}%
}

\usepackage{etoolbox}  % patch def of algorithmic environment
\makeatletter
\patchcmd{\algorithmic}{\addtolength{\ALC@tlm}{\leftmargin} }{\addtolength{\ALC@tlm}{\leftmargin}}{}{}
\makeatother
 \usepackage{tikz}
 \usepackage{tikz-qtree}
 \usetikzlibrary{decorations.pathreplacing,calc}
 \usetikzlibrary{arrows}
 \usetikzlibrary{positioning}
 \usetikzlibrary{matrix}

 % tikz macros for scaling etc. 
 \newcommand{\yslant}{0}
 \newcommand{\xslant}{0}
 \newcommand{\diagscale}{0.35}
 \newcommand{\diagtexttop}{0.51}
 \newcommand{\diagtext}{0.45}

 
 \newcommand*{\AddNote}[4]{%
     \begin{tikzpicture}[overlay, remember picture]
         \draw [decoration={brace,amplitude=0.5em},decorate,ultra thick,red]
             ($(#3)!(#1.north)!($(#3)-(0,1)$)$) --  
             ($(#3)!(#2.south)!($(#3)-(0,1)$)$)
                 node [align=center, text width=2.5cm, pos=0.5, anchor=west] {#4};
     \end{tikzpicture}
 }%
 

 \usetikzlibrary{automata}
 \usetikzlibrary{arrows,snakes,backgrounds}
 \tikzstyle{ball} = [circle,shading=ball, ball color=black!80!white,
     minimum size=1cm]
 \tikzstyle{ball2} = [circle,shading=ball, ball color=red!80!white,
     minimum size=1cm]
 \tikzstyle{ball3} = [circle,shading=ball, ball color=blue!80!white,
     minimum size=1cm]
 \tikzstyle{ball4} = [circle,shading=ball, ball color=green!100!white,
     minimum size=1cm]
 \tikzstyle{ball5} = [circle,shading=ball, ball color=purple!80!white,
     minimum size=1cm]       
     
%\usepackage[hidelinks,pdftex]{hyperref}
\usepackage[pdftex, plainpages = false, colorlinks=true, linkcolor=black, citecolor = green!50!blue, urlcolor = blue, filecolor=black, pagebackref=false, hypertexnames=false,  pdfpagelabels ]{hyperref}

\usepackage[capitalise]{cleveref}
\crefname{equation}{}{}

\usepackage[normalem]{ulem}

\newcounter{JPH}

\newcounter{sidebartheorem}
\newenvironment{sidebartheorem}[1][]{\refstepcounter{sidebartheorem}\par\medskip \textit{Theorem~S\thesidebartheorem} #1:\rmfamily}{\medskip}
\newcommand{\sidebarref}[1]{S\ref{#1}}


\usepackage[nolists,tablesfirst,nomarkers]{endfloat}

%\captionsetup[subfigure]{aboveskip=-4pt}
 
 
 
 
\title{Evolving Gaussian Processes and Kernel Observers for Learning and Control in Spatiotemporally Varying Domains\\\Large with applications in agriculture, weather monitoring, and fluid dynamics}
\author{Joshua E. Whitman, Harshal Maske, Hassan A. Kingravi, Girish Chowdhary, \\ POC email: girishc@illinois.edu}


\graphicspath{{figures/}}








%\input{inc_macros}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newif\ifPDF \ifx\pdfoutput\undefined \PDFfalse \else \ifnum \pdfoutput > 0 \PDFtrue \else\PDFfalse \fi \fi

%\newcommand{\qed}{\nobreak \ifvmode \relax \else
%      \ifdim\lastskip<1.5em \hskip-\lastskip
%      \hskip1.5em plus0em minus0.05em \fi \nobreak
%      \vrule height0.25em width0.5em depth0.25em\fi}

%\usepackage[usenames]{color}
\usepackage[normalem]{ulem}
\newcommand{\gXX}[1]{\color{red} XX #1 XX \color{black}}
\newcommand{\hXX}[1]{\color{green} XX #1 XX \color{black}}
\newcommand{\gcmargin}[2]{{\color{red}#1}\marginpar{\color{red}\tiny\raggedright \bf [GC] #2}}
\newcommand{\hkmargin}[2]{{\color{red}#1}\marginpar{\color{green}\tiny\raggedright \bf [HK] #2}}
\newcommand{\gsec}[1]{\fcolorbox{DarkRed}{DarkRed}{\parbox{3in}{\raggedright \color{green} #1 }}}
\newcommand{\gsout}[2]{{\sout{#1}}{{\gXX{#2}}}}



\newcommand{\nn}{{\nonumber}}
\newcommand{\motiv}{{\bf Why, How, Who cares?}}
\newcommand{\mean}{{\bf E}}
\newcommand{\meanw}{{\bf E}_w}
\newcommand{\boldp}{\bf P}
\newcommand{\boldsp}{\bf p}
\newcommand{\cov}{{\bf \Sigma}}
\newcommand{\maxmu}{{\max_\mu}}
\newcommand{\maxtmu}{{\max_{\tilde{\mu}}}}
\newcommand{\tmu}{\tilde{\mu}}
\newcommand{\hmu}{\hat{\mu}}
\newcommand{\mui}{\mu^i}
\newcommand{\mukki}{\mu^i_{k|k}}
\newcommand{\mukkj}{\mu^j_{k|k}}
\newcommand{\mukpki}{\mu^i_{k+1|k}}
\newcommand{\mukpkpi}{\mu^i_{k+1|k+1}}
\newcommand{\x}{\mathcal{X}}
\newcommand{\iso}{\boldsymbol{1_s}}
\newcommand{\dd}{\boldsymbol{1_{di}}}

\newcommand{\tPi}{\tilde{\Pi}}
\newcommand{\tpi}{\tilde{\pi}}
\newcommand{\tLambda}{\tilde{\Lambda}}
\newcommand{\hatxk}{\hat{x}_{k|k}}
\newcommand{\hatxkk}{\hat{x}_{k+1|k+1}}
\newcommand{\hatxkki}{\hat{x}_{k+1|k+1}^i}
\newcommand{\hatxki}{\hat{x}_{k|k}^i}
\newcommand{\Pk}{P_{k|k}}
\newcommand{\Pkk}{P_{k+1|k+1}}
\newcommand{\Pki}{P_{k|k}^i}
\newcommand{\Pkki}{P_{k+1|k+1}^i}

\newcommand{\matlabpathrmmmeas}{C:/MATLAB7/work/UMC/RobustMM/UAV_TrackingMM/MeasurementUpdate}
\newcommand{\matlabpathrmmd}{C:/MATLAB7/work/UMC/RobustMM/UAV_TrackingMM/Version1}
\newcommand{\matlabpathrmmvv}{C:/MATLAB7/work/UMC/RobustMM/UAV_TrackingMM/Version4}
\newcommand{\matlabpathrmm}{C:/MATLAB7/work/UMC/RobustMM/UAV_TrackingMM/Version3}
\newcommand{\matlabpathrmmtwod}{C:/MATLAB7/work/UMC/RobustMM/UAV_TrackingMM/Version3/Figs/}
\newcommand{\matlabpathrmmprob}{C:/MATLAB7/work/UMC/RobustMM/ProblemViz}
\newcommand{\robmmpath}{C:/Documents and Settings/Luca F. Bertuccelli/My Documents/Research/UncertainMarkovChain/RobustMM/}
\usepackage{multirow}
\newtheorem{theorem}{Theorem}%[section]
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}

% matrix
\newcommand{\bbm}{\begin{bmatrix}}
\newcommand{\ebm}{\end{bmatrix}}

% itemize
%\newcommand{\bi}{\begin{itemize}}
%\newcommand{\ei}{\end{itemize}}

% enumerate
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}

% equationarray
%\newcommand{\bea}{\begin{eqnarray}}
%\newcommand{\eea}{\end{eqnarray}}

% equation
%\newcommand{\be}{\begin{equation}}
%\newcommand{\ee}{\end{equation}}
\newcommand{\bes}{\begin{eqnarray*}}
\newcommand{\ees}{\end{eqnarray*}}

% indent
\newcommand{\nid}{\noindent}

% figure
\newcommand{\bfig}{\begin{figure}}
\newcommand{\efig}{\end{figure}}

% center
%\newcommand{\bc}{\begin{center}}
%\newcommand{\ec}{\end{center}}

% bullet
\newcommand{\nb}{\noindent $\bullet$\hspace{1.5mm}}

% ignore
\newcommand{\ignore}[1]{}

% spaces
\newcommand{\hs}[1]{\hspace{#1mm}}
\newcommand{\vs}[1]{\vspace{#1mm}}

% lists / enumerations
\newcommand{\beni}[2]
{\begin{enumerate}\setlength{\itemsep}{#1mm}\setlength{\parskip}{#2mm}}

\newcommand{\bii}[2]
{\begin{itemize}\setlength{\itemsep}{#1mm}\setlength{\parskip}{#2mm}}


\newcommand{\al}{\alpha}
%\newcommand{\be}{\beta}
\newcommand{\e}{\epsilon}
\newcommand{\la}{\lambda}
\newcommand{\s}{\sigma}
\newcommand{\p}{\partial}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\LI}{\mathcal{L}}
\newcommand{\Co}{\mathcal{C}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\K}{\mathbf{K}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\Be}{\mathbf{\beta}}
\newcommand{\y}{\mathbf{y}}
\DeclareMathOperator{\GP}{GP}
\newcommand{\BV}{\mathcal{BV}}
\newcommand{\Hi}{\mathcal{H}}
\newcommand{\No}{\mathcal{N}}
\newcommand{\V}{\mathbb V}
\newcommand{\La}{\mathcal{L}}


%\def\i{\infty}
\def\l{\langle}
\def\v{\varphi}
\def\r{\rangle}
\def\m{\mathbf}
\def\H{\mathcal{H}}
\def\O{\mathcal{O}}
\def\P{\mathbb{P}}
\def\Ny{ Nystr\"{o}m }

% define paper-specific macros

% Hilbert space/basis function macros
\newcommand{\bfunc}{\phi}
\newcommand{\bvect}{\Phi}
\newcommand{\uncertainty}{\Delta}
\newcommand{\weight}{w}
\newcommand{\estweight}{\widehat{w}}
\newcommand{\idweight}{{W^{*}}}
\newcommand{\fweight}{\mathbf{W^*}}
\newcommand{\fspace}{\mathcal{H}}
\newcommand{\dspace}{\mathcal{H}^*}
\newcommand{\fmap}{\psi}
\newcommand{\fdim}{M}
\newcommand{\fevec}{\mathbf{\xi}}
\newcommand{\fefunc}{\mathbf{\phi}}
\newcommand{\feval}{\mathbf{\lambda}}
\newcommand{\fsol}{\mathbf{\varphi}}
\newcommand{\fvect}{\Psi}
\newcommand{\proj}{\gamma}
\newcommand{\sysop}{\mathcal{A}}
\newcommand{\estsysop}{\widehat{A}}
\newcommand{\controlop}{\mathcal{B}}
\newcommand{\measop}{\mathcal{K}}
\newcommand{\estmeasop}{K}
\newcommand{\sloc}{S}
\newcommand{\centers}{C}
\newcommand{\centerscontrol}{D}
\newcommand{\weights}{{w}}

% dynamical system macros
\newcommand{\state}{x}
\newcommand{\astate}{z}
\newcommand{\aastate}{z}%in time varying this should be \bar {z}
\newcommand{\statesize}{n_s}
\newcommand{\isize}{n}
\newcommand{\sdomain}{D_x}
\newcommand{\tdomain}{D_{\tau}}
\newcommand{\tvarsig}{\tau}
\newcommand{\tsize}{m}
\newcommand{\sdefunc}{F}
\newcommand{\sysfunc}{f}
\newcommand{\control}{\delta}
\newcommand{\cdomain}{D_{\delta}}
\newcommand{\csize}{l}
\newcommand{\pcontrol}{\nu}
\newcommand{\asysfunc}{\hat{f}}
\newcommand{\terror}{e}
\newcommand{\reference}{r}
\newcommand{\rstate}{x_{rm}}
\newcommand{\lyap}{V}
\newcommand{\nneval}{\varsigma}
\newcommand{\adElement}{\nu_{ad}}
\newcommand{\measnoise}{\zeta}
\newcommand{\processnoise}{\eta}


% Gaussian process macros
\newcommand{\kernel}{k}
\newcommand{\kernelvec}{\mathbf{k}}
\newcommand{\estKernel}{\hat{k}}
\newcommand{\evalKernel}{k^*}
\newcommand{\kernelM}{K}
\newcommand{\estKernelM}{\hat{K}}
\newcommand{\meas}{y}
\newcommand{\estmeas}{\widehat{y}}
\newcommand{\imean}{m}
\newcommand{\pVar}{\Sigma}
\newcommand{\Covar}{C}
\newcommand{\estMean}{\hat{m}}
\newcommand{\estPVar}{\hat{\Sigma}}
\newcommand{\switchiMean}{m^{\sigma}}
\newcommand{\switchMean}{\hat{m}^{\sigma}}
\newcommand{\errMean}{\epsilon_m}
\newcommand{\switchErrMean}{\epsilon_m^{\sigma}}
\newcommand{\bstack}{Z}
\newcommand{\zstackT}{Z_\tau}
\newcommand{\Tdisc}{\tau}
\newcommand{\etasup}{\eta_{\mathrm{sup}}}
\newcommand{\stateideal}{\bar{x}}
\newcommand{\nuavail}{\nu_{\mathrm{avail}}}
% miscellaneous macros
\newcommand{\switch}{\sigma}
\newcommand{\Index}{\mathcal{I}}

% integral operator and density macros
\newcommand{\idealP}{\ensuremath{{p}}}
\newcommand{\idealK}{\ensuremath{{\m{K}}}}
\newcommand{\eval}{\la}
\newcommand{\efunc}{\ensuremath{\phi}}
\newcommand{\empEfunc}{\ensuremath{\widehat \phi}}
\newcommand{\empEval}{\ensuremath{\widehat \la}}
\newcommand{\delP}{\ensuremath{{p_{\delta}}}}
\newcommand{\delEmpP}{\ensuremath{\widehat p_{\delta}}}
\newcommand{\empP}{\ensuremath{\widehat p}}
\newcommand{\shP}{\ensuremath{\widetilde p}}
\newcommand{\kMax}{\ensuremath{\kappa}}
\newcommand{\probMeas}{\ensuremath{\mu}}

% matrix and vector macros
\newcommand{\empK}{\ensuremath{K}}
\newcommand{\shK}{\ensuremath{\widetilde K}}
\newcommand{\idealshK}{\ensuremath{\widetilde{\m{K}}}}
\newcommand{\shG}{\ensuremath{\widetilde G}}
\newcommand{\CK}{K^{\shCent}}
\newcommand{\quaK}{\ensuremath{\bar{K}}}
\newcommand{\quaC}{\ensuremath{\oline{\mathcal{C}}}}
\newcommand{\evecs}{\ensuremath{U}}
\newcommand{\evalM}{\ensuremath{\Lambda}}
\newcommand{\extrap}{\ensuremath{E}}
\newcommand{\normChoice}{\xi}

\newcommand{\Dist}{\mathcal{D}}
\newcommand{\DDist}{\mathbb{D}}

% dataset and reduced set macros 
\newcommand{\dom}{\Omega}
\newcommand{\domI}{\Omega_I}
\newcommand{\domO}{\Omega_O}
\newcommand{\sampSet}{\mathcal{X}}
\newcommand{\sampSetOther}{\mathcal{Y}}
\newcommand{\sampSetClass}{\mathcal{D}}
\newcommand{\sampSetLong}{\{x_1, \dots, x_{\nsamp}\}}
\newcommand{\sampSetClassLong}{\{(x_1,y_1), \dots, (x_{\nsamp},y_{\nsamp})\}}
\newcommand{\sampSetShort}{\{\astate_i\}_{1}^{\Tdisc}}
\newcommand{\sampSetClassShort}{\{(x_i,y_i)\}_{1}^{\nsamp}}
\newcommand{\card}[1]{\left|{#1}\right|}
\newcommand{\cent}{c}
\newcommand{\nsamp}{N}
\newcommand{\ncent}{M}
\newcommand{\dtime}{\tau}
\newcommand{\ntrain}{n_{t}}
\newcommand{\ntest}{n_{te}}
\newcommand{\neigs}{r}
\newcommand{\shCent}{\mathcal{C}}
\newcommand{\shCentLong}{\{c_1,\dots,c_{\ncent}\}}
\newcommand{\weightSet}{\W}
\newcommand{\weightSetLong}{\{w_1, \dots, w_{\ncent}\}}
\newcommand{\recSet}{\delta X}
\newcommand{\shSet}{S}
\newcommand{\shrad}{\varepsilon}

\newcommand{\G}{\mathcal{G}}
\newcommand{\X}{\mathcal{X}}

\newcommand{\statesizea}{n_1}
\newcommand{\statesizeb}{n_2}
%\newcommand{\statesize2}{n_2}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\HS}{HS}

\newcommand{\eqlabel}[1]{\label{eq:#1}}
\newcommand{\EQref}[1]{Eq.~(\ref{eq:#1})}
\renewcommand{\eqref}[1]{(\ref{eq:#1})}

\newcommand{\EGP}{\text{EGP}}
\newcommand{\swindex}{j}
\newcommand{\RKHS}{RKHS~}

\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\refm}{\mathrm{ref}}
\newcommand{\des}{\mathrm{des}}
\newcommand{\Sa}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\T}{\mathcal{T}}


% dynamical system macros

\newcommand{\controlfunc}{b}

\newcommand{\acontrolfunc}{\hat{b}}

% Gaussian process macros

\newcommand{\fow}{\Upsilon}
\newcommand{\FoW}{FOW~}

\DeclareMathOperator{\vol}{vol}

% % hybrid systems
\newcommand{\cont}{x}
\newcommand{\discrete}{x^+}

\DeclareMathOperator{\Dir}{Dir}
\DeclareMathOperator{\BP}{BP}
\DeclareMathOperator{\BeP}{BeP}

%from Hassan
%\newcommand{\DiscP}{\mathbb{D}}
\newcommand{\parms}{\Theta}
\newcommand{\MN}{\mathcal{MN}}
\newcommand{\err}{\mathbf{e}}
\newcommand{\errCov}{\mathbf{\Sigma}}
\newcommand{\zero}{\mathbf{0}}
\newcommand{\pastData}{\mathcal{W}}
\newcommand{\pastDataL}{\bar{\mathcal{W}}}
\newcommand{\pastBoth}{\mathcal{D}}
\newcommand{\pastErr}{\mathbf{E}}
\newcommand{\postWish}{\mathbf{S}_{w\bar{w}}}
\newcommand{\postWishLL}{\bar{\mathbf{S}}_{\bar{w}\bar{w}}}
\newcommand{\postWishLLI}{\bar{\mathbf{S}}^{-\swindex}_{\bar{w}\bar{w}}}
\newcommand{\postWishL}{\mathbf{S}_{\bar{w}\bar{w}}}
\newcommand{\postWishS}{\mathbf{S}_{w|\bar{w}}}

\def\i{\infty}
\def\l{\langle}
\def\v{\varphi}
\def\r{\rangle}
\def\m{\mathbf}
\def\H{\mathcal{H}}
\def\O{\mathcal{O}}
\def\P{\mathbb{P}}
\def\Na{\mathbb{N}}
\def\Ny{ Nystr\"{o}m }

% define paper-specific macros

% Hilbert space/basis function macros

\newcommand{\nsysop}{\mathcal{G}}

% Gaussian process macros

% dataset and reduced set macros 


% E-GP specific macros
\newcommand{\egpFunc}{f}
\newcommand{\egpDyn}{g}

\newcommand{\EGPFspace}{\mathbb{H}}
\newcommand{\EGPSample}{\mathbb{F}}
\newcommand{\EGPFspaces}{\coprod_{j=1}^{\infty}\fspace^j}



% VV Stuff
\newcommand{\Kr}{\m{K}}
\newcommand{\f}{\m{f}}
%\newcommand{\I}{\m{I}}


\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\MMD}{MMD}
\DeclareMathOperator{\divergence}{div}
\DeclareMathOperator{\Span}{span}
%\DeclareMathOperator{\span}{span}
\DeclareMathOperator{\Rank}{rank}
\DeclareMathOperator{\Pro}{\mathbb{P}}
\DeclareMathOperator*{\argmax}{arg\,max}

%\newcommand{\statesize2}{n_2}


\DeclareMathOperator{\DiscP}{Disc}
\DeclareMathOperator{\IW}{IW}
\DeclareMathOperator{\Tr}{Tr}


%\renewcommand{\eqref}[1]{(\ref{eq:#1})}

\newcommand{\NMBRL}{N-MBRL}


% new macros
\newcommand{\dimI}{\ensuremath{D}}
\newcommand{\dimO}{\ensuremath{d}}
\newcommand{\dimP}{\ensuremath{P}}
\newcommand{\sO}{\mathcal{S}}
\newcommand{\risk}{\mathop{\mathbf{R}}}
\newcommand{\empRisk}{\mathop{\widehat{\mathbf{R}}}}
\newcommand{\radCom}{{\mathcal{R}}}
\newcommand{\funcClass}[1]{\mathcal{F}_{#1}}
\newcommand{\empFuncClass}[1]{\widehat{\mathcal{F}}_{#1}}
\newcommand{\oweights}{\ensuremath{\alpha}}
\newcommand{\loss}{\ell}

% newer macros
\newcommand{\Obs}{\mathcal{O}}
\newcommand{\otime}{L}
\newcommand{\JorMul}{O}
\newcommand{\Tset}{\Upsilon}
\newcommand{\measmat}{\Phi}
\newcommand{\enrgy}{\gamma}
\newcommand{\eenrgy}{\lambda}
\newcommand{\blockmat}{\boldsymbol\Phi}
\newcommand{\modker}{\widehat\kernel}
\newcommand{\centker}{\widetilde\kernel}
\newcommand{\Dim}{D}
\newcommand{\Ind}{\mathcal{I}}
\newcommand{\LaVec}{\boldsymbol{\la}}
\newcommand{\LaMat}{\boldsymbol{\Lambda}}
\newcommand{\JorP}{P}
\newcommand{\JorLa}{\Lambda}
\newcommand{\empKDiag}{\mathbf{K}^D}
%\newcommand{\empKMod}{\widetilde{\empK}} %repeated twice
\newcommand{\empKBlock}{\widehat{\mathbf{K}}} % now catempK
%\newcommand{\ABlock}{\widehat{\mathbf{A}}} %now defined as \catdualopC
\newcommand{\Coh}{\mathcal{C}}

% feature map macros
\newcommand{\fspaceC}{\ensuremath{\mathcal{H}^{\mathcal{C}}}}
\newcommand{\fspaceD}{\ensuremath{\widetilde{\fspace}}}
\newcommand{\functionSet}{\mathcal{J}}
\newcommand{\AtomsControl}{\mathcal{F}_{\centerscontrol}}
\newcommand{\fspaceApprox}{\widehat{\fspace}}
\newcommand{\fsubspaceApprox}[1]{\fspaceApprox_{#1}}
\newcommand{\fmapApprox}{\widehat{\fmap}}
\newcommand{\fbasis}{\psi}
\newcommand{\fspaceEl}{f}
\newcommand{\fspaceApproxEl}{\widehat{\fspaceEl}}
\newcommand{\obsMat}{\empK}
\newcommand{\randFreq}{\omega}
\newcommand{\randMat}{V}
\newcommand{\obsMatRow}{\widehat{\Psi}}
\newcommand{\Kiprod}[2]{\langle \fmap(#1),\fmap(#2) \rangle_{\fspace}}
\newcommand{\Atoms}{\mathcal{F}^{\shCent}}

% controls specific stuff
\newcommand{\weightmap}{\ensuremath{\mathcal{W}}}
\newcommand{\weightmapI}{\ensuremath{\mathcal{W}^{-1}}}
\newcommand{\weightmapC}{\ensuremath{\acute{\mathcal{W}}}}
\newcommand{\weightmapCI}{\ensuremath{\acute{\mathcal{W}}^{-1}}}
\newcommand{\data}{X}
\newcommand{\ncontrol}{\ell'}
\newcommand{\weightc}{\acute{\weight}}
\newcommand{\empKD}{\empK_{\centerscontrol}}
\newcommand{\empKCD}{\empK_{\centers\centerscontrol}}
\newcommand{\ControlMat}{\Psi}
\newcommand{\controlCent}{\mathcal{D}}
\newcommand{\controlCentLong}{\{d_1,\dots,d_{\ncontrol}\}}
\newcommand{\cbasis}{\widetilde{\psi}}

% minimal polynomial and measurement map etc
\newcommand{\charpoly}{\pi}
\newcommand{\minpoly}{\alpha}
\newcommand{\minpolyv}{\xi}
\newcommand{\geomMult}[1]{\gamma_{#1}}
\newcommand{\algMult}[1]{\mu_{#1}}
\newcommand{\genMult}[1]{\nu_{#1}}
\newcommand{\rank}{r}
\newcommand{\nevals}{r}
\newcommand{\linvec}{v}
\newcommand{\polycoeff}{a}
\newcommand{\acycdeg}{m}
\newcommand{\minmeas}{\ell}
\newcommand{\linspace}{\mathcal{V}}
\newcommand{\linspaceout}{\mathcal{U}}
\newcommand{\subspace}{\linspace_{\mathcal{S}}}
\newcommand{\measmap}{\widetilde{\empK}}
\newcommand{\premeasmap}{\mathring{\empK}}
\newcommand{\measmapsum}{\check{\empK}}
\newcommand{\mmapInd}[1]{\mathcal{J}^{({#1})}}
\newcommand{\restrict}[2]{{#1}_{|#2}}
\newcommand{\fsubspaceC}[1]{\fspaceApprox_{#1}}
\newcommand{\initcondf}{\widetilde{f}}
\newcommand{\initcond}{\weight_0}
\newcommand{\sysopC}{\sysop_{\shCent}}
\newcommand{\sysopApprox}{\widehat{\sysop}}
\newcommand{\dualop}{A}
\newcommand{\dualopC}{A_{\shCent}}
\newcommand{\dualopApprox}{\widehat{\dualop}}
\newcommand{\empKShadFull}{\mathbf{\empK}}

\newcommand{\sampind}{i}
\newcommand{\centind}{j}
\newcommand{\setind}{\iota}

% kernel observer transition macros
\newcommand{\tindex}{\tau}
\newcommand{\ftime}{T}
\newcommand{\orbit}{\boldsymbol{\Theta}}
\newcommand{\banachspace}{\mathcal{B}}
\newcommand{\banachop}{\mathcal{L}}
\newcommand{\banachfunc}{u}
\newcommand{\rands}{\varsigma}

\DeclareMathOperator{\dims}{dim}
\DeclareMathOperator{\degs}{deg}
\DeclareMathOperator{\Ker}{Ker}

%Borrowed from CDC
\newcommand{\evalvec}{\boldsymbol{\eval}}
% supplementary macros
\newcommand{\transempK}{\breve{\empK}}
\newcommand{\catempK}{\widehat{\mathbf{K}}}
\newcommand{\catdualopC}{\widehat{\mathbf{A}}}
\newcommand{\catJorP}{\boldsymbol{\JorP}}
\newcommand{\catJorLa}{\boldsymbol{\JorLa}}
\newcommand{\estdualopC}{\widehat{A}_{\shCent}}
\newcommand{\estcontrolop}{\widehat{B}}

% decomposition macros
\newcommand{\Fmap}{\Psi}
%\newcommand{\LaMat}{\boldsymbol{\Lambda}}
%\newcommand{\JorP}{P}
%\newcommand{\JorLa}{\Lambda}
\newcommand{\FrobP}{Q}
\newcommand{\FrobC}{C}
\newcommand{\subsetC}[1]{\mathcal{S}^{(#1)}}
%\newcommand{\Atoms}{\Fmap}
\newcommand{\atomSubset}[1]{\Fmap^{(#1)}}
\newcommand{\centerSubset}[1]{\shCent^{(#1)}}

% more macros for proofs
\newcommand{\zerosMat}[2]{\mathbf{0}_{\R^{#1\times#2}}}
\newcommand{\zerosK}{\zerosMat{\nsamp}{\ncent}}
\newcommand{\zerosU}{\zerosMat{\nsamp}{\nsamp}}
\newcommand{\bdU}{\mathcal{U}}

% sensor placement macro
\newcommand{\entireSet}{\mathcal{V}}
\newcommand{\xset}{X}
\newcommand{\sensub}{\mathcal{A}}
\newcommand{\sensubh}{\bar{\sensub}}
\newcommand{\xdomvec}{\bf x}
\newcommand{\ydomvec}{\bf y}
\newcommand{\wvec}{\bm w}
\newcommand{\fest}{\hat{f}_\tindex}
\newcommand{\measure}{\nu}
\newcommand{\meanDist}{\mu}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%









\begin{document}
\maketitle
\CSMsetup
\linenumbers \modulolinenumbers[5] % added for CSMAG only




%\input{sec_introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction} \label{sec:intro}
Monitoring and modeling of large-scale stochastic phenomena with both spatial and temporal (spatiotemporal) evolution using a network of distributed sensors is a critical problem in many controls applications. Consider, for example, a team of robots with the task of destroying herbicide-resistant weeds on a farm (see Figure \ref{fig:cps}, also see ``\nameref{sb:ag}''). This team of robots needs to predict weed growth across the whole farm  to make intelligent, coordinated decisions \cite{McAllistar18IROS}. However, the robots can only observe a limited part of the field at a time, leading to the critical problem: How can a few robots which can only partially observe the field at any time predict the full state of the spatiotemporally-evolving weed growth over the entire field? When building an observer over a spatiotemporal process, which locations should be sampled to obtain the necessary information to render the problem observable? The goal of this tutorial is to show the steps we have taken towards addressing this kind of challenging problem. Examples of such problems abound across many domains, including: modeling and monitoring of ocean heat content and acidification for oceanography using a network of satellites and surface sensors \cite{barnett2001detection}; prediction of traffic patterns using data from vehicles, cellphones, and traffic cameras; prediction of enemy movements through ground and aerial surveillance; and prediction of extreme weather events using data from weather stations and aerial drones \cite{heaton2011spatio}. The rapid advances in the computational power of compact systems and robotics as a whole has led to an explosion of real-world applications for such distributed cyber-physical systems. 
 
\begin{figure}[h] %{r}{0.5\textwidth}
	\centering
	\includegraphics[width=\columnwidth]{"Figure 1"}
		\caption{A Cyber Physical system consisting of a distributed team of robots for mechanical weed management on a farm. Image courtesy EarthSense inc.}
	\label{fig:cps}
\end{figure}


These types of applications need to estimate complex, stochastic dynamics that are distributed over space and time. The key constraint is the number of spatially distributed sensors available, which are not enough to entirely cover the whole space at any given moment in time. One approach to solving the problem under this constraint is to use a predictive model of the phenomenon which informs our sensing strategy. %It may be difficult to model such systems with spatiotemporal dynamics using first principles alone. 
While the modeling of such spatiotemporal phenomena has traditionally been the object of study in geostatistics, it has in recent years gained more attention in the machine learning community \cite{cressie2011statistics}. The data-driven models developed by machine learning techniques provide a way to capture complex spatiotemporal phenomena which are not easily modeled by first-principles alone. However, these models are limited by the data sets they are trained on, and the high variability of complex distributed physical systems makes it even more challenging. For example, a model trained over years of weed growth data in one field doesn't necessarily generalize to another, and a model trained on the past few years of data still cannot reliably predict weather variability in the following year. What is needed is not just a \textit{predict} system but a \textit{predict-and-correct} system. This tutorial shows how to design just such a system for these kind of problems. The system utilizes kernel methods for modeling, Bayesian filtering theory for prediction correction, and exploits the mathematical structure of the regression and dynamics models to place the sensors. 


In the machine learning community, kernel methods represent a class of well-studied and powerful methods for regression in spatial domains. In these techniques, correlations between the input variables are related via covariance kernels, and the model is generated by a linear combination of the kernels \cite{RasmussenWilliams2005,schoelkopf01kernelbased,scholkopf2002learning}. In recent years, kernel methods have been applied to spatiotemporal regression problems with varying degrees of success \cite{cressie2011statistics,RasmussenWilliams2005}. Many recent methods have focused on nonstationary covariance kernel design and algorithms for learning the associated hyperparameters \cite{garg2012AAAI,ma2003nonstationary,plagemann2008nonstationary,todescato2017efficient}. These methods, which focus on the careful design of covariance kernels, have been proposed as an alternative to the naive approach of simply including time as an additional input dimension in the kernel \cite{Chowdhary13_CDC1}. The careful design/optimization of a covariance kernel avoids an explosion in the number of parameters used by the model, which would be inevitable in the naive approach, and can better account for spatiotemporal couplings. Such covariance kernels, however, do not scale in the face of large-scale phenomena since the optimization of the kernel hyperparameters is non-convex and computationally demanding for large datasets \cite{sra2012optimization}. Deep learning also suffers from similar issues, and moreover lacks the spatial encoding properties of certain kernels, which are exploited by the strategy outlined in this tutorial.

No matter how much data the model is trained on, it cannot completely capture the variability of real-world systems with complex spatiotemporal dynamics. This is a problem that the controls community is quite aware of; their solution to this is built upon feedback, leading to fundamental notions of observability and controllability which can be used to build robust state estimators and controllers. To bring these ideas to fruition in the spatiotemporal problem, we needed a way to find where sensing/control should be performed to ensure that the state estimation problem can be made observable/controllable. % Current ML models do not provide such insight. In particular, 
%\rr{
While methods such as \cite{todescato2017efficient} have succeeded in using nonstationary kernels that evolve efficiently using feedback, it is not clear how notions of observability and controllability could be utilized with it or other existing kernel-based machine learning models, and how observers and controllers can be embedded within such models.
%} % for the large scale spatiotemporal phenoemena. }
Computational challenges can be addressed with faster methods or increasing computational power; however, addressing the latter, more fundamental challenge in designing robust observers/controllers is particularly important in the design of reliable engineering systems, such as distributed sensor/actuator networks intended for monitoring physical phenomena, autonomous soft-robots, or other physical systems with distributed sensing and actuation.


\subsection{Contributions}
In this tutorial, we present a different perspective on solving the spatiotemporal monitoring problem that brings together kernel-based modeling, systems theory, and Bayesian filtering. We define the monitoring problem as follows: \textit{given an approximate predictive model of the spatiotemporal phenomena learned using historical data, estimate the current latent state of the phenomena in the presence of uncertainty, using as few sensors as possible}. Ideally, the solution to the problem should also provide guidance on how many sensors are needed and where to place them. In this paper we argue that when it comes to predictive inference over spatiotemporal phenomena, a Kalman-filter type approach of predicting and correcting with feedback from a set of minimal sensors is a robust way of dealing with real-world uncertainties and inherent modeling errors.  In the context of this specific problem, our main contributions are two-fold: first, we demonstrate that spatiotemporal functional evolution can be modeled using stationary kernels with a linear dynamical systems layer on their mixing weights. In particular, in contrast with existing work, this approach does not necessarily require the design of complex spatiotemporal kernels, and can accommodate positive-definite kernels on any domain on which it is possible to define them, which includes non-Euclidean domains such as Riemannian manifolds, strings, graphs and images \cite{Jayasumana_PAMI2015_RBFs}. Second, we show that such a model can be utilized to determine sensing locations that guarantee that the hidden states of functional evolution can be estimated using a Bayesian state-estimator (Kalman filter) that is embedded in the feature space of the kernel model with very few sensors. A benefit of our solution's approach is that it provides guidance on how many sensors are needed and where to place them. Accordingly, we provide sufficient conditions on the number and location of sensor measurements required and prove non-conservative lower bounds on the minimum number of sampling locations by developing fundamental results on the observability of kernel-based models. Our model is also analyzed in terms of Koopman operator theory, and several key theoretical results are proven showing that our model can produce the Koopman modes, eigenvalues, and eigenfunctions. 
The validity of the presented model and sensing techniques is corroborated using synthetic and large real datasets. 

\subsubsection*{Broader Context}
The fundamental idea of building observers and controllers embedded in the feature spaces of machine learning models introduced in this paper is generalizable beyond the particular application of spatiotemporal monitoring. Figure \ref{fig:cps_soa} shows a general landscape of problems that are relevant for engineering. Since the controls literature is strongest when the system dynamics can be represented as Ordinary Differential Equations (ODEs), some of the major successes of controls have included results such as Linear Quadratic Gaussian control, reinforcement learning, and adaptive control in state spaces with well-defined, finite, and \emph{physically meaningful} state variables. The estimation of the states of these temporally evolving, finite-dimensional state-space systems have been extensively studied in the context of Kalman filtering and observer design \cite{Gelb74}. A different approach for modeling complex spatiotemporal dynamical systems comes from machine learning, where trained models reside in abstract feature spaces that are only relatable to physical quantities through complex functional operations (see ``\nameref{sb:featspace}''). There has been some work that relates approaches from controls to machine learning (see e.g. \cite{mardia1998kriged} for an extension of the Kalman filter to the functional domain), but the results are not studied in the context of the spatiotemporal monitoring problem presented here. 

To fuse machine learning with controls for building robust systems for engineering, we need to answer fundamental questions such as 1) the least number of sensors required to observe a distributed system, 2) the placement of sensors/actuators to guarantee observability/controllability of the system, and 3) the effect of random sensor placement on system observability/controllability.

This tutorial presents an approach that can provide one formal way of addressing these and other questions about complex systems that are modeled with machine learning. In particular, we demonstrate how linear dynamical systems can be embedded in the reproducing kernel Hilbert space (RKHS) \cite{schoelkopf01kernelbased,ams:cucker,kingravi2012reproducing} generated by features used in Gaussian Process modeling \cite{Liu2018csmtutorial,rasmussen2006gaussian}, %machine learning feature spaces 
and utilized to answer fundamental questions such as controllability and observability. 
% The marriage of systems theory with machine learning pursued in this paper is exciting, and % because it can provide a formal way of answering fundamental questions about complex systems, such as: % and seek to develop machine learning models that can be utilized to answer questions such as: 
We expect that follow-up work will exploit the framework presented in this paper of utilizing linear models in RKHSs and feature spaces of other machine learning models to enable practical and analyzable data-driven engineering systems. To facilitate the development of the theory, we have focused this paper on the problem of monitoring spatiotemporal phenomena. However, the idea should be generalizable to any distributed cyber-physical system that is changing with space and time. 

\begin{figure}[h] %{r}{0.5\textwidth}
	\centering
	\includegraphics[width=\columnwidth]{"Figure 2"}
		\caption{Modeling, monitoring, and controlling dynamical systems with complex and uncertain dynamics, such as agricultural, traffic, or weather monitoring systems, presents exciting open challenge for the controls community. The bottom left quadrant describes linear and time-invariant systems with single-scale dynamics, for which the theory of feedback control of dynamical systems is often sufficient. The bottom right quadrant shows stochastic single-scaled systems, where approaches such as Kalman Filters and Gaussian optimization have marked several successes of control systems, enabling endeavors from lunar landings to GPS navigation. The top left quadrant denotes systems with dynamics at multiple scales, where the efficient computation of solutions to Partial Differential Equations (PDEs) is an highly active area of research. Fundamental theoretical advances and practical algorithms are needed, however, to enable autonomous decision making for distributed stochastic Cyber Physical Systems with dynamics at multiple scales – shown in the top right quadrant – such as distributed agricultural robotic systems, traffic networks, and weather monitoring systems with mobile and stationary sensors.}
	\label{fig:cps_soa}
\end{figure}


\subsection*{Outline of the article and relationship to prior work by the authors}
 We begin the rest of the article by summarizing some related work in machine learning in this area.  ``\nameref{sb:featspace}'' discusses the concept of feature spaces and its importance in machine learning in a broader context. We then formulate the problem, introduce \emph{Kernel Observers (KO)}, and develop the main theoretical and algorithmic results.
This is followed by some results on the expected number of randomly placed sensors required to monitor a spatiotemporal process in the context of our model. An extension to the KO method called \emph{Evolving Gaussian Processes (E-GP)} is presented that learns one model for multiple, similar spatiotemporal processes, the efficacy of which on real-world CFD data is presented in Sidebar \emph{Learning Fluid Flows with Evolving Gaussian Processes}.
Elements of the work presented in this paper first appeared in Neural Information Processing Systems (NIPS 2016) (\cite{Kingravi16_NIPS,whitman2016NIPSworkshop}), IEEE CDC 2015 conference \cite{Kingravi:2015a}, the Conference on Robot Learning (CoRL 2017) \cite{whitman2017learning} and IEEE ACC 2018 conference \cite{Maske18_ACC}.  This paper presents a comprehensive set of results and fills in the missing links in a single encompassing publication, and introduces new results on observability in the presence of random sensor placement, and connections to Koopman operator theory. As such, we have focused in this article mostly on the fundamental theory and practical algorithms for modeling, estimation, and control, while the details of how to optimally implement the presented algorithms are omitted. Instead, an open-source code-base is made available in MATLAB at \url{http://daslab.illinois.edu/software.html} or at \url{https://github.com/hkingravi/FunctionObservers} and in Python on GitHub at \url{https://github.com/hkingravi/funcobspy}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%








%\input{sec_relatedwork}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Related Work}\label{sec:related}

There is a large amount of literature on Gaussian Processes and spatiotemporal modeling, a complete survey of which is beyond the scope of this paper. Since our contributions are in the area of creating a feedback-based observer in the feature spaces of GP models, we will here discuss  related work in three related areas: spatiotemporal modeling with GPs, the connection of GPs to Kalman filtering, and sensor placement for inference in spatiotemporal domains.
 
The use of process-dependent kernels for spatiotemporal modeling in geostatistics is well-studied \cite{wikle2002kernel,cressie2011statistics,stroud2001dynamic}. Other approaches that utilize hierarchy or evolution of kernels have also been used for modeling spatiotemporal functions \cite{hartikainen2013sequential,lindgren2011explicit,ho1996multiresolution}.
From the machine learning perspective, a naive approach is to utilize both spatial and temporal variables as inputs to a Mercer kernel \cite{perez2013gaussian}. However, this technique leads to an ever-growing kernel dictionary. %, which is computationally taxing.
Furthermore, constraining the dictionary size or utilizing a moving window will occlude learning of long-term patterns. A more clever approach is to use state-space representations of time-varying GPs \cite{sarkka2014convergence,hartikainen2013sequential}. From this viewpoint, each GP instance is viewed as a snapshot of an evolving set of weights. We follow in a similar vein here, with added emphasis on exploiting mathematical structures relevant to observability and controllability. Periodic or nonstationary covariance functions and nonlinear transformations have been proposed for spatiotemporal modeling \cite{ma2003nonstationary,RasmussenWilliams2005}. Work focusing on nonseparable and nonstationary covariance kernels seeks to design kernels optimized for environment-specific dynamics, and to tune their hyperparameters in local regions of the input space. Seminal work in \cite{higdon1998process} proposes a process convolution approach for space-time modeling. This model captures nonstationary structure by allowing the convolution kernel to vary across the input space. This approach can be extended to a class of nonstationary covariance functions, thereby allowing the use of a Gaussian process (GP) framework, as shown in \cite{paciorek2004nonstationary}. However,  since this model's hyperparameters are inferred using MCMC integration, its application has been limited to smaller datasets. To overcome this limitation, \cite{plagemann2008nonstationary} proposes to use the mean estimates of a second isotropic GP (defined over latent length scales) to parameterize the nonstationary covariances. Finally, \cite{garg2012AAAI} considers non-isotropic variation across different dimensions of input space for the second GP as opposed to isotropic variation by \cite{plagemann2008nonstationary}. Issues with this line of approach include the nonconvexity of the hyperparameter optimization problem and the fact that selection of an appropriate nonstationary covariance function for the task at hand is a nontrivial design decision (as noted in \cite{singh2010modeling}). 

Apart from directly modeling the covariance function using additional latent GPs, there exist several other approaches for specifying nonstationary GP models. One approach maps the nonstationary spatial process into a latent space, in which the problem becomes approximately stationary \cite{schmidt2003bayesian}. Along similar lines, \cite{pfingsten2006nonstationary} extends the input space by adding latent variables, which allows the model to capture  nonstationarity in original space. Both these approaches require MCMC sampling for inference, and as such are subject to the limitations mentioned in the preceding paragraph. 
A geostatistics approach that finds dynamical transition models on the linear combination of weights of a parameterized model \cite{cressie2011statistics,mardia1998kriged} is advantageous when the spatial and temporal dynamics are hierarchically separated, leading to a convex learning problem. This approach has been utilized previously in MRI imaging \cite{noh2007testing,noh2012space}. As a result, complex nonstationary kernels are often not necessary (although they can be accommodated). This approach is essentially the starting point of this tutorial. 
A systems-theoretic study of this viewpoint enables our fundamental contributions, which are 1) allowing for inference on more general domains with a larger class of basis functions than those typically considered in the geostatistics community, and 2) quantifying the minimum number of measurements required to estimate the state of the system. 

Kalman filtering in the context of Gaussian processes and kernel models has also been quite widely studied \cite{carron2016machine,hartikainen2010kalman,sarkka2013spatiotemporal,stroud2001dynamic,miller1986toward}.  There is a direct link between the Bayesian approach to inference taken in GPs and its natural extension to Kalman Filters. Our contributions here are in creating explicit connections between feedback observers and inference by deriving conditions on observability in the kernel space. This leads to explicit conditions on the number of sensors required and where to place them. Lastly, sensor placement optimization is also a well-studied area. Examples include, but are not limited to 1) geometric approaches, which seek to provide a covering of the operating space without making assumptions about the spatiotemporal dynamics \cite{egerstedt:bk:2010}, and 2) information-theoretic approaches, which place their focus on sensor placement optimizing strategies based on mutual information and information entropy for Gaussian process models \cite{Guestrin05_ICML}. It should be noted that the contribution of our work concerning sensor placement is to provide \emph{sufficient conditions} for monitoring rather than optimization of the placement locations, and therefore a comparison with these approaches is not considered in the experiments. 

Lastly, we connect our work to the large body of literature produced in the last decade on Koopman operator theory and Dynamic Mode Decomposition, particularly in the Computational Fluid Dynamics (CFD) community. These methods rely on discovering \emph{modes} of motion which show the spatial distribution, oscillation frequency, and growth rate/decay of the component dynamics of the system. Many applications have been realized through these methods, which include the ability to transform the state space so the dynamics appear linear, to predict the temporal evolution of the linear system, to reconstruct the state of the original nonlinear system, and even to implement controller design. Dynamic Mode Decomposition (DMD) is the most widely used method for finding a finite-dimensional subspace of the Koopman operator's infinite-dimensional domain to work in \cite{schmid2010dynamic}. Williams et al., recently integrated DMD with the kernel trick, allowing the algorithm to be extended to systems with much larger dimensions \cite{williams2015kerneldmd}. Brunton et al., inspired by DMD, were able to generate governing equations from data by sparse identification of nonlinear dynamical systems \cite{brunton2016discovering}. However, these methods are restricted to approximating the Koopman operator given a fixed vector-valued observable, and have no way of effectively using measurements that vary in both number and location over time. Furthermore, the state of research into data-driven generalizing over similar systems with varying parameters is at best preliminary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%\input{sec_formulation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.1in}
\section{Kernel Observers}\label{sec:observers}

This section outlines our modeling framework and presents theoretical results associated with the number of sampling locations required for monitoring functional evolution. 

%\input{sec_preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Problem Formulation}\label{sec:formulation}
We focus on predictive inference of a time-varying stochastic process, whose mean $f$ evolves temporally via $f_{\tindex+1} \sim \mathbb{F}(f_{\tindex},\eta_{\tindex})$, where $\mathbb{F}$ is a distribution varying with time $\tindex$ and exogenous inputs $\eta$. Our approach builds on the fact that in several cases, temporal evolution can be hierarchically separated from spatial functional evolution. A classical and quite general example of this is the \emph{abstract evolution equation} (AEO), which can be defined as the evolution of a function $\banachfunc$ embedded in a Banach space $\banachspace$: $\dot{\banachfunc}(t) = \banachop\banachfunc(t)$, subject to $\banachfunc(0)= \banachfunc_0$, and $\banachop:\banachspace\to\banachspace$ determines spatiotemporal transitions of $\banachfunc\in\banachspace$ \cite{brezis2010functional}. This model of spatiotemporal evolution is very general (AEOs, for example, model many PDEs), but working in Banach spaces can be computationally taxing.  A simple way to make the approach computationally feasible is to place restrictions on $\banachspace$: in particular, we restrict the sequence $f_{\tindex}$ to lie in a Reproducing Kernel Hilbert Space (RKHS), the theory of which provides powerful tools for generating flexible classes of functions with relative ease \cite{RasmussenWilliams2005}.
In a kernel-based model, $\kernel:\dom\times\dom\to\R$ is a positive-definite Mercer kernel on a domain $\dom$ that models the covariance between any two points in the input space,  
and implies the existence of a smooth map $\fmap:\dom\to\fspace$, where $\fspace$ is an RKHS with the property $\kernel(x,y) = \Kiprod{x}{y}$. The key insight behind the proposed model is that spatiotemporal evolution in the input domain corresponds to temporal evolution of the mixing weights of a kernel model alone in the functional domain. Therefore, $f_{\tindex}$ can be modeled by tracing the evolution of its mean embedded in a RKHS using switched ordinary differential equations (ODE) when the evolution is continuous, or switched difference equations when it is discrete (Figure \ref{fig:hilbert_evolution}). 
The advantage of this approach is that it allows us to utilize powerful ideas from systems theory for deriving necessary and sufficient conditions for spatiotemporal monitoring. 

\begin{figure}
	\centering
	\includegraphics[width=0.4\columnwidth]{"Figure 3"}
	\caption{Two types of Hilbert space evolutions. Left: discrete switches in RKHS $\fspace$; Right: smooth evolution in $\fspace$.}
	\label{fig:hilbert_evolution}           
\end{figure}\hfill

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\linewidth]{"Figure 4a.pdf"}
		\caption{1-shaded (Def. \ref{def:shaded})} \label{fig:shadeda}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\linewidth]{"Figure 4b.pdf"} 
		\caption{2-shaded (Eq. \eqref{empKShadFull})} \label{fig:shadedb}
	\end{subfigure}
	\caption{Shaded observation matrices for dictionary of atoms. Each row represents a sensing location with the color map indicating the evaluation of kernel function w.r.t the others points in the domain.}
	\label{fig:shaded}
\end{figure}



\begin{figure}[t]
\centering
\begin{subfigure}[t]{0.32\textwidth}
	\includegraphics[width=\linewidth]{"Figure 5a.pdf"}
	\caption{Gaussian}
\end{subfigure}
\begin{subfigure}[t]{0.32\textwidth}
	\includegraphics[width=\linewidth]{"Figure 5b.pdf"}
	\caption{Laplacian}
\end{subfigure}
\begin{subfigure}[t]{0.32\textwidth}
	\includegraphics[width=\linewidth]{"Figure 5c.pdf"}
	\caption{Periodic}
\end{subfigure}
\caption{One-dimensional function evolution over a fixed transition matrix $A$, 
initial condition $\weight_0$ and centers $\shCent$, but with different kernels $\kernel(x,y)$. 
Each $y$-vector at a given value of $x$ represents the output of the function, which evolves from left to right. As seen, changing the kernel creates quite different dynamic behaviors.}
\label{fig:kernel_variation}
\end{figure}


In this paper, we restrict our attention to the class of functional evolutions $\mathbb{F}$ defined by linear Markovian transitions in an RKHS. While extension to the nonlinear case is possible (and non-trivial), it is not pursued in this paper to help ease the exposition of the key ideas. The class of linear transitions in RKHS is rich enough to approximately model many real-world datasets, as suggested by our experiments.

Let $y\in\R^{\nsamp}$ be the measurements of the function available from $\nsamp$ sensors, $\sysop:\fspace\to\fspace$ be a linear transition operator in the RKHS $\fspace$, and $\measop:\fspace\to\R^{\nsamp}$ be a linear measurement operator. The model for the functional evolution and measurement studied in this paper is:
\begin{align}\eqlabel{ideal_lin_evol}
 f_{\tindex+1} = \sysop f_{\tindex} + \eta_{\tindex}, \quad
 y_{\tindex} = \measop_{\tindex} f_{\tindex} + \zeta_{\tindex},
\end{align}
where $\eta_{\tindex}$ is a zero-mean stochastic process in $\fspace$, and $\zeta_{\tindex}$ is a Wiener process in $\R^{\nsamp}$. 
Classical treatments of kernel methods emphasize that for most kernels, the feature map $\fmap$ is unknown, and possibly infinite-dimensional; this forces practioners to work in the dual space of $\fspace$, whose dimensionality is the number of samples in the dataset being modeled. This conventional wisdom precludes the use of kernel methods for most tasks involving modern datasets, which may have millions and sometimes billions of samples \cite{rahimi2007random}. An alternative is to work with a feature map 
$\fmapApprox(x) := \left[\begin{smallmatrix}
  \fmapApprox_1(x) & \cdots & \fmapApprox_{\ncent}(x)
 \end{smallmatrix}\right]^T$ to an approximate feature space
 $\fspaceApprox$ with the property that for every element $\fspaceEl\in\fspace$, $\exists\fspaceApproxEl\in\fspaceApprox$ s.t. $\|\fspaceEl-\fspaceApproxEl\| < \e$ for an appropriate function norm and $\e>0$. A few such approximations are listed below.
 
%\begin{enumerate}
\paragraph{Dictionary of atoms} Let $\dom$ be compact. Given points $\shCent = \shCentLong$, $c_i\in\dom$, we have a dictionary of atoms $\Atoms = \{\fmap(c_1), \cdots , \fmap(c_{\ncent})\}$, $\fmap(c_i)\in\fspace$, the span of which is a strict subspace $\fspaceApprox$ of the RKHS $\fspace$ generated by the kernel. Here, 
 \begin{equation}\eqlabel{fmap_dict}
 \fmapApprox_i(x) := \l\fmap(x), \fmap(c_i)\r_{\fspace} = \kernel(x, c_i).
 \end{equation}
\paragraph{Low-rank approximations} Let $\dom$ be compact, let $\shCent = \shCentLong$, $c_i\in\dom$, and let $\empK\in\R^{\ncent\times\ncent}$, $\empK_{ij}:=\kernel(c_i,c_j)$ be the Gram matrix computed from $\shCent$. This matrix can be diagonalized to compute approximations $(\empEval_i, \empEfunc_i(x))$ of the eigenvalues and eigenfunctions $(\eval_i, \efunc_i(x))$ of the kernel \cite{williams2001using2}. These spectral quantities can then be used to compute  $ \fmapApprox_i(x):=\sqrt{\empEval}_i\empEfunc_i(x)$.
 \paragraph{Random Fourier features} Let $\dom\subset\R^n$ be compact, and let $ \kernel(x,y) = e^{-\|x-y\|^2/2\s^2}$ be the Gaussian RBF kernel. Then random Fourier features approximate the kernel feature map as $\fmapApprox_{\randFreq}:\dom\to\fspaceApprox$, where $\randFreq$ is a sample from the Fourier transform of $\kernel(x,y)$, with the property that $\kernel(x,y) = \E_{\randFreq}[\l\fmapApprox_{\randFreq}(x),\fmapApprox_{\randFreq}(y)\r_{\fspaceApprox}]$ \cite{rahimi2007random}. In this case, if $\randMat\in\R^{M/2\times n}$ is a random matrix representing the sample $\randFreq$, then 
 $ 
  \fmapApprox_i(x) := \left[\begin{smallmatrix}
  \frac{1}{\sqrt{\ncent}}\sin([\randMat x]_i), \frac{1}{\sqrt{\ncent}}\cos([\randMat x]_i)
 \end{smallmatrix}\right]$. Similar approximations exist for other radially symmetric kernels, as well as dot-product kernels. 

\begin{figure}
	\centering
	
	\begin{subfigure}[t]{0.32\textwidth}
        	\label{fig:commute_sysop_dyn}
        	\begin{tikzpicture}
        	  \matrix (m) [ampersand replacement=\&, matrix of math nodes, 
        	                 row sep=0.75in,column sep=1in,minimum width=0.5in] {
        	     \boldsymbol\fspaceApprox \& \boldsymbol\fspaceApprox \\
        	     \pmb{\R^{\ncent}} \& \pmb{\R^{\ncent}} \\};
        	  \path[-stealth]
        	    (m-1-1) edge node [left] {$\boldsymbol\weightmap$} (m-2-1)
        	            edge [right] node [above] {$\boldsymbol\sysop$} (m-1-2)
        	    (m-2-1.east|-m-2-2) edge node [below] {$\boldsymbol A$} node [above] {} (m-2-2)
        	    (m-2-2) edge node [right] {$\boldsymbol\weightmapI$} (m-1-2);            
        	\end{tikzpicture}
	\caption{Relationship between $\sysop$ and $A$}
	\end{subfigure}

	\begin{subfigure}[t]{0.32\textwidth}
	\label{fig:commute_sysop_meas}
	
	\begin{tikzpicture}
	  \matrix (m) [ampersand replacement=\&, matrix of math nodes, 
	               row sep=0.75in,column sep=1in,minimum width=0.5in] {
	     \boldsymbol\fspaceApprox \& \pmb{\boldsymbol\R^{\nsamp}} \\
	     \pmb{\R^{\ncent}} \&  \\};
	  \path[-stealth]
	    (m-1-1) edge node [left] {$\boldsymbol\weightmap$} (m-2-1)
	            edge [right] node [above] {$\boldsymbol\measop$} (m-1-2)
	    (m-2-1) edge node [right] {$\ \boldsymbol\empK$} (m-1-2)
	    (m-2-1) edge node [right] {$\boldsymbol\weightmapI$} (m-1-1);            
	\end{tikzpicture}
	\caption{Relationship between $\measop$ and $\empK$}
	\end{subfigure}
	
	\begin{subfigure}[t]{0.32\textwidth}
	\label{fig:commute_sysop_control}
	\begin{tikzpicture}
	  \matrix (m) [ampersand replacement=\&, matrix of math nodes, 
	                 row sep=0.75in,column sep=1in,minimum width=0.5in] {
	     \boldsymbol\fspaceD \& \boldsymbol\fspaceApprox \\
	     \pmb{\R^{\ncontrol}} \& \pmb{\R^{\ncent}} \\};
	  \path[-stealth]
	    (m-1-1) edge node [left] {$\boldsymbol\weightmapC$} (m-2-1)
	            edge [right] node [above] {$\boldsymbol\controlop$} (m-1-2)
	    (m-2-1.east|-m-2-2) edge node [below] {$\boldsymbol B$} node [above] {} (m-2-2)
	    (m-2-2) edge node [right] {$\boldsymbol\weightmapI$} (m-1-2);            
	\end{tikzpicture}
	\caption{Relationship between $\controlop$ and $B$}
	\end{subfigure}
	
	\caption{Commutative diagrams between primal and dual spaces}
	\label{fig:commute_sysop}
\end{figure}



In the approximate space case, we replace the transition operator $\sysop:\fspace\to\fspace$ in \eqref{ideal_lin_evol} by $\sysopApprox:\fspaceApprox\to\fspaceApprox$.
This approximate regime, which combines the flexibility of a truly nonparametric approach with computational realizability, still allows for the representation of rich phenomena, as will be seen in the sequel, and in Figure \ref{fig:kernel_variation}. 
The finite-dimensional evolution equations approximating \eqref{ideal_lin_evol} in dual form are:

\begin{align} \eqlabel{k_measure}
 \weight_{\tindex+1} = \dualopApprox\weight_{\tindex} + \processnoise_{\tindex}, \quad 
 \meas_{\tindex} = \obsMat \weight_{\tindex} +\measnoise_{\tindex},
\end{align}
where we have matrices $\dualopApprox\in \R^{\ncent\times\ncent}, \ \obsMat\in \R^{\nsamp\times\ncent}$, the vectors $\weight_{\tindex}\in\R^{\ncent}$, and where we have slightly abused notation to let $\meas_{\tindex}, \processnoise_{\tindex}$ and $\measnoise_{\tindex}$ denote their $\fspaceApprox$ counterparts. Here $\obsMat$ is the matrix whose rows are of the form $\obsMat_{(i)} = \obsMatRow(x_i) =
 \left[\begin{smallmatrix}
  \fmapApprox_1(x_i) & \fmapApprox_2(x_i) & \cdots & \fmapApprox_{\ncent}(x_i)
 \end{smallmatrix}\right]$. In systems-theoretic language, each row of $\obsMat$ corresponds to a \emph{measurement} at a particular location, and the matrix itself acts as a measurement operator. 

The equations in \eqref{ideal_lin_evol} suggest an immediate extension to functional control problems. 
Pick another basis for $\fspace$ as $\cbasis(x) := \begin{bmatrix}\cbasis_1(x) &\cdots & \cbasis_{\ncontrol}(x)
\end{bmatrix}^T$, where the functions $\cbasis_j(x)$ are used to approximate the RKHS $\fspace$ generated by the kernel. We denote the span of these functions as $\fspaceD$. In the dictionary of atoms case, an example would be another set of atoms
 $\AtomsControl = \begin{bmatrix}\fmap(d_1) &\cdots & \fmap(d_{\ncontrol})
\end{bmatrix}$, $\fmap(d_j)\in\fspace$, $d_j\in\dom$, with $\fspaceD$ being a strict subspace of the RKHS $\fspace$  generated by the kernel. 
The functional evolution equation is then as follows:
\begin{align}\eqlabel{ideal_lin_evol_control}
 f_{\tindex+1} = \sysop f_{\tindex} + \controlop \control_{\tindex} + \eta_{\tindex}, \quad y_{\tindex} = \measop_{\tindex} f_{\tindex} + \zeta_{\tindex},
\end{align}
where the control functions $\control_{\tindex}$ evolve in $\fspaceD$, and $\controlop:\fspaceD\to\fspaceApprox$. To derive the finite-dimensional equivalent of $\controlop$, we have to work out the structure of the matrix $B$: since $\fspaceApprox$ is not, in general, isomorphic to $\fspaceD$, this imposes strict restrictions on $B$. We can derive $B$ using least squares using the inner product of $\fspace$. An instructive example is where both $\fspaceApprox$ and $\fspaceD$ are generated by dictionaries of atoms; recall that in this case, $\Atoms = 
 \begin{bmatrix}\fmap(c_1) &\cdots & \fmap(c_{\ncent})
\end{bmatrix}$ is the basis for $\fspaceApprox$, and let $\control = \sum_{j=1}^{\ncontrol}\weightc_j\fmap(d_j)$, and let $\Atoms = 
 \begin{bmatrix}\fmap(c_1) &\cdots & \fmap(c_{\ncent})
\end{bmatrix}$ be the basis for $\fspaceC$. Then the projection of $\delta$ onto $\fspaceApprox$ can be derived as: 


\begin{align}
 \begin{bmatrix}
  \l \delta, \fmap(c_1) \r_{\fspace}\\
   \vdots\\
  \l \delta, \fmap(c_{\ncent}) \r_{\fspace} 
 \end{bmatrix}
 = 
 \underbrace{
 \begin{bmatrix}
  \Kiprod{d_1}{c_1} & \cdots & \Kiprod{d_{\ncontrol}}{c_1}\\
   \vdots  &\ddots &\vdots\\
  \Kiprod{d_1}{c_{\ncent}} & \cdots & \Kiprod{d_{\ncontrol}}{c_{\ncent}}
 \end{bmatrix}}_{\empKCD}
  \begin{bmatrix}
   \weightc_1\\
   \vdots\\
   \weightc_{\ncontrol}
  \end{bmatrix}.
\end{align}

Note that in the dictionary of atoms case, the entries of $\empKCD$ can be computed in closed form as ${\empKCD}_{ij}:= \kernel(d_i, c_j)$,
using the reproducing property. 
This derivation shows that the operator $B$ is simply $\empKCD\in\R^{\ncent\times\ncontrol}$, the kernel matrix between the data $\centers$ generating the atoms $\Atoms$ of $\fspaceApprox$ and the data $\centerscontrol$ generating the atoms $\AtomsControl$ of $\fspaceD$. 

Thus, the finite-dimensional evolution equations equivalent to \eqref{ideal_lin_evol_control} are
\begin{align}
 \weight_{\tindex+1} = \dualopApprox\weight_{\tindex} + \empKCD\weightc_{\tindex}, \quad
 y_{\tindex} = \empK_{\tindex} w_{\tindex} \eqlabel{k_measure_c1}.
\end{align}
We define the \emph{generalized observability matrix} \cite{zhou:bk:96} as 
%\begin{align}\eqlabel{obs_mat}
$  \Obs_{\Tset} = 
 \left[
 \begin{smallmatrix}
  \empK \dualopApprox^{\tindex_1}\\
  \cdots\\
  \empK \dualopApprox^{\tindex_\otime}
 \end{smallmatrix}
 \right] $ 
%\end{align}
where $\Tset = \{\tindex_1, \dots, \tindex_{\otime}\}$ are the set of instances $\tindex_i$
when we apply the operator $\empK$. A linear system is said to be \emph{observable} if $\Obs_{\Tset}$ has full column rank (that is, $\mathrm{Rank} (\Obs_{\Tset})=\ncent$) for 
$\Tset = \{0, 1, \dots, \ncent-1\}$ \cite{zhou:bk:96}. Observability guarantees two critical facts: firstly, it guarantees that the state $\weight_0$ can be recovered exactly from a finite series of measurements $\{y_{{\tindex}_1}, y_{{\tindex}_2}, \dots, y_{{\tindex}_{\otime}}\}$; in particular, defining $y_{\Tset} = \begin{bmatrix}y_{{\tindex}_1}^T, y_{{\tindex}_2}^T, \cdots, y_{{\tindex}_{\otime}^T}\end{bmatrix}^T$, we have that $y_{\Tset} = \Obs_{\Tset}\weight_0.$  Secondly, it guarantees that a feedback based \emph{observer} can be designed such that the estimate of $\weight_{\tindex}$, denoted by $\estweight_{\tindex}$, converges exponentially fast to $\weight_{\tindex}$ in the limit of samples. Note that all our theoretical results assume $\dualopApprox$ is available: while we perform system identification in the experiments (\cite{Kingravi16_NIPS}), it is not the focus of the paper. 

We are now in a position to formally state the spatiotemporal modeling, control, and inference problems being considered: given a spatiotemporally evolving system modeled using \eqref{k_measure}, choose a set of $\nsamp$ sensing locations such that even with $\nsamp\ll \ncent$, the functional evolution of the spatiotemporal model can be estimated (which corresponds to \emph{monitoring}), can be predicted robustly (which corresponds to \emph{Bayesian filtering}), and which can be controlled (which corresponds to \emph{functional control}). Our approach to solve the monitoring and prediction problem relies on the design of the measurement operator $\empK$ so that the pair $(\empK, \dualopApprox)$ is observable: any Bayesian state estimator (for example a Kalman filter) utilizing this pair is denoted as a \textbf{kernel observer}. In the case where no measurements are taken, for the sake of consistency, we denote the state estimator as an \textit{autonomous} kernel observer. In the controls case, given a spatiotemporally evolving system modeled using \eqref{k_measure_c1}, we need to choose a set of $\nsamp$ sensing locations and $\ncontrol$ control locations, such that even with $\nsamp\ll \ncent, \ \ncontrol \ll\ncent$, the functional evolution of the spatiotemporal model can be controlled; in this case, we must design both a measurement operator $\empK$ and a control operator $\empKCD$ such that the pair $(\empKCD, \dualopApprox)$ is controllable: a controls system utilizing this pair and the measurement operator $\empK$ is denoted as a \textbf{kernel controller}.


\subsection{Preliminaries on Rational Canonical Structures}\label{sec_prelim}

We take a geometric approach towards the choice of sampling locations for inferring $\weight_{\tindex}$ in  \eqref{k_measure}; the extension for control is similar.  We use the notation $\linspace$, with $\dims(\linspace)=\ncent$, to emphasize the fact that these theorems hold for any finite-dimensional vector space. Consider the linear operator $\sysop:\linspace\rightarrow\linspace$, and recall that the definition of observability requires the construction of a linear operator $\measop:\linspace\to\linspaceout$, with $\dim(\linspaceout) = \nsamp$, such that 
$\Rank\left[
 \begin{smallmatrix}
  \left(\measop\right)^T &
  \cdots &
  \left(\measop \sysop^{\ncent-1}\right)^T
 \end{smallmatrix}
 \right]^T = \ncent$. 
In most applications, if $\nsamp\geq\ncent$, and $\Rank\left(\measop\right) = \nsamp$, it is reasonable to expect that observability may be achieved. However, for our purposes, $\nsamp$ must be \emph{significantly} less than $\ncent$. Therefore, we must design $\measop$ with as small a rank as possible. To do so, we require a series of vectors $\linvec_i$ that, under repeated iterations of $\sysop$, can generate a basis for $\linspace$. For this task, we will use a fundamental decomposition result from the theory of modules, known as the \emph{rational canonical structure} of $\sysop$ \cite{wonham1974linear}. The intuition here is that if the sequence $\{\linvec_i\}_{i}$ can generate this basis, it can be directly used to construct $\measop$.

The linear operator $\sysop:\linspace\rightarrow\linspace$ has a characteristic polynomial $\charpoly(\eval) $ such that $\charpoly(\sysop)=0 $ by the Cayley-Hamilton theorem. The minimal polynomial (MP) of $\sysop$ is the monic polynomial $\minpoly(\cdot)$ of least degree (denoted by $\degs(\cdot)$) given as 
$\minpoly(\eval) = \polycoeff_0 + \polycoeff_1\eval +\cdots + \eval^{\degs(\minpoly)} = 0$, such that
$\minpoly(\sysop)=\polycoeff_0 I + \polycoeff_1\sysop +\cdots + \sysop^{\degs(\minpoly)} = \bm{0}$. 
The MP is unique and divides $\charpoly(\lambda)$, so that $ \degs(\minpoly) \leq \degs(\charpoly)$. The MP of a vector $\linvec\in\linspace$ \emph{relative to $\sysop$} is the unique monic polynomial $\minpolyv_{\linvec}$ of least degree such that 
$\minpolyv_{\linvec}(\sysop)\linvec= \polycoeff_0\linvec + \polycoeff_1\sysop\linvec + \cdots + \sysop^{\degs(\minpoly)}\linvec = 0$. 
If $\degs(\alpha) = \ncent$, then $\sysop$ is \emph{cyclic} and $\exists\linvec\in \linspace$, such that the vectors $\{\linvec, \sysop \linvec,\dots,\sysop^{\ncent-1}\linvec\}$ form a basis for $\linspace$; this is the same as saying that the pair $(\linvec^T,\sysop^T)$ is observable.    
A subspace $\subspace\subset\linspace$ s.t. $\sysop\subspace\subset\subspace$ is \emph{$\sysop$-cyclic} if  $\restrict{\sysop}{\subspace}$, the restriction of $\sysop$ to the subspace $\subspace$, is cyclic. If $\minpoly(\eval)$ is the minimal polynomial of $\sysop$ and $\degs(\minpoly) = \acycdeg < \ncent$, $\exists~\linvec\in\linspace$ such that $\{\linvec, \sysop \linvec,\dots,\sysop^{\acycdeg-1}\linvec\}$ span an $\acycdeg$-dimensional $\sysop$-cyclic subspace $\subspace$, with $\linvec$ being the \emph{cyclic generator} of $\subspace$.  The subspace $\subspace$ decomposes $\linspace$ relative to $\sysop$. By the rational canonical structure theorem (Theorem 0.1 of \cite{wonham1974linear}), $\sysop$ can be successively decomposed into subspaces $\linspace_i \subset \linspace$, $i\in \{1,\dots,\minmeas\}$, s.t. $\linspace = \linspace_1 \oplus ... \oplus \linspace_{\minmeas}$, $\sysop\linspace_i \subset \linspace_i$, and  $\sysop_{|\linspace_i}, i \in \{1,\dots,\minmeas\}$, are cyclic. In general, the subspaces $\linspace_i$ are not unique for a fixed $\sysop$. The integer $\minmeas$ is unique and is called the \emph{cyclic index of $\sysop$}. 

One of our main results is to show that the cyclic index is a lower bound on the number of measurements required to reconstruct $\weight_{\tindex}$ (see Prop. \ref{prop:3} and Alg. 1 below). The matrix transform associated to this theorem is known as the \emph{Frobenius normal form} (denoted by $\FrobC\in\R^{\ncent\times\ncent}$ ): for $\sysop\in\R^{\ncent\times\ncent}$,  $\exists \FrobP\in\R^{\ncent\times\ncent}$ invertible  such that $\sysop = \FrobP\FrobC\FrobP^{-1}$. We will also use the \emph{Jordan decomposition}, where for $\sysop\in\R^{\ncent\times\ncent}$, $\exists \JorP\in\R^{\ncent\times\ncent}$ invertible such that $\sysop = \JorP\JorLa \JorP^{-1}$, where $\JorLa$ is a unique block diagonal matrix with Jordan blocks with $\eval_i$ along the diagonal. 
If all the eigenvalues $\eval_i$ are nonzero and real, we say the matrix has a \emph{full-rank Jordan decomposition}. 




\subsection{Main Results}\label{sec:theory_results}

In this section, we prove results concerning the observability of spatiotemporally varying functions modeled by the functional evolution and measurement equations \eqref{k_measure}. In particular,  observability of the system states implies that we can recover the current state of the spatiotemporally varying function using a small number of sampling locations $\nsamp$, which allows us to 1) track the function, and 2) predict its evolution forward in time. We work with the approximation $\fspaceApprox\approx\fspace$: given $\ncent$ basis functions, this implies that the dual space of $\fspaceApprox$ is $\R^{\ncent}$.
Proposition \ref{prop:1} shows that if $\dualopApprox$ has a full-rank Jordan decomposition, the observation matrix $\obsMat$ meeting a condition called \emph{shadedness} (Definition \ref{def:shaded}) is sufficient for the system to be observable. Proposition \ref{prop:2} provides a lower bound on the number of sampling locations required for observability which holds for any $\dualopApprox$.  Proposition \ref{prop:3} constructively shows the existence of an abstract measurement map $\measmap$ achieving this lower bound. Since the measurement map does not have the structure of a kernel matrix, a slightly weaker sufficient condition for the observability of any $\dualopApprox$ is in Theorem \ref{thm:1}. Finally, since both $\empK$ and $\empKCD$ are kernel matrices generated from a shared kernel, these observability results translate directly into controllability results.

\begin{definition}\label{def:shaded}
\textbf{(Shaded Observation Matrix)} Given $\kernel:\dom\times\dom\to\R$ positive-definite on a domain $\dom$, let $\{\fmapApprox_1(x), \dots, \fmapApprox_{\ncent}(x)\}$ be the set of bases generating an approximate feature map $\fmapApprox:\dom\to\fspaceApprox$, and let
$\sampSet = \sampSetLong$ be the set of sampling (or sensing) locations, with each $x_i\in\dom$. 
Let $\obsMat\in\R^{\nsamp\times\ncent}$ be the observation matrix, where $ \obsMat_{ij} := \fmapApprox_j(x_i)$. For each
row $\obsMat_{(i)} := \left[\begin{smallmatrix}
  \fmapApprox_1(x_i) & \cdots & \fmapApprox_{\ncent}(x_i)
 \end{smallmatrix}\right]$, define the set 
$\Ind_{(i)} := \{\iota_1^{(i)},\iota_2^{(i)},\dots, \iota_{\ncent_i}^{(i)}\}$ to be the indices in the observation
matrix row $i$ which are nonzero. 
Then if 

$\bigcup_{i\in\{1,\dots,\nsamp\}} \Ind^{(i)} = \{1,2,\dots, \ncent\}$,

we denote $\obsMat$ as a \emph{shaded observation matrix} (see Figure \ref{fig:shadeda}).
\end{definition}

This definition seems quite abstract, so the following remark considers a more concrete example.

\begin{remark}\label{rem:shaded}
 Let $\fmapApprox$ be generated by the dictionary given by $\shCent = \shCentLong$, $c_i\in\dom$. Note that since $\fmapApprox_j(x_i) = \l\fmap(x_i), \fmap(c_j)\r_{\fspace} = \kernel(x_i,c_j)$, $\obsMat$ is the kernel matrix between $\sampSet$ and $\shCent$. For the kernel matrix to be shaded thus implies that there does not exist an atom $\fmap(c_j)$ such that the projections $\l\fmap(x_i),\fmap(c_j)\r_{\fspace}$ vanish for all $x_i$, $1\leq i\leq \nsamp$. Intuitively, the shadedness property requires that the sensor locations $x_i$ are privy to information propagating from every $c_j$. As an example, note that, in principle, for the Gaussian kernel, a single row generates a shaded kernel matrix. However, in this case, the matrix can have many entries that are extremely close to zero, and will probably be very ill-conditioned.  
\end{remark}


\begin{proposition}\label{prop:1}
Given $\kernel:\dom\times\dom\to\R$ positive-definite on a domain $\dom$, let $\{\fmapApprox_1(x), \dots, \fmapApprox_{\ncent}(x)\}$ be the set of bases generating an approximate feature map $\fmapApprox:\dom\to\fspaceApprox$, and let
$\sampSet = \sampSetLong$, $x_i\in\dom$. Consider the discrete linear system on $\fspaceApprox$ given by the evolution and measurement equations \eqref{k_measure}. Suppose that a full-rank Jordan decomposition of $\dualopApprox\in\R^{\ncent\times\ncent}$ of the form $\dualopApprox = \JorP\JorLa\JorP^{-1}$ exists, where $\JorLa = 
\left[\begin{smallmatrix}\JorLa_1 &\cdots & \JorLa_{\JorMul}\end{smallmatrix}\right]$,
and there are no repeated eigenvalues. Then, given a set of time instances  $\Tset = \{\tindex_1,\tindex_2,\dots,\tindex_{\otime}\}$, and a set of sampling locations $\sampSet=\sampSetLong$,
the system \eqref{k_measure} is observable if the observation matrix $\empK_{ij}$ is shaded according to Definition \ref{def:shaded},
% $\empK^D$, the row vector generated by summing the rows of $\empK$, has all nonzero entries, 
$\Tset$ has distinct values, and $|\Tset| \geq \ncent$.
\end{proposition}

\begin{proof}
	To begin, consider a system where $\dualopApprox = \JorLa$, with Jordan blocks $\{\JorLa_1, \JorLa_2, \dots, \JorLa_{\JorMul}\}$ along the 
	diagonal. Then $\dualopApprox^{\tindex_i} = \diag(\begin{bmatrix}\JorLa_1^{\tindex_i} & \JorLa_2^{\tindex_i} & \cdots & \JorLa_{\JorMul}^{\tindex_i}\end{bmatrix})$. 
	%The exponentiation of each Jordan block results in upper triangular matrices with linearly independent columns. 
	We have that:
	\begin{align*}
	\Obs_{\Tset} &=
	\underbrace{
		\begin{bmatrix} 
		\empK \dualopApprox^{\tindex_1}\\
		\cdots\\
		\empK \dualopApprox^{\tindex_\otime}.
		\end{bmatrix}}_{\Obs_{\Tset}\in\R^{\nsamp\otime\times\ncent}}
	\end{align*}
	We need to prove that the column rank of $\Obs_{\Tset}$ is $\ncent$, which is not immediately
	obvious since typically $\nsamp \ll \ncent$. To prove the statement, we will show that 
	computing the rank of $\Obs_{\Tset}$ is equivalent to the rank computation of the product of 
	two simple matrices. In what follows,
	we use the notation $\zerosMat{I}{J}$ to denote an $I\times J$ matrix of all zeros. 
	
	In the first step, we write the above matrix as the product of two matrices. Then it can be	shown that $\Obs_{\Tset}$ is the product of two block matrices.
	\begin{align*}
	\Obs_{\Tset}  
	&=
	\underbrace{
		\begin{bmatrix}
		\empK   & \cdots & \zerosK\\
		\vdots  & \ddots & \vdots\\
		\zerosK  & \cdots & \empK
		\end{bmatrix}}_{\catempK\in\R^{\nsamp\otime\times\ncent\otime}}
	\underbrace{
		\begin{bmatrix}
		\JorLa_1^{\tindex_1} & \cdots & 0\\
		\vdots & \ddots & \vdots\\
		0 & \cdots & \JorLa_{\JorMul}^{\tindex_1}\\ 
		\hline
		\vdots & \ddots & \vdots\\
		\hline
		\JorLa_1^{\tindex_{\otime}} & \cdots & 0\\
		\vdots & \ddots & \vdots\\
		0 & \cdots & \JorLa_{\JorMul}^{\tindex_\otime}   
		\end{bmatrix}}_{\catdualopC\in\R^{\ncent\otime\times\ncent}}.
	\end{align*}
	We need to simplify $\catempK$ even further. 
	Recall that a matrix's rank is preserved under a product with an invertible matrix. Design a 
	matrix of elementary row operations $U\in\R^{\nsamp\times\nsamp}$ such that $\transempK := U\empK$ is a matrix with at least one row vector of nonzeros; this can be achieved by having an elementary matrix that adds rows together. By the shadedness assumption, such a matrix exists. We can write this operation as:
	\begin{align*}
	U\empK = 
	\begin{bmatrix}
	\transempK_{11} & \transempK_{12} & \cdots & \transempK_{1\ncent}\\
	\transempK_{21} & \transempK_{22} & \cdots & \transempK_{2\ncent}\\
	\vdots & \vdots & \ddots & \vdots\\
	\transempK_{\nsamp1} & \transempK_{\nsamp2} & \cdots & \transempK_{\nsamp\ncent}.
	\end{bmatrix}
	\end{align*}
	Without loss of generality, and abusing notation slightly, let this multiplication lead to one nonzero row, with the rest of the elements of the matrix being zero, as:
	\begin{align*}
	U\empK = 
	\begin{bmatrix}
	\kernel_{11} & \kernel_{12} & \cdots & \kernel_{1\ncent}\\
	0 & 0 & \cdots & 0\\
	\vdots & \vdots & \ddots & \vdots\\
	0 & 0 & \cdots & 0
	\end{bmatrix}.
	\end{align*}
	Since elementary matrices are full-rank, we then have that $\Rank(U\empK) = \Rank(\empK)$. 
	
	To analyze the rank of $\Obs_{\Tset}$, we apply these elementary matrices to every $\empK\in\catempK$. To do so, consider the block-diagonal matrix $\bdU\in\R^{\nsamp\otime\times\nsamp\otime}$ with $U\in\R^{\nsamp\times\nsamp}$ along the diagonal, and zeros everywhere else,
	that is,
	\begin{align}
	\bdU:= \begin{bmatrix}
	U   & \zerosU & \cdots & \zerosU\\
	\zerosU & U   & \cdots & \zerosU\\
	\vdots  & \vdots  & \ddots & \vdots\\
	\zerosU & \zerosU & \cdots & U
	\end{bmatrix}.
	\end{align}
	It can be shown that  $\bdU$ is full-rank, that is, has rank $\nsamp\otime$. Going back to the observability matrix, we have that:
	\begin{align*}
	\bdU\Obs_{\Tset} &= \bdU\catempK\catdualopC\\
	&=  
	\underbrace{
		\begin{bmatrix}
		U\empK   & \zerosK & \cdots & \zerosK\\
		\zerosK & U\empK   & \cdots & \zerosK\\
		\vdots  & \vdots  & \ddots & \vdots\\
		\zerosK & \zerosK & \cdots & U\empK
		\end{bmatrix}}_{\bdU\catempK\in\R^{\nsamp\otime\times\ncent\otime}}
	\underbrace{\catdualopC}_{\in\R^{\ncent\otime\times\ncent}},
	\end{align*}
	since $\zerosU\zerosK = \zerosK$. Due to the fact that $\Rank(\bdU\Obs_{\Tset}) = \Rank(\Obs_{\Tset})$,
	we can therefore perform our rank analysis on the simpler matrix $\Rank(\bdU\Obs_{\Tset})$. Note that:
	\begin{align*}
	U\empK \dualopApprox^{\tindex_j} &=  
	\begin{bmatrix}
	\kernel_{11} & \kernel_{12} & \cdots & \kernel_{1\ncent}\\
	0 & 0 & \cdots & 0\\
	\vdots & \vdots & \ddots & \vdots\\
	0 & 0 & \cdots & 0
	\end{bmatrix}
	\dualopApprox^{\tindex_j}\\
	&= 
	\begin{bmatrix}
	k_{11}\la_1^{\tindex_j} & \binom{\tindex_j}{1}\la_1^{\tindex_j-1} + k_{12}\la_1^{\tindex_j}  & \cdots & k_{1\ncent}\la_{\JorMul}^{\tindex_j}\\
	0 & 0 & \cdots & 0\\
	\vdots & \vdots & \ddots & 0\\
	0 & 0 & \cdots & 0
	\end{bmatrix}.  
	\end{align*}
	Therefore, following some more elementary row operations encoded by $V\in\R^{\ncent\otime\times\ncent\otime}$, we have that:
	\begin{align*}
	V \bdU\Obs_{\Tset}
	&= 
	\begin{bmatrix}
	\kernel_{11}\la_1^{\tindex_1} & \cdots & \kernel_{1\ncent}\la_{\JorMul}^{\tindex_1}\\
	\kernel_{11}\la_1^{\tindex_2} & \cdots & \kernel_{1\ncent}\la_{\JorMul}^{\tindex_2}\\
	\vdots & \ddots & 0\\
	\kernel_{11}\la_1^{\tindex_{\otime}} & \cdots 
	& \kernel_{1\ncent}\la_{\JorMul}^{\tindex_{\otime}}\\
	\zerosMat{\ncent(\otime-1)}{1} & \cdots & \zerosMat{\ncent(\otime-1)}{1}
	\end{bmatrix}\\
	&= 
	\begin{bmatrix}
	\boldsymbol{\Phi}\\
	\zerosMat{\ncent(\otime-1)}{\ncent}
	\end{bmatrix}.
	\end{align*}
	If the individual entries $\kernel_{1i}$ are nonzero, and the Jordan block diagonals have nonzero eigenvalues, the columns of $\boldsymbol\Phi$
	become linearly independent. Therefore, if $\otime \geq \ncent$, the column rank of $\Obs_{\Tset}$ is $\ncent$, which results in an observable system.
	
	To extend this proof to matrices $\dualopApprox = \JorP\JorLa\JorP^{-1}$, note that:
	\begin{align*}
	\Obs_{\Tset} &= 
	\begin{bmatrix}
	\empK \dualopApprox^{\tindex_1}\\
	\cdots\\
	\empK \dualopApprox^{\tindex_\otime}
	\end{bmatrix}\\
	&=
	\begin{bmatrix}
	\empK \JorP\JorLa^{\tindex_1}\JorP^{-1}\\
	\cdots\\
	\empK \JorP\JorLa^{\tindex_\otime}\JorP^{-1}.
	\end{bmatrix}\\
	&=
	\catempK
	\catJorP
	\catJorLa^t
	\catJorP^{-1},
	\end{align*} 
	where $\catJorP\in\R^{\ncent\otime\times\ncent\otime}$, $\catJorLa^t\in\R^{\ncent\otime\times\ncent\otime}$, and
	$\boldsymbol{\JorP^{-1}}\in\R^{\ncent\otime\times\ncent\otime}$ are the block diagonal matrices associated with the system. 
	Since $\catJorP$ is an invertible matrix, the conclusions about the column rank drawn before still hold, and the system is observable. 
\end{proof}



When the eigenvalues of the system matrix are repeated, it is not enough for $\empK$ to be shaded. 
In the next proposition, we take a geometric approach and utilize the rational canonical form  of $\dualopApprox$ to obtain a lower bound on the number of sampling locations required. Let $\nevals$ be the number of unique eigenvalues of $\dualopApprox$, and let $\geomMult{\eval_i}$ denote the geometric multiplicity of eigenvalue $\eval_i$. Then the \emph{cyclic index} of $\dualopApprox$ is defined as $\minmeas = \max_{1\leq i\leq\nevals}{\geomMult{\eval_i}}$\cite{wonham1974linear}.

\begin{proposition}\label{prop:2}
 Suppose that the conditions in Proposition \ref{prop:1} hold, with the relaxation that
 the Jordan blocks $\left[\begin{smallmatrix}
                           \JorLa_1 &\cdots & \JorLa_{\JorMul}
                          \end{smallmatrix}\right]$ may have 
 repeated eigenvalues (that is, $\exists \JorLa_i$ and $\JorLa_j$ s.t. $\eval_i = \eval_j$). Then there exist kernels $\kernel(x,y)$ such that the lower bound $\minmeas$ on the number of sampling locations $\nsamp$ is given by the cyclic index of $\dualopApprox$. In other words, the system in \eqref{k_measure} is observable if $ \nsamp \geq \ell$.
\end{proposition}
\begin{proof}
	\textbf{By Contrapositive.} We will show that if the number of sampling locations are $ \nsamp=\ell-1 $ (that is, $ \nsamp < \ell$), then the system is not observable. Pick the Gaussian kernel in the dictionary of atoms framework,
	with sampling locations $x_i\in\sampSet$ and centers $c_j\in\shCent$, with the additional 
	property that $x_i\neq x_j \forall i,j\in\{1,\dots,\nsamp\}, i\neq j$.
	In this case, 
	$\empKShadFull$ has $\minmeas-1$ nonzero, linearly independent rows, and can be written as:
	\begin{align*}
	\empKShadFull &= \begin{bmatrix}
	k_{11} & k_{12} & \cdots & k_{1\ncent} \\
	\vdots & \vdots & \cdots & \vdots \\
	k_{(\minmeas-1)1} & k_{(\minmeas-1)2} & \cdots & k_{(\minmeas-1)\ncent} 
	\end{bmatrix}.
	\end{align*}
	Since the cyclic index is $\minmeas$, this implies that at least one eigenvalue, say $\eval$, has $\minmeas$ Jordan blocks. 
	%  For concreteness, suppose $\minmeas=2$, and let the size of the blocks be $i\times i$ and $j\times j$. 
	Define indices $j_1, j_2, \dots, j_{\minmeas} \in \{1,2,\dots,\ncent\}$ as the columns corresponding to the leading entries of the $\minmeas$ Jordan blocks corresponding to $\eval$. WLOG, let $j_1 = 1$. Using ideas similar to the last proof, we can write the observability matrix as:
	\begin{align*}
	\Obs_{\Tset}
	&:= 
	\begin{bmatrix}
	\kernel_{11}\eval^{\tindex_1}  & \cdots & \kernel_{1j_{\minmeas}}\eval^{\tindex_1} & \cdots\\
	\vdots & \ddots &\vdots & \ddots\\
	\kernel_{11}\eval^{\tindex_{\otime}}  & \kernel_{1j_{\minmeas}}\eval^{\tindex_{\otime}} & \cdots\\
	\vdots & \ddots & \vdots & \ddots\\
	\kernel_{(\minmeas-1)1}\eval^{\tindex_1}  \cdots & \kernel_{(\minmeas-1)j_{\minmeas}}\eval^{\tindex_1} & \cdots\\
	\vdots & \ddots &\vdots & \ddots\\
	\kernel_{(\minmeas-1)1}\eval^{\tindex_{\otime}}  & \cdots & \kernel_{(\minmeas-1)j_{\minmeas}}\eval^{\tindex_{\otime}} & \cdots
	\end{bmatrix}.
	\end{align*}
	Define $\evalvec:= \begin{bmatrix}\eval^{\tindex_1} & \eval^{\tindex_2} & \cdots \eval^{\tindex_{\otime}}\end{bmatrix}^T$. 
	Then the above matrix becomes:
	\begin{align*}
	\Obs_{\Tset}
	&:= 
	\begin{bmatrix}
	\kernel_{11}\evalvec  & \cdots & \kernel_{1j_2}\evalvec & \cdots & \kernel_{1j_{\minmeas}}\evalvec & \cdots\\
	\vdots & \ddots & \vdots & \ddots &\vdots & \ddots\\
	\kernel_{(\minmeas-1)1}\evalvec  & \cdots & \kernel_{(\minmeas-1)j_2}\evalvec & \cdots & \kernel_{(\minmeas-1)j_{\minmeas}}\evalvec & \cdots
	\end{bmatrix}.
	\end{align*}
	We need to show that one of the columns above can be written in terms of the others. This is equivalent to solving the linear system.
	\begin{align*}
	\begin{bmatrix}
	\kernel_{1j_1}\\
	\kernel_{2j_1}\\
	\vdots\\
	\kernel_{(\minmeas-1)j_1}
	\end{bmatrix}
	&=
	\begin{bmatrix}
	\kernel_{1j_2} & \cdots & \kernel_{1j_{\minmeas}}\\
	\kernel_{2j_2} & \cdots & \kernel_{2j_{\minmeas}}\\
	\vdots & \ddots & \vdots\\
	\kernel_{(\minmeas-1)j_2} & \cdots & \kernel_{(\minmeas-1)j_{\minmeas}}\\
	\end{bmatrix} 
	\begin{bmatrix}
	c_1\\
	c_2\\
	\vdots\\   
	c_{(\minmeas-1)}
	\end{bmatrix}. 
	\end{align*}
	Since the kernel matrix on the RHS is generated from the Gaussian kernel, from \cite{micchelli1984interpolation}, 
	it's known that every principal minor of a Gaussian kernel matrix is invertible, which implies that $\Obs_{\Tset}$ cannot be observable. 
\end{proof}


We will give a concrete example to build intuition regarding this lower bound below. For now, we note the following:
\begin{figure}[t!]
	\begin{algorithm}[H]
		\caption{Measurement Map $\measmap$}
		\label{alg:measmap}
		\begin{algorithmic}
				\STATE {\bfseries Input:} $\dualopApprox\in\R^{\ncent\times\ncent}$
				\STATE Compute Rational Canonical Form, s.t. $\FrobC = \FrobP^{-1}\dualopApprox^T\FrobP$. Set $\FrobC_0:=\FrobC$, and
				$\ncent_0:=\ncent$. 
				\FOR{$i=1$ {\bfseries to} $\minmeas$}
				\STATE Obtain (m.p.) $\minpoly_i(\eval)$ of $\FrobC_{i-1}$. 
				This returns associated indices $\mmapInd{i}\subset\{1,2,\dots,\ncent_{i-1}\}$. 
				\STATE Construct vector $\linvec_i \in \R^{\ncent}$ such that 
				$\minpolyv_{\linvec_i}(\eval)=\minpoly_{i}(\eval)$ .
				\STATE Use indices $\{1,2,\dots,\ncent_{i-1}\}\setminus\mmapInd{i}$ to select matrix $\FrobC_i$. Set 
				$\ncent_i:= |\{1,2,\dots,\ncent_{i-1}\}\setminus\mmapInd{i}|$
				\ENDFOR
				\STATE Compute $ \premeasmap = [\linvec_1^T, \linvec_2^T,...,\linvec_{\minmeas}^T]^T$
				\STATE {\bfseries Output:} $\measmap =\premeasmap\FrobP^{-1}$
		\end{algorithmic}
	\end{algorithm}
\end{figure}


\begin{proposition}\label{prop:3}
Given the conditions stated in Proposition \ref{prop:2}, it is possible to construct a measurement map $\measmap \in \R^{\minmeas\times\ncent}$ for the system given by \eqref{k_measure}, such that the pair $(\measmap, \dualopApprox)$ is observable.
\end{proposition}
\begin{proof}
	The construction of the measurement map $\measmap$ is based on the rational canonical structure of $\dualopApprox^T$, which decomposes $ \linspace $ into $\dualopApprox^T$-cyclic direct summands such that $\linspace = \linspace_1 \oplus \cdots \oplus \linspace_\minmeas$, where $\minmeas$ is the cyclic index of $\dualopApprox$. Let $\minpolyv_{\linvec}$ be the minimal polynomial (m.p.) of $ \linvec $ (relative to $\dualopApprox^T$): it is then the unique monic polynomial of least degree such that $\minpolyv_{\linvec}(\dualopApprox^T)\linvec=0$. Let $\minpoly_1(\eval)$ be the m.p. of ${\dualopApprox^T}_{|\linspace_1}$: then $\degs(\minpoly_1(\eval)) < \ncent$. By the rational canonical structure theorem \cite{wonham1974linear}, there exists a vector $\widehat{\linvec}_1$, such that $\minpolyv_{\linvec_1}(\eval)=\minpoly_1(\eval)$. Similarly there exists a vector $\widehat{\linvec}_2$, such that $\minpolyv_{\linvec_2}(\eval)=\minpoly_2(\eval)$, where $\minpoly_2(\eval)$, is the minimal polynomial of ${\dualopApprox^T}_{|\linspace_2}$ and so on. Thus we can obtain $\minmeas$ such vectors that form the measurement map $\measmap = [\widehat{\linvec}_1, \widehat{\linvec}_2,\cdots, \widehat{\linvec}_\minmeas]^T$. Construction of these vectors $\widehat{\linvec}_i$, can be simplified by first performing the Jordan decomposition as $ \dualopApprox^T = \JorP\JorLa\JorP^{-1} $. Then the vectors $ \widetilde{\linvec_i},\ i\in \{1,\dots,\minmeas\}$ for $ \JorLa $, can be constructed such that the entries corresponding to the leading entries of Jordan blocks of $ \JorLa_{|\linspace_i} $ are nonzero. Such a construction ensures that the m.p. of vector $ \widetilde{\linvec_i}$ w.r.t $\JorLa_{|\linspace_i}$, is also the corresponding m.p. of 
	$\JorLa_{|\linspace_i}$. Finally, the required map can be obtained as $ \measmap = [\widetilde{\linvec_1}, \widetilde{\linvec_2},\dots,\widetilde{\linvec_\minmeas}]^T\JorP^{-1}$.
\end{proof}

The construction provided in the proof of Proposition \ref{prop:3} is utilized in Algorithm 1, which uses the rational canonical structure of $\dualopApprox$ to generate a series of vectors $\linvec_i\in\R^{\ncent}$, whose iterations $\{\linvec_1,\dots,\dualopApprox^{\acycdeg_1-1}\linvec_1,\dots,\linvec_{\minmeas},\dots,\dualopApprox^{\acycdeg_{\minmeas}-1}\linvec_{\minmeas}\}$ generate a basis for $\R^{\ncent}$.
Unfortunately, the measurement map $\measmap$, being an abstract construction unrelated to the kernel, does not directly select $\sampSet$. We will show how to use the measurement map to guide a search for $\sampSet$ in Remark \ref{rem:1}. For now, we state a sufficient condition for observability of a general system. 

\begin{theorem}\label{thm:1}
 Suppose that the conditions in Proposition \ref{prop:1} hold, with the relaxation that the Jordan blocks $\begin{bmatrix}\JorLa_1 & &\cdots & \JorLa_{\JorMul}\end{bmatrix}$ may have repeated eigenvalues. Let $\minmeas$ be the cyclic index of $\dualopApprox$. Define:
 \begin{align}\eqlabel{empKShadFull}
  \empKShadFull = \left[\begin{smallmatrix}
                    \empK^{{(1)}^T} & 
                    \cdots &
                    \empK^{{(\minmeas)}^T}
                  \end{smallmatrix}\right]^T
 \end{align}
 as the \emph{$\minmeas$-shaded matrix} (see Figure \ref{fig:shadedb}) which consists of $\minmeas$ shaded matrices with the property that any subset of
 $\minmeas$
 columns in the matrix are linearly independent from each
 other. Then system \eqref{k_measure} is observable if $\Tset$ has distinct values, and $|\Tset| \geq \ncent$.
\end{theorem}
\begin{proof}
	A cyclic index of $\minmeas$ for this system implies that there exists an eigenvalue $\eval$ that's repeated $\minmeas$ times. We prove the theorem for repeated eigenvalues of dimension 1: the same statement can be proven for repeated eigenvalues for Jordan blocks using the ideas in the proof of Proposition \ref{prop:1}. 
	WLOG, let $\empKShadFull$ have $\minmeas$ fully shaded, linearly independent rows, and, assume that the column indices corresponding to this eigenvalue are $\{1,2,\dots,\minmeas\}$. Define: 
	$\evalvec_i:= \begin{bmatrix}\eval_i^{\tindex_1} & \eval_i^{\tindex_2} & \cdots \eval_i^{\tindex_{\otime}}\end{bmatrix}^T$. Then,
	\begin{align*}
	\Obs_{\Tset}
	&:= 
	\begin{bmatrix}
	k_{11} \evalvec_1 & k_{12} \evalvec_2 & \cdots & k_{1\ncent} \evalvec_{\ncent}\\
	\vdots & \vdots & \ddots & \vdots\\
	k_{\minmeas 1} \evalvec_1 & k_{\minmeas 2} \evalvec_2 & \cdots & k_{\minmeas \ncent} \evalvec_{\ncent}
	\end{bmatrix}.
	\end{align*}
	Let $\evalvec_1 = \evalvec_2 = \cdots \evalvec_{\minmeas} := \evalvec$. 
	Focusing on these first $\minmeas$ columns of this matrix, this implies that
	we need to find constants $c_1,c_2,\dots, c_{\minmeas-1}$ such that:
	\begin{align*}
	\begin{bmatrix}
	k_{11}\\
	\vdots\\
	k_{\minmeas 1}
	\end{bmatrix}
	&= 
	c_1 
	\begin{bmatrix}
	k_{12}\\
	\vdots\\
	k_{\minmeas 2}
	\end{bmatrix}
	+ \cdots + 
	c_{\minmeas-1} 
	\begin{bmatrix}
	k_{1\minmeas}\\   
	\vdots\\
	k_{\minmeas \minmeas} 
	\end{bmatrix}.
	\end{align*}
	However, these columns are linearly independent by assumption, and thus no such constants exist, implying that $\Obs_{\Tset}$ is observable. 
\end{proof}

While Theorem \ref{thm:1} is a quite general result, the condition that any $\minmeas$ columns of $\empKShadFull$ be linearly independent is a very stringent condition. One scenario where this condition can be met with minimal measurements is in the case when the feature map $\fmapApprox(x)$ is generated by a dictionary of atoms with the Gaussian RBF kernel evaluated at sampling locations $\sampSetLong$ according to \eqref{fmap_dict}, where $x_i\in\dom\subset\R^d$, and $x_i$ are sampled from a non-degenerate probability distribution on $\dom$ such as the uniform distribution. For a semi-deterministic approach, when the dynamics matrix $\dualopApprox$ is block-diagonal, we can utilize a simple heuristic:

\begin{remark}\label{rem:1}
 Let $\dom$ be compact, $\shCent = \shCentLong$, $c_i\in\dom$, and let the approximate feature map be defined by \eqref{fmap_dict}. Consider the system \eqref{k_measure} with $\dualopApprox=\JorLa$, and let $\Tset = \{0,1,\dots,\ncent-1\}$. Then the measurement map $\measmap$'s values lie in $\{0, 1\}$; in particular, each row $\measmap^{(j)}$, $j\in\{1,\dots,\minmeas\}$, corresponds to a subspace $\fsubspaceC{j}$, generated by a subset of centers $\shCent^{(j)}\subset\shCent$. Generate samples $x_i^{(j)}$ to create a kernel matrix $\empK^{(j)}$ that is shaded only with respect to centers $\shCent^{(j)}$. Once this is done, move on to the next subspace $\fsubspaceC{j+1}$. When all $\minmeas$ rows of $\measmap$ are accounted for, construct the matrix $\empKShadFull$ as in \eqref{empKShadFull}. Then the resulting system $(\empKShadFull, \dualopApprox)$ is observable. 
\end{remark}


This heuristic is formalized in Algorithm 2. Note that in practice, the matrix $\dualopApprox$ needs to be inferred from measurements of the process $f_{\tindex}$. If no assumptions are placed on $\dualopApprox$, it's clear that at least $\ncent$ sensors are required for the system identification phase. Future work will study the precise conditions under which system identification is possible with less than $\ncent$ sensors.

\begin{figure}[t!]
	\begin{algorithm}[H]
		\caption{Sampling locations set $ \sampSet $}
		\label{alg:samples}
		\begin{algorithmic}
				\STATE {\bfseries Input:} $ \dualopApprox =\FrobC $, lower bound $\minmeas$
				%		\STATE Check $k=\max_i \nu(\lambda_i)$
				\STATE Decompose $ \FrobC $ to generate invariant subspaces $ \fsubspaceC{j} $, $ j\in \{1,2,\dots,\minmeas\} $ (see section ``Preliminaries on Rational Canonical Structures'')
				\FOR{$j=1$ {\bfseries to} $\minmeas$}
				\STATE Obtain centers $\shCent^{(j)}$ w.r.t subspace $ \fsubspaceC{j} $,
				\STATE Generate samples $x_i^{(j)}$ to create a kernel matrix $\empK^{(j)}$ that is shaded only with respect to centers $\shCent^{(j)}$
				\ENDFOR
				\STATE {\bfseries Output:} Sampling locations set  $\sampSet =\{x^{(1)}, x^{(2)}\cdots,x^{(l)}\} $.
		\end{algorithmic}
	\end{algorithm}
\end{figure}

\begin{figure}[t!]
	\centering
	\begin{algorithm}[H]
		\caption{Kernel Observer (Transition Learning)}
		\label{alg:egp_trans}
		\begin{algorithmic}
				\STATE {\bfseries Input:} Kernel $\kernel$, basis centers $\shCent$, final time 
				step $\ftime$. 
				\WHILE{$\tindex \leq \ftime$}
				\STATE $1)$ Sample data $\{y^i_{\tindex}\}_{i=1}^{\ncent}$ from $f_{\tindex}$. 
				\STATE $2)$ Solve for $\estweight_\tindex$ by using least squares on $\meas_{\tindex} = \obsMat \estweight_{\tindex}$. 
				\STATE $3)$ Store weights $\estweight_\tindex$ in matrix $\W\in\R^{\ncent\times \ftime}$.
				\ENDWHILE
				\STATE To infer $\dualopApprox$, define matrix $\Phi = \W^T\W$. Then:
				\FOR{$i=1$ {\bfseries to} $\ncent$}
				\STATE At step $i$, solve system
				\begin{align}
				\dualopApprox^{(i)} = \left(\left(\Phi + \la I\right)^{-1}(\W^T\W^{(i)})\right)^T,
				\end{align}
				where $\dualopApprox^{(i)}$, and $\W^{(i)}$ are the $i$th columns of $\dualopApprox$ and $\W^{(i)}$ respectively. 
				\ENDFOR
				\STATE Compute the covariance matrix  $\estcontrolop$ of the observed 
				weights $\W$. 
				\STATE {\bfseries Output:} estimated transition matrix $\dualopApprox$, predictive covariance    
				matrix $\estcontrolop$. 
		\end{algorithmic}
	\end{algorithm}
	\vspace{-0.3in}
\end{figure}

\begin{figure}[t!]
	\begin{algorithm}[H]
		\caption{Kernel Observer (Monitoring and Prediction)}
		\label{alg:egp_inf}
		\begin{algorithmic}
				\STATE {\bfseries Input:} Kernel $\kernel$, basis centers $\shCent$, 
				estimated system matrix $\dualopApprox$, estimated covariance matrix $\estcontrolop$.
				\STATE {\bfseries Compute Observation Matrix:} Compute the cyclic index $\minmeas$ of $\dualopApprox$, and compute $\empK$.
				\STATE {\bfseries Initialize Observer:} Use $\dualopApprox$, $\estcontrolop$, and $\empK$ to initialize a state-observer (such as Kalman filter (KF)) on $\fspaceApprox$.
				\WHILE{ measurements available }   
				\STATE 1) Sample data $\{y^i_{\tindex}\}_{i=1}^{\nsamp}$ from $f_{\tindex}$.
				\STATE 2) Propagate KF estimate $\estweight_{\tindex}$ 
				forward to time $\tindex+1$, correct using measurement feedback with $\{y^i_{\tindex+1}\}_{i=1}^{\nsamp}$. 
				\STATE 3) Output predicted function $\widehat{f}_{\tindex+1}$ of KF.
				\ENDWHILE   
		\end{algorithmic}
	\end{algorithm}
	\vspace{-0.2in}
\end{figure}

\begin{figure*}[ht!]
\centering
\resizebox{1\textwidth}{!}{
\framebox[1.1\textwidth]{
 \begin{tikzpicture}[->,>=stealth',auto,node distance=1cm,
  thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]
  \node[inner sep=0pt,label=below:{\tiny Physical 
                                  sampling locations},draw] (physical) at (-8,-0.3)
    {\includegraphics[width=0.18\textwidth,
                      height=0.08\textwidth]{"Figure 7a.png"}};
  \node[inner sep=0pt,label=below:{\tiny Data locations},draw] (data) at (-4.25,-0.3)
    {\includegraphics[width=0.18\textwidth,
                      height=0.08\textwidth]{"Figure 7b.pdf"}};
  \node[inner sep=0pt,label=below:{\tiny Functional inference 
                                   (for $\estsysop$)},draw] (inference) at (-0.5,-0.3)
    {\includegraphics[trim=2.4cm 2.6cm 3.4cm 1.5cm,clip,
                      width=0.18\textwidth,
                      height=0.08\textwidth]{"Figure 7c.pdf"}};    
  \node[inner sep=0pt,label={[align=center]
       below:{\tiny Sensor location selection after\\[-1.7\jot]
              \tiny basis decomposition ($\minmeas=3$)}},draw] 
       (sensors) at (3.25,-0.3)
       {\includegraphics[width=0.18\textwidth,
                         height=0.08\textwidth]{"Figure 7d.pdf"}};                          
  \node[inner sep=0pt,label=below:{\tiny Physical sensor placement},draw] (placement) at (6.75,-0.3)
    {\includegraphics[width=0.18\textwidth,
                      height=0.08\textwidth]{"Figure 7e.png"}};                                                
  \path[every node/.style={font=\sffamily\small}]
    (physical) edge node [right] {} (data)
    (data) edge node [right] {} (inference)
    (inference) edge node [right] {} (sensors)
    (sensors) edge node [right] {} (placement);
\end{tikzpicture}

} % end framebox
} % end resizebox
\caption{
Overall description of how the kernel observer fits in the sensing framework. Physical 
locations are mapped to data locations, over which historical data is collected 
as a time series. Functional inference is performed over $\fspaceApprox$ to 
solve for $\estsysop$. The measurement operator $\empK$ is then computed 
(see Figure \ref{fig:sensplace}), leading to sensor placement. 
}\label{fig:overall_system}

\end{figure*}


\begin{figure*}[ht!]
  \begin{minipage}{\textwidth}
  \centering
  \begin{minipage}{0.47\textwidth}
  \resizebox{1\textwidth}{!}{
  \framebox[1.2\textwidth]{  
  \begin{tikzpicture}[scale=1.0, every node/.style={minimum size=1cm},on grid]    
	\begin{scope}[scale=\diagscale, xshift=-250, yshift=0]
		% The frame:
		\fill[white,fill opacity=.85] (0,0) rectangle (7,7); % Opacity
		\draw[black, thin] (0,0) rectangle (7,7); 
		 % Agents:
		\draw [fill=red]
			(4.7,2.7) circle (.2) % Firms
			(2,2) circle (.2) % Households
			(3.5,4.6) circle (.2); % Banks
		\fill[black]
			(0.5,6.5) node[right, scale=\diagtexttop] { \textbf{Compute cyclic index:}}
			(0.7,5.8) node[right, scale=\diagtexttop]
			{$\boldsymbol\minmeas = \mathbf{2}$}
			(4.5,2.1) node[right, scale=\diagtext]{$\boldsymbol\fmap(\mathbf{c_3})$}
			(2.5,1.4) node[left, scale=\diagtext]{$\boldsymbol\fmap(\mathbf{c_2})$}
			(3.5,4.6) node [above, scale=\diagtext] {$\boldsymbol\fmap(\mathbf{c_1})$}
			;
        % draw lines representing possible choices of decomposition                
        \draw[thick](1.3,4.1) to (6.5,4.1);
        \draw[thick](2.2,0.5) to (6.5,5.4);
        \draw[thick](2.5,0.5) to (2.5,5.3);
	\end{scope} 
	\begin{scope}[scale=\diagscale, xshift=0, yshift=0]
		% The frame:
		\draw[black, thin] (0,0) rectangle (7,7); 
		% Agents:
		\draw [fill=blue]
			(4.7,2.7) circle (.2) % Firms
			(2,2) circle (.2); % Households
		\draw [fill=green]			
			(3.5,4.6) circle (.2); % Banks
		 % Labels:
		\fill[black]
		        (0.5,6.5) node[right, scale=\diagtexttop] { \textbf{Compute meas. map:}}
			(0.7,5.8) node[right, scale=\diagtexttop]
			{$\boldsymbol\measmap =[\mathbf\linvec_1, 
			                        \mathbf\linvec_2]^T\boldsymbol\JorP^{-1}$}
% 			(4.5,2.1) node[right, scale=\diagtext]{$\boldsymbol\fmap(\mathbf{c_3})$}
% 			(2.5,1.4) node[left, scale=\diagtext]{$\boldsymbol\fmap(\mathbf{c_2})$}
% 			(3.5,4.6) node [above, scale=\diagtext] {$\boldsymbol\fmap(\mathbf{c_1})$}
			;
	\end{scope} 
	\begin{scope}[scale=\diagscale, xshift=250, yshift=0]
		% The frame:
		\draw[black, thin] (0,0) rectangle (7,7); 
		% Agents:
		\draw [fill=blue, opacity=0.4]
			(4.7,2.7) circle (.2) 
			(2,2) circle (.2)
			;
		\draw [fill=blue]
			(3.2,2) rectangle (3.55,2.35)
			; 
			\node (one) at (3.37,1.5) {\scriptsize$ 1 $};
		\draw [fill=green, opacity=0.4]
			(3.5,4.6) circle (.2)
			;
		\draw [fill=green]			
			(3.0,4.0) rectangle (3.35,4.35)
			;
			\node (two) at (3.17,3.5) {\scriptsize$ 2 $};
		\fill[black]
		        (0.5,6.5) node[right, scale=\diagtexttop] { \textbf{Sensor loc. selection:}}
			(0.7,5.8) node[right, scale=\diagtexttop]
			{$\mathbf{x_1, \ x_2\in}\boldsymbol\dom \boldsymbol\Rightarrow \empKShadFull$}
			;
	\end{scope}	
  \end{tikzpicture}
  } % end framebox
  } % end resizebox  
  \end{minipage}
  \begin{minipage}{0.47\textwidth}
  \resizebox{1\textwidth}{!}{
  \framebox[1.2\textwidth]{  
  \begin{tikzpicture}[scale=1.0, every node/.style={minimum size=1cm},on grid]  
	\begin{scope}[scale=\diagscale, xshift=-150, yshift=0]
		% The frame:
		\fill[white,fill opacity=.85] (0,0) rectangle (7,7); % Opacity
		\draw[black, thin] (0,0) rectangle (7,7); 
		 % Agents:
		\draw [fill=red]
			(4.7,2.7) circle (.2) % Firms
			(2,2) circle (.2) % Households
			(3.5,4.6) circle (.2); % Banks
		\fill[black]
			(0.5,6.5) node[right, scale=\diagtexttop]{\textbf{Compute cyclic index:}}
			(0.7,5.8) node[right, scale=\diagtexttop]
			{$\boldsymbol\minmeas = \mathbf{2}$}
			(4.5,2.1) node[right,scale=\diagtext]{$\boldsymbol\fmap(\mathbf{c_3})$}
			(2.5,1.4) node[left,scale=\diagtext]{$\boldsymbol\fmap(\mathbf{c_2})$}
			(3.5,4.6) node [above, scale=\diagtext] {$\boldsymbol\fmap(\mathbf{c_1})$};
        % draw lines representing possible choices of decomposition                
        \draw[thick](1.3,4.1) to (6.5,4.1);
        \draw[thick](2.2,0.5) to (6.5,5.4);
        \draw[thick](2.5,0.5) to (2.5,5.3);
	\end{scope} 
	\begin{scope}[scale=\diagscale, xshift=150, yshift=0]
		% The frame:
		\draw[black, thin] (0,0) rectangle (7,7); 
		% Agents:
		\draw [fill=blue, opacity=0.4]
			(4.7,2.7) circle (.2) % Firms
			(2,2) circle (.2)
			;
		\draw [fill=blue]
			(1.17,1.1) rectangle (1.17+0.35,1.1+0.35)
			(5.0,1.8) rectangle (5.35,2.15)
                        ;
           \node (one) at (1.31,0.7) {\scriptsize$ 1 $};
           \node (two) at (5.17,1.3) {\scriptsize$ 2 $};
		\draw [fill=green, opacity=0.4]
			(3.5,4.6) circle (.2)
			;
		\draw [fill=green]
                        (3.0,4.0) rectangle (3.35,4.35)
			;
			\node (three) at (3.17,3.5) {\scriptsize$ 3 $};
		 % Labels:
		\fill[black]
		        (0.5,6.5) node[right, scale=\diagtexttop] { \textbf{Random sampling:}}
			(0.7,5.8) node[right, scale=\diagtexttop]
			{$\mathbf{x_1, x_2, x_3\in} \boldsymbol\dom \Rightarrow \empKShadFull$}
			;
	\end{scope} 
  \end{tikzpicture}
  } % end framebox
  } % end resizebox                      

  \end{minipage} 
  \end{minipage} 
  \caption{
  Diagram demonstrating sensor placement using the measurement map or random sampling approaches. 
  The circles represent data locations associated to bases (such as $c_j\Leftrightarrow\fmap(c_j)$) 
  and the squares represent sensor locations (such as $x_i\Leftrightarrow\fmap(x_i)$) .
  The cyclic index ($\minmeas=2$) indicates how many possible couplings of bases exist, 
  which can be represented 
  as a choice of $\binom{\ncent}{\minmeas}$ hyperplanes in $\dom$. If the measurement map is 
  computed (left), the correct couplings are chosen (green vs. blue), and a smaller number of sensors (2) can be placed.
  Alternatively, random sampling (right) is more computationally efficient, but generally
  requires more sensors (3). 
  }\label{fig:sensplace}
\end{figure*}



\subsection{Discussion of Theoretical Results}\label{sec:discussion}
The systems-theoretic approach taken in this paper reveals something rather surprising: functions with complex dynamics (with a small cyclic index) can be recovered with less sensor placements than functions with simpler dynamics. Although seemingly counterintuitive, it becomes clear that this is because complex dynamics, which are characterized by a lower geometric multiplicity of the eigenvalues, ensure that the orbit $\orbit := \{\dualopApprox\weight_{\tindex}\}_{\tindex\in\Tset}$ traverses a greater portion of $\R^{\ncent} \equiv \fspaceApprox$ and thus that fewer sensors can recover more geometric information. On the other hand, in `simpler' functional evolution, $\orbit$ evolves along strict subspaces of $\R^{\ncent}$, and so more independent sensors are required to infer the same amount of information. 

In the case described in Remark \ref{rem:1}, we have a set of centers $\shCent=\shCentLong$, which generate the bases $\Atoms = \{\fmap(c_1), \cdots , \fmap(c_{\ncent})\}$. Let the cyclic index be $\minmeas$: this implies that there exist $\minmeas$ subsets $\atomSubset{i}$ of $\Atoms$ with at least one element $\fmap(c_j)$ each, leading to $\binom{\ncent}{\minmeas}$ possible choices: Figure \ref{fig:sensplace} represents these choices as hyperplanes separating the subsets. 
The measurement map described in Alg. 1 in \cite{Kingravi16_NIPS} induces this \emph{decomposition of bases} $\Atoms = \{\atomSubset{1},\dots,\atomSubset{\minmeas}\}$ in polynomial time. Further, each subset $\atomSubset{i}$ is directly associated to a subset of centers $\centerSubset{i}\subset\shCent$, which allows us to pick targeted sensor locations $x_i\in\dom$. In particular, for radially symmetric kernels such as the Gaussian, the centroid of the convex hull of $\centerSubset{i}$ is sufficient for generating a sensor placement. The measurement map is a significant theoretical insight into sensor placement for dynamically changing environments, because it directly takes into account the dynamics of the process. Of course, in practice, this may be too expensive for approximate feature spaces with $\ncent$ very large, so one can use random sampling to generate the sensor locations instead, at the cost of $\nsamp$ being larger than $\minmeas$. The advantage here though is that since random sampling is computationally inexpensive, different choices of sensor placements can be generated and evaluated relatively quickly.

Another point to note is that since the collection of bases $\{\fmapApprox_i(x)\}_{i=1}^{\ncent}$ determines the richness of the function space $\fspaceApprox\approx\fspace$ we operate in, it determines the fidelity of the model approximation to the true time-varying function. As a consequence, observability of the system in $\fspaceApprox$ refers to the best possible approximation in $\fspaceApprox$. The greater the number of bases, the higher the dimensionality, which results in greater model fidelity, but which may require a much greater number of measurements for state recovery. This is where the lower bounds presented in the paper are particularly useful, because they show that for functional evolutions corresponding to certain $\dualopApprox$, \emph{the number of sensor placements are essentially independent of the dimensionality $\ncent$}, but depend rather on the cyclic index of $\dualopApprox$.

Figure \ref{fig:overall_system} gives an overall picture on the process of generating a kernel observer, while Figure \ref{fig:sensplace} gives two approaches to sensor selection in our framework. The measurement map approach can generate a smaller set of sensors than the random placement approach, but comes at an additional computational cost. 

\subsection{Random Sensor Placement}\label{sec:random_results}
We now elaborate on how the challenging problem of sensor placement can be tackled through random selection. This process of random selection is a product of the kernel observer model described above. We present the theoretical background required to prove Theorem \ref{thm:r1}, which states the expected number of randomly placed sensors required to monitor a given spatiotemporal process, and Theorem \ref{thm:r2}, which determines the probability with which optimal sensor placement is ensured, given that $\nsamp$ number of sensors have been placed. 

As discussed earlier, we work with an approximate feature space $ \fspaceApprox $, with the corresponding transition operator $ \dualopApprox: \fspaceApprox \rightarrow \fspaceApprox $ representing finite-dimensional functional evolution. To achieve observability for the pair ($ \dualopApprox , \empK $), row vectors of the corresponding observability matrix $ \Obs $, should form the basis for the $ \R^\ncent $-dimensional space $ \fspaceApprox $. According to the rational canonical structure Theorem \cite{wonham1974linear}, $\dualopApprox$ can successively decompose the dual space $ \R^\ncent $ into subspaces, $\linspace_i \subset \linspace$, $i\in \{1,\dots,\minmeas\}$, which have the properties: i) $\linspace = \linspace_1 \oplus ... \oplus \linspace_{\minmeas}$, ii) $\dualopApprox\linspace_i \subset \linspace_i$, and iii) $\dualopApprox|_{\linspace_i}, i \in \{1,\dots,\minmeas\}$, are cyclic. The integer $\minmeas$ is unique and is called the \emph{cyclic index of $\dualopApprox$}.  Each of these properties contribute towards the theorem on the number of random samples required to achieve observability. The first property shows that the space $ \R^\ncent $ can be decomposed into $ \ell $ independent subspaces. The second property shows that the vector $ \linvec_i \in \linspace_i $ stays in $ \linspace_i $ even when operated upon by $ \dualopApprox $. To generate bases for $ \R^\ncent $, one needs at least $ \ell $ vectors $ \linvec_1, \dots,\linvec_\ell $, where each $\linvec_i$ arises from a correponsing subspace $\linspace_i$, from the set of subspaces $ \linspace_1,\dots,\linspace_\ell $. This holds due to the third property, but requires that the vectors  $ \linvec_1, \dots,\linvec_\ell, $ are the cyclic generators of their corresponding subspaces. Our analysis is based on whether a randomly selected sensor can generate a cyclic generator. To examine this, recall that a row vector $ \empK_{(i)} $ generated by a randomly selected sensor location $ x_i $ takes the form
\begin{equation}\label{eq:rowvec}
\empK_{(i)} = \bbm k(x_i,c_1),\dots,k(x_i,c_\ncent) \ebm.
\end{equation}
Here, for radial kernels for example, the entries corresponding to the centers closer to $ x_i $ tend to be non-zero, whereas the others tend to be zero.  

Overall, our construction is as follows: for each subspace $ \linspace_i $, let $ \shCent_{\linspace_i} \subset \shCent $ be the centers corresponding to those leading entry of Jordan blocks: then the minimum number of random samples required to generate the bases for $ \linspace_i $ is equal to the number of Jordan blocks comprising $ \linspace_i $. Altogether, the minimum number of random samples required to generate a basis for $ \R^\ncent $ is equal to the total number of Jordan blocks in $ \dualopApprox $. Let $ \rands $ be the total number of Jordan blocks in $\dualopApprox$. Then
%	For entire space we obtain the measurement map $ \measmap = [\linvec_1^T, \linvec_2^T,...,\linvec_{\minmeas}^T]^T $.
\begin{equation}\label{rands}
\rands = \sum_{\lambda \in \sigma(\dualopApprox)} \gamma_{\dualopApprox}(\lambda), \qquad %\geomMult_\lambda
\end{equation}
where $\sigma(\dualopApprox) $ represents the spectrum of $ \dualopApprox $, whose elements are the eigenvalues of $ \dualopApprox $, and $ \gamma_{\dualopApprox}(\lambda) $ is the geometric multiplicity corresponding to the eigenvalue $ \lambda $, which is also equal to the total number of Jordan blocks corresponding to the eigenvalue $ \lambda $. Define a set of centers $ \shCent_\rands $ with elements $ \{c_1, c_2,\dots, c_\rands\} $, to be the centers corresponding to the leading entries of  the Jordan blocks.
For sensor location $x\in\dom$, and $ \epsilon > 0 $, let $\kernel(x, c_j) > \epsilon$. Denote the region $\dom_j\subset\dom$, such that the kernel evaluation with respect to center $c_j$ is greater than $\e$, that is $ \dom_j \equiv \{x\in \dom:\kernel(x, c_j) > \epsilon\} $. We define
$ p_{\e} $ as:
\begin{equation}\label{ppp}
p_{\e} = \min_{c_j \in \shCent_\rands} \frac{\measure(\kernel(x, c_j) > \epsilon)}{\measure(\dom)},
\end{equation}
where $\measure$ is a measure in the real analysis sense. Hence, $p_{\e}$ corresponds to a lower bound on the probability that a random sample lies within the $ \epsilon-$shaded region of a particular center $ c_j$. With all of this in place, we can prove the following theorem.

\begin{theorem}\label{thm:r1}
	Given the spatiotemporal function $ f(x,\tindex) $ with $ x \in \dom \subseteq  \mathbb{R}^\dimI, \tindex\in \mathbb{Z}^+  $ its kernel observer model \eqref{k_measure}, and a tolerance parameter $\e>0$, the expected number of randomly placed sensor locations required to achieve observability for the pair $ (\empK,\dualopApprox) $ is $ \rands/{p_{\e}} $ where $ \rands $ is the summation over geometric multiplicities of each $ \lambda \in \sigma(\dualopApprox) $  given by  (\ref{rands}).
\end{theorem}
\begin{proof}
	For each random sample, the probability that it lies within the $ \epsilon- $shaded region of a particular center $ c_j \in \shCent_\rands$
	is at least $ p_{\e} $. The series of random samples can be considered as Bernoulli trials in which $p_{\e}$ is the probability of a successful outcome. Note this is assuming the worst case scenario that the intersection between any two $ \epsilon $-shaded region of centers belonging to the set  $ \shCent_\rands $ is empty. Observability for the pair $ (\empK, \dualopApprox) $ is achieved after $ \rands  $ successful outcomes are obtained, because each success ensures a row vector with non-zero entry corresponding to the leading entry of the Jordan block. 
	
	Let $ X_1, X_2, \dots, X_\nsamp $ be i.i.d. random variables whose common distribution is the Bernoulli distribution with parameter $p_{\e}$. The random variable $ X = X_1 + X_2+ \dots+ X_\nsamp $ denotes the number of success after a certain number $ \nsamp $ of random samples. Since each $ X_i $ has the Bernoulli distribution, $ X $ will have a binomial distribution, 
	\begin{equation*}
	P(X=h) = \binom{\nsamp}{h}p_{\e}^h (1-p_{\e})^{\nsamp-h},
	\end{equation*}
	in which $ h  $ is the number of success. The expectation of the binomial distribution, that is, the expected number of success, is $ Np_{\e} $, and thus the expected number of trials required will be $ N = \rands/p_{\e}$.
\end{proof}

\begin{theorem}\label{thm:r2}
	Given the spatiotemporal function $ f(x,\tindex) $ with $ x \in \dom \subseteq  \mathbb{R}^\dimI, \tindex\in \mathbb{Z}^+  $, its kernel observer model \eqref{k_measure}, a tolerance parameter $\e>0$, summation over geometric multiplicities of each $ \lambda \in \sigma(\dualopApprox) $ denoted by $ \rands  $ as in  (\ref{rands}), and a constant $ \delta \in (0,1] $, the probability that pair $ (\empK, \dualopApprox) $ is unobservable after the selection of $ \nsamp $ random sensors is at most $ e^{\frac{-1}{2}(\nsamp p_{\e}-2\rands)} $, where $ p_{\e} $ is given by (\ref{ppp}) and $ \nsamp > 2\rands/p_{\e} $.
\end{theorem}
\begin{proof}
	The random variable $ X $ from the proof of Theorem 1 has a binomial distribution, which enables the application of a Chernoff-type bound on its tail probabilities. A well known result  on multiplicative Chernoff bound \cite{motwani2010randomized} is directly applied to establish this Theorem. If $ X $ is binomially distributed, $ \delta \in (0,1] $, and $ \meanDist = \mathbb{E}[X] $, then $ P[X\leq(1-\delta)\meanDist] \leq \exp(-\meanDist \delta^2/2) $, where $ \delta := 1-\frac{\rands}{\nsamp p_{\e}}$.  The expression in the exponent can be simplified to $ -\frac{1}{2}\nsamp p_{\e}+\rands - \frac{\rands^2}{2\nsamp p_{\e}} $, using $ \meanDist = \nsamp p_{\e} $. Note that $ e^{\frac{-\rands^2}{2\nsamp p_{\e}}} \leq 1$. This implies that,
	\begin{equation*}
	\exp(-\meanDist \delta^2/2) =  e^{-\frac{1}{2}(\nsamp p_{\e}-2\rands)}.e^{\frac{-\rands^2}{2\nsamp p_{\e}}}\leq e^{-\frac{1}{2}(\nsamp p_{\e}-2\rands)}
	\end{equation*}
	Note that $ (1-\delta)\mu = \rands $, and so we obtain that $ P[X\leq\rands] \leq e^{-\frac{1}{2}(\nsamp p_{\e}-2\rands)}. $
\end{proof}


For the case when $ \dualopApprox \neq \JorLa $, a change of basis can be used to obtain $ \JorLa = P^{-1}\dualopApprox P $, where $ P $ is the projection map. There are two challenges in performing the above analysis for $\JorLa$ so obtained: first, the leading entries of Jordan blocks do not directly correspond to the centers $\{ c_1,\dots,c_\ncent\}$ which was the case for $ \dualopApprox = \JorLa $. Second, although we can obtain the transformation of the row vector (\ref{eq:rowvec}) using the projection map $P$, we can no longer arrive at the definition of the probability $p_{\e}$ as in  (\ref{ppp}). The existence of the similarity transform hints that the results in Theorems \ref{thm:r1}-\ref{thm:r2} should hold for any $ \dualopApprox$, but the mathematical tools utilized in the paper seem to be insufficient to prove them. However, we present some empirical evidence for these claims for when $ \dualopApprox \neq \JorLa $  in the empirical results section.%Section \cite{Maske18_ACC}.


\subsection{Generalizing Across Similar Spatiotemporally Evolving Systems} \label{sec:egp}
Building on the Kernel Observers method, let us introduce Evolving Gaussian Processes (E-GP). The primary novelty in this method of generating a model is learning an $\dualopApprox$ matrix for \emph{multiple} systems. The ultimate goal of this research would be to generate highly efficient machine learning models that can be used instead of the costly numerical simulations for design and autonomy purposes. This would be a major success for the design and control of complex physical systems, such as soft robotics, as they would significantly reduce the cost and resources required in simulations. The ability to generalize across different physical situations, is critical. This is a difficult problem, as it requires that the model have the capability to actually learn the underlying physics and not just input-output relationships. For example, in the context of fluid flows, these models must be able to predict fluid dynamics at different conditions (such as Reynolds number) than the training data. E-GP, as far as the authors know, was the first machine learning method to generalize across spatiotemporally evolving systems of such complexity using end-to-end data.

We found that the class of functional evolutions $\mathbb{F}$ defined by linear Markovian transitions in a RKHS is still sufficient to model the nonlinear Navier Stokes equations which govern fluid dynamics, since the unknown map $\fmap$ allows us to model highly nonlinear dynamics in the input space. However, we do expect that phenomena such as bifurcation or turbulence will require nonlinear mappings $\fspace$. There are three steps to generate an E-GP model:

\begin{enumerate}
	\item After picking the kernel and estimating the bandwidth hyperparameter $\s$ (we utilize the maximum likelihood approach, although other approaches can be used), find an optimal basis vector set $\shCent$ using the algorithm in \cite{csato2002sparse}.
	\item Use Gaussian process inference to find weight vectors for each time-step in the training set(s), generating the sequence $\weight_\tindex, \tindex=1,\dots,T$ for each system. A uniform time-step makes the next step easier but can be worked around for non-uniform data sets
	\item Using the weight trajectory, use matrix least-squares with the equation $\dualopApprox [\weight_1,\weight_2, ...,\weight_{T-1}] = [\weight_2,\weight_3,...,\weight_T]$ to solve for $\dualopApprox$.
	\item To generate a multi-system model, concatenate the weight trajectories from each similar system in the least-squares computation of $\dualopApprox$. That is, let $W_{\theta} = [\weight_1^{(\theta)},\weight_2^{(\theta)}, ...,\weight_{n-1}^{(\theta)}]$ and $W_{\theta}' = [\weight_2^{(\theta)},\weight_3^{(\theta)}, ...,\weight_n^{(\theta)}]$ be the weight trajectory and next weight trajectory for some parameter . Then we solve the least-squares problem $\dualopApprox [W_{\theta_1},\dots,W_{\theta_n}] = [W_{\theta}',\dots,W_{\theta_n}']$
\end{enumerate}

For the sake of defining when it is appropriate to expect this method to be able to generalize across different spatiotemporally evolving systems, we shall define what it means for two fluid flows to be \emph{similar}. In configuring a fluid dynamics simulation, a set of quantifiable parameters are defined. Two dynamical fluid systems $S_1$ and $S_2$ are considered \emph{similar} if they have  the same configuration of parameters and differ only in the value of at most one parameter. Furthermore, we require that the parameter be continuously variable, and that any observable quantity in the domain of the system vary smoothly as that parameter varies from its value in $S_1$ to its value in $S_2$. For example, for fluids flowing past identical cylinders, the Reynolds number associated with the free stream velocity may be varied to produce similar systems. However, to replace the system's cylinder with a triangle would be to qualitatively change the configuration of the system parameters, and thus would produce a non-similar system.

Unlike neural networks, the weights in an E-GP do not exist in some abstract, difficult-to-comprehend space, but are associated with kernel centers in specific locations in the domain. We refer to this attribute of E-GPs as the \emph{spatial encoding} property. This property is an extremely valuable tool for gaining insight into how the learned model works. Some examples:
\begin{enumerate}
	\item By plotting which kernel centers are associated with which invariant subspaces in the transition matrix, one can visualize where the eigenfunctions are found and how the dynamic modes are separated spatially.
	\item By plotting arrows from center $c_j$ to $c_i$ for each of the largest elements $\hat a_{ij}$ of $\dualopApprox$, one can visualize how different areas of the domain influence each other's evolution.
	\item By performing an eigendecomposition of the $\dualopApprox$ matrix, and transforming the eigenvectors back from the weight space to the function space, one can obtain the Koopman modes (and associated eigenvalues) of the system (see next section).
\end{enumerate}


\subsection{Spectral Analysis of Evolving Gaussian Process Model}

We would be remiss not to examine our methods in light of Koopman operator theory, which has served as a major source of inspiration for number of new methods in analyzing dynamical systems in the last decade, especially within the Computational Flow Dynamics (CFD) community. Here we present results which show a direct connection between the Koopman modes, eigenfunctions, and eigenvalues and the spectral decomposition of the transition matrix in our model. In fact, in our final theorem, we show that the eigenvalues of our model are a subset of the eigenvalues of the infinite-dimensional Koopman operator, the eigenvectors transformed to the input space are congruent in shape to the Koopman modes, and the eigenfunctions are identical. These results have allowed us to construct new methods for sensor placement under even more difficult conditions than described previously -- specifically, the situation of one (or a few) sensors attached to moving agents or robots.

For a general dynamical system $f_{\tindex+1} = \mathbb{F}(f_{\tindex})$ defined on a state space (for us, an RKHS $f\in\fspace$), we can define an arbitrary, vector-valued \emph{observable} $g : \fspace \to \R^{\nsamp}$. Note that the space of observables $g$ is a vector space. The Koopman operator $U$ is defined to be the operator on the space of observables such that:
\begin{align} \eqlabel{koopman_operator}
U g(f_{\tindex}) = g(\mathbb{F}(f_{\tindex})) = g(f_{\tindex+1})
\end{align}
This operator is clearly linear from its definition, and thus it is reasonable to examine its spectral properties. The special observables $\phi : \fspace \to \C$ that have the property
\begin{align} \eqlabel{koopman_eigenfunctions}
U \phi(f_{\tindex}) = \phi(\mathbb{F}(f_{\tindex})) = \phi(f_{\tindex+1}) = \lambda \phi(f_{\tindex})
\end{align}
are the eigenfunctions of $U$, and the associated $\lambda$ are the eigenvalues. Suppose now we have a vector-valued observable $u(\fspaceEl,x)$, where $x\in\dom$ and $\fspaceEl\in\fspace$.

\begin{definition}
	The Koopman mode $s(x)$ at isolated eigenvalue $\lambda$ of algebraic multiplicity 1 is the projection of $u(f,x)$ onto the eigenfunction $\phi_{\lambda}(\fspaceEl)$ of $U$ at $\lambda$. \cite{mezic2013analysis}
\end{definition}

As previously shown by Rowley in 2009 \cite{rowley2009spectral}, the modes produced by the Dynamic Mode Decomposition (DMD) algorithm constitute a subset of Koopman modes. Mezic (2013) \cite{mezic2013analysis} showed that there exists, in principle if not in practice, a rigorous method for computing the full set of Koopman modes by a method known as generalized Laplace analysis (GLA). We have generated a number of results interpreting the E-GP model in terms of Koopman operator theory, culminating in the proof that the eigenvalues and eigenvectors of $\dualopApprox$ are related to the Koopman eigenvalues and modes.

\begin{proposition}\label{thm:ApproxObsv}
	Let $\fspace$ be a RKHS with  an approximate feature space $\fspaceApprox$, and let $u(\fspaceEl,x)$ be an observable in the Koopman sense with respect to the dynamical system $f_{\tindex+1} = \mathbb{F}(f_{\tindex})$ in $\fspace$. Then $\hat u(\fspaceEl,x) \coloneqq u(\fspaceApproxEl,x)$, where $\fspaceApproxEl$ is the projection of $\fspaceEl\in\fspace$ onto $\fspaceApprox$, is also an observable.
	%Given a RKHS $\fspace$ and an approximate feature space $\fspaceApprox$ which has finite dimension $\ncent$, the projection $\fmapApprox : \fspace \to \R^\ncent$ from the RKHS to the dual space of $\fspaceApprox$ is an observable in the Koopman sense with respect to the dynamical system $f_{\tindex+1} = \mathbb{F}(f_{\tindex})$
\end{proposition}


This follows from the fact that the projection from the function space to its subspace is well-defined when the $\fmapApprox_i$ are independent. Now, Koopman modes of observables are of interest because they are akin to the eigenvector expansions utilized in linear dynamics. If we separate the Koopman operator into $U = U_s + U_r$ where $U_s$ has a pure point spectrum with $k$ points and $U_r$ has a pure continuous spectrum, then we can write,
\begin{align} \eqlabel{spectral_expansion}
U^t u(\fspaceEl,x) = u^{\ast}(\fspaceEl,x) + \sum_{j=1}^k \lambda_j^t \phi_j(\fspaceEl) s_j (x)  +  U_r^t u(\fspaceEl,x)
\end{align}
where $u^{\ast}(x)$ represents the time-averaged of part of the field, which corresponds with $\lambda=1$ (see GLA in \cite{mezic2013analysis}). The continuous-spectrum component is usually discarded/neglected since it represents the part of the field that is genuinely aperiodic (or chaotic) in time, which could be modeled as a stochastic process \cite{mezic2013analysis}. Now, from this expansion we can prove that:

\begin{proposition}\label{prop:ApproxModes}
	Let $u(\fspaceEl,x)$ and $\hat u(\fspaceEl,x)$ be observables as in Proposition \ref{thm:ApproxObsv}, and $s_j(x)$ be the Koopman modes associated with the projection of the former onto the eigenfunctions $\phi_j$ of $U$ at $\lambda_j$. Then the Koopman modes associated with $\hat u$ are:
	\begin{align}
	\hat s_j(x) = \frac{\phi_j(\fspaceApproxEl)}{\phi_j(\fspaceEl)} s_j(x)
	\end{align}
\end{proposition}
\begin{proof}
	Using the spectral expansion and the definition of the observables, we have:
	$$U^t \hat u(\fspaceEl,x) = U^t u(\fspaceApproxEl,x) $$
	$$ \hat u^{\ast}(\fspaceEl,x) + \sum_{j=1}^k \lambda_j^t \phi_j(\fspaceEl) \hat s_j (x)  +  U_r^t \hat u(\fspaceEl,x) = u^{\ast}(\fspaceApproxEl,x) + \sum_{j=1}^k \lambda_j^t \phi_j(\fspaceApproxEl) s_j (x)  +  U_r^t u(\fspaceApproxEl,x)$$
	Since this must be true for all $t$, the terms must match, and the hypothesis follows.% see that this must be the spectral expansion of $\hat u(\fspaceEl,x)$
\end{proof}


Note that this means the modes of the two observables are identical in shape (only differing by a multiplicative constant). In the exceptional case that $\phi_j(\fspaceEl)=0$, the GLA method is unable to compute $s_j (x)$ anyway, so that is not an issue for this proposition. The final step in our analysis is to connect the Koopman modes with the spectral decomposition of  our model's $\dualopApprox$ operator in the dual space.

\begin{theorem}\label{thm:DualApproxModes}
	In an E-GP or KO model of the dynamical system $ f_{\tindex+1} = \sysop f_{\tindex}$,
	\begin{enumerate}
		\item The eigenvalues of $\dualopApprox$ are a subset of the eigenvalues of the Koopman operator.
		\item The eigenfunctions of the Koopman operator in the dual space correspond with a subset of the eigenfunctions of the Koopman operator on $\fspaceEl_0$, that is $\hat\phi_j(\weight_{\tindex}) = \phi_j(f_{\tindex})$.
		\item If the observable $u(\fspaceEl,x)$ is the evaluation operator, $u(\fspaceEl,x) \coloneqq \fspaceEl(x)$, then the eigenvectors $v_j$ of $\dualopApprox$ are related to the Koopman modes of the observable by:
		\begin{align}
			s_j (x) = \frac{\phi_j(\fspaceEl)}{\phi_j(\fspaceApproxEl)} \obsMatRow(x) \cdot v_j
		\end{align}
		where $\obsMatRow(x)$ is the feature map of our model as a row vector.
	\end{enumerate} 
\end{theorem}
\begin{proof}
	It should be clear that, as long as the projection onto the approximate feature space is well defined, that $P(f_{\tindex}) \coloneqq \weight_{\tindex} $ is an observable. Then if we let $\phi_j(\fspaceEl) = \langle P(\fspaceEl), q_j \rangle$, where $q_j$ are eigenvectors of the adjoint $\dualopApprox^{\ast}$ (that is, $\dualopApprox^{\ast} q_j = \bar \lambda_j q_j$), then $\phi_j$ is an eigenfunction of the Koopman operator in $\fspace$ since $U \phi_j(f_{\tindex}) = \langle P(f_{\tindex+1}), q_j \rangle = \langle \weight_{\tindex+1}, q_j \rangle = \langle \dualopApprox \weight_{\tindex}, q_j \rangle =  \langle \weight_{\tindex}, \dualopApprox^{\ast} q_j \rangle =  \lambda_j \langle \weight_{\tindex}, q_j \rangle =  \lambda_j \phi_j(f_{\tindex})$. This shows that:
	\begin{enumerate}
		\item The eigenvalues of $\dualopApprox$ correspond with that of the Koopman operator.
		\item The eigenfunctions of the Koopman operator in the dual space, known to be $\hat\phi_j(\cdot) = \langle \cdot, q_j \rangle$, correspond with the eigenfunctions of the Koopman operator in $\fspace$.
	\end{enumerate}
	In the case that $u(\fspaceEl,x) \coloneqq \fspaceEl(x)$, we have the relationship $\hat u(\fspaceEl,x) = \fspaceApproxEl(x) = \obsMatRow(x) \cdot \weight(\fspaceEl)$ according to the formulation of our model. Now, it is well known that the spectral expansion of a finite linear system is:
	$$ \weight_t = \sum_{j=1}^{\ncent} \lambda_j^t \hat\phi_j(\weight_0) v_j$$
	where $v_j$ are the eigenvectors of the transition matrix. Therefore, we have:
	$$ U^t \hat u(\fspaceEl_0,x) = U^t \left( \obsMatRow(x) \cdot \weight(\fspaceEl_0) \right) = \obsMatRow(x) \cdot \weight_t = \obsMatRow(x) \cdot \left( \sum_{j=1}^{\ncent} \lambda_j \hat\phi_j(\weight_0)  v_j \right) = \sum_{j=1}^{\ncent} \lambda_j \phi_j(\fspaceEl_0) \obsMatRow(x) \cdot v_j$$
	
	Comparing this to the spectral expansion of $\hat u(\fspaceEl,x)$, we see (letting $\lambda_1=1$) that:
	\begin{enumerate}
		\setcounter{enumi}{2}
		\item $\hat u^{\ast}(\fspaceEl,x) = \obsMatRow(x) \cdot v_1$, $\hat s_j(x) = \obsMatRow(x) \cdot v_j$, and that there is no continuous spectrum component. The hypothesis now follows from Proposition \ref{prop:ApproxModes}.
	\end{enumerate}
	
\end{proof}
In the end, we have established a direct connection between the spectral decomposition of the transition matrix in the dual space of the approximate feature space and the Koopman modes, eigenfunctions, and eigenvalues. 
\begin{corollary}\label{cor:ModesApprox}
	Suppose, given an $\e>0$, we are able to find an approximate feature space $\fspaceApprox$ such that for all $\fspaceEl\in\fspace$ there exists $\fspaceApproxEl\in\fspaceApprox$ such that $\|\fspaceEl - \fspaceApproxEl\| < \e$. Then, if $\phi_j(\fspaceEl) \neq 0$, there exists an approximate feature space such that $\obsMatRow(x) \cdot v_j$ is arbitrarily close to the Koopman mode $s_j(x)$ (where $v_j$ is an eigenvector of the dual space transition matrix $\dualopApprox$).
\end{corollary}
\begin{proof}
	Since $\phi_j$ is continuous, we can make $|\phi_j(\fspaceEl) - \phi_j(\fspaceApproxEl)|$ arbitrarily small, which means if $\phi_j{\fspaceEl} \neq 0$ we can make $\frac{\phi_j(\fspaceEl)}{\phi_j(\fspaceApproxEl)}$ arbitrarily close to 1. From Theorem \ref{thm:DualApproxModes} and the fact that $s_j\in\fspace$ means $s_j$ is bounded, we can conclude that $\obsMatRow(x) \cdot v_j$ can be made arbitrarily close to $s_j(x)$ everywhere in $\dom$. %choose $\delta$ such that $\|\fspaceEl - \fspaceApproxEl\| < \delta$ implies $|\phi_j(\fspaceEl) - \phi_j(\fspaceApproxEl)| < 
	
	% neeed to actually say why the phi are continuous
\end{proof}
In essence, this says that if we can find a close-enough approximate feature space, then the eigenvectors of the transition matrix in the dual space correspond exactly with the Koopman modes in the input space.




\subsubsection{Invariant Subspaces}

One way of viewing the invariant subspaces concept is to say that information contained in an invariant subspace never leaves that invariant subspace. We hypothesize that the kernel centers associated with the invariant subspaces of a spatiotemporally evolving system are generally associated with spatial regions in the domain (and not just homogeneously spread all over and or mixed with the other invariant subspaces). This hypothesis makes sense both physically and mathematically. In physics, the \emph{principle of locality} states that an object is only directly influenced by its immediate surroundings \cite{berkovitz2007action}. If this is the case (and there is no reason to believe that it is not, apart from certain quantum dynamics situations), and the E-GP model accurately captures the physics of the system, then information (measurable phenomena) may only travel continuously from one point in the domain to another. Mathematically, since a value at any one point in the domain is influenced by the weights of multiple nearby centers, we would expect nearby centers to be connected dynamically, unless separated by ``plains'' where the values are indistinguishable from noise.

In an ideal case, the Jordan form of a $n\times n$ matrix $\dualopApprox$ is block diagonal, and therefore gives a decomposition of the $n$ dimensional Euclidean space into clearly separated invariant subspaces of $\dualopApprox$. The cyclic index, which can be found by counting the geometric multiplicities of eigenvalues in $\dualopApprox$, gives the number of invariant subspaces. In practice, data-driven approximations of $\dualopApprox$ rarely give such easily interpretable properties. This fact drives the need for an algorithm that can divide the system into invariant subspaces even when the boundaries between such spaces are not mathematically precise. This algorithm can be thought of as a `soft' Jordan decomposition.

Each block in the Jordan normal form has a set of corresponding eigenvectors and an eigenvalue with geometric multiplicity. When we transform the former back into the domain space, we obtain complex-valued functions which are the Koopman modes of the system. These provide an image of what kind of structures we see in the dynamics. The eigenvalues describe the frequency with which these structures oscillate between their real and imaginary forms, as well as their exponential growth or decay in magnitude. %In this section, we demonstrate our method on systems with eigenvalues primarily on the unit circle (neither growing nor decaying).


\subsubsection{k-Invariant Subspaces Clustering}
In response to the need for an algorithm that can separate invariant subspaces in the linear model of a system generated by data, we have developed what we call ``$k$-invariant subspaces clustering''. The intuition behind our algorithm is to replace the Euclidean distance in the well-known $k$-means algorithm with a different metric of ``nearness'', namely one corresponding with the dynamic connections in the space. The $\dualopApprox$ matrix provides easy access to these: its rows $\dualopApprox_{i\ast}$ indicate which centers inform the i\textsuperscript{th} value of $\weight_{\tindex+1}$, and its columns $\dualopApprox_{\ast j}$ indicate what centers will be informed by the j\textsuperscript{th} value of $\weight_{\tindex}$. However, these values do tend to be biased towards the eigenmodes with higher frequencies (that is, those whose eigenvalues have a greater polar angle) and those which grow exponentially. To  control for this, we chose to modify the eigenvalues of the matrix in the following way: we (1) zeroed any eigenvalue that is clearly inside (not on) the unit circle, (2) unitized the remaining eigenvalues, and (3) adjusted the frequency of the remaining eigenvalues on the unit circle to either $\pm \frac{\pi}{4}$. If the eigen-decomposition of the original was $\dualopApprox = UDU^{-1}$, then we can reconstruct a new matrix with our modified eigenvalues $\bar D$ as $\bar A = U\bar D U^{-1}$.

Much like the pairwise-squared deviations of points formulation of the $k$-means clustering problem, we can now write our problem as:
$$\arg\max_S \sum_{i=1}^k \frac{1}{2|S_i|} \sum_{\substack{x_i \neq x_j \\ x_j,x_i\in S_i}} \bar A_{ij}^2 $$

This problem can be solved with Algorithm \ref{kinvsub}.

\begin{figure}[t!]
	\begin{algorithm}[H]
		\caption{$k$-Invariant Subspaces Algorithm}
		\label{kinvsub}
		\begin{algorithmic}
				\WHILE{clusters have changed}   
				\FOR{each center $i$}
				\STATE {Find cluster $k$ which maximizes the score} $ \frac{1}{|S_k|} \left( \|\bar A_{i, S_k\setminus \{i\} } \|^2 + \|\bar A_{S_k\setminus \{i\},i} \|^2 \right)$
				\STATE Reassign center $i$ to cluster with highest score
				\ENDFOR
				\ENDWHILE   
				\STATE \textbf{return} clusters
		\end{algorithmic}
	\end{algorithm}
	\vspace{-0.2in}
\end{figure}



Note the differences between this and the $k$-means clustering algorithm: first, we are \emph{maximizing} since the terms represent influence rather than distance. Secondly, in the possible case that $|S_k|=0$, we make the total value zero in order to avoid division by zero. Thirdly, we exclude centers' influence on themselves from the score by taking $S_k\setminus\{i\}$.

This algorithm can be repeated as many times as desired with different random initial conditions, and the result which produces the highest score retained.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%\input{sec_results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Empirical Results}
We begin with numerical results obtained for determining sensing locations by application of kernel observers to the prediction of spatiotemporal functions. The highlight here is a set of results on sensing global ocean temperatures with information from just a few locations using the AVHRR satellite data. This is followed by an application of E-GP in predicting spatiotemporal functions. We include results in predicting weed growth in simulated agricultural fields. The application of E-GP to model flow past a cylinder at different Reynolds numbers is explored in ``\nameref{sb:cfd}''. We conclude the results section with a comparison of eigenvalues and Koopman modes computed from E-GP to those of DMD. 


\subsection{Sensing Locations for Synthetic Data Sets}\label{sec:exp}
The goal of this experiment is to investigate the dependency of the observability of system \eqref{k_measure} on the shaded observation matrix and the lower bound presented in Proposition \ref{prop:2}. The domain is fixed on the interval $\dom = [0,2\pi]$. First, we pick sets of points $\shCent^{(\setind)} = \{c_1,\dots,c_{\ncent_{\setind}}\}, \ c_{\centind}\in\dom$, $\ncent=50$, and construct a dynamics matrix $\dualop = \JorLa \in {\R^{\ncent \times \ncent}}$, with cyclic index $5$.  We pick the RBF kernel $\kernel(x,y) = e^{-\|x-y\|^2/2\s^2}$, $\s=0.02$. Generating samples $\sampSet=\sampSetLong$, $x_{\sampind}\in\dom$ randomly, we compute the $\minmeas$-shaded property and observability for this system. Figure \ref{fig:kobs_small} shows how shadedness is a necessary condition for observability, validating Proposition \ref{prop:1}: the slight gap between shadedness and observability here can be explained due to numerical issues in computing the rank of $\Obs_{\Tset}$. 
 
Next, we  consider a system with a cyclic index $\minmeas=18$ to verify random sensor placement results. We constructed the measurement operator $\empK$ using the heuristic in Remark \ref{rem:1} (Algorithm \ref{alg:samples}), and random sensor selection to generate the sampling locations $\sampSet$. These results are presented in Figure \ref{fig:sample_observability}. The plot for random sampling which has been averaged over $ 100 $ runs, resembles a c.d.f function of an exponential distribution $ F(X=x)=1-\exp(-\lambda x) $. This verifies the claim made in Theorem \ref{thm:r2}, as the probability of becoming unobservable decays exponentially with the number of sensors placed. Also, fitting an exponential distribution, we found that the mean $ \lambda^{-1}$ comes close to the ratio $ {\rands}/{p} $, which is the expected number of randomly placed sensors required for observability as per Theorem \ref{thm:r1}. Note that observability is not achieved if the number of samples $\nsamp < \minmeas$, which is experimental evidence of the result in Proposition \ref{prop:2}. 



\subsection[Comparison with Nonstationary Kernel Methods]{Comparison With Nonstationary Kernel Methods on Real-World Data}\label{sec:comparison}

We use three real-world datasets to evaluate and compare the kernel observer with the two different lines of approach for non-stationary kernels  discussed in section on related work. %\ref{sec:related}. 
For the Process Convolution with Local Smoothing Kernel (PCLSK) and Latent Extension of Input Space (LEIS) approaches, we compare with NOSTILL-GP \cite{garg2012AAAI} and \cite{pfingsten2006nonstationary} respectively, on the Intel Berkeley, Irish Wind and Ozone data-sets. 
% Each of these methods were trained on a particular set of data, and the inferred model was used to perform predictions. 

Model inference for the kernel observer involved three steps: 1) picking the Gaussian RBF kernel $\kernel(x,y) = e^{-\|x-y\|^2/2\s^2}$, a search for the ideal $\s$ is performed for a sparse Gaussian Process model (with a fixed basis vector set $\shCent$ selected using the method in \cite{csato2002sparse}. %\footnote
{For the data set discussed in this section, the number of basis vectors were equal to the number of sensing locations in the training set, with the domain for input set defined over $ \R^2 $}; 2) having obtained $\s$, Gaussian process inference is used to generate weight vectors for each time-step in the training set, resulting in the sequence $\weight_\tindex, \tindex\in\{1,\dots,T\}$; 3) matrix least-squares is applied to this sequence to infer $\dualopApprox$ (Algorithm \ref{alg:egp_trans}). For prediction in the autonomous setup, $\dualopApprox$ is used to propagate the state $\weight_{\tindex}$ forward to make predictions with no feedback, and in the observer setup, a Kalman filter (Algorithm \ref{alg:egp_inf}) with $\nsamp$ determined using Proposition \ref{prop:2}, and locations picked randomly, is used to propagate $\weight_{\tindex}$ forward to make predictions. We also compare with a baseline GP (denoted by `original GP'), which is the sparse GP model trained using all of the available data. 

Our first dataset, the Intel Berkeley research lab temperature data, consists of 50 wireless temperature sensors in indoor laboratory region spanning 40.5 meters in length and 31 meters in width ({\url{http://db.csail.mit.edu/labdata/labdata.html}}). Training data consists of temperature data on March 6th 2004 at intervals of 20 minutes (beginning 00:20 hrs) which totals to 72 timesteps. Testing is performed over another 72 timesteps beginning 12:20 hrs of the same day. Out of 50 locations, we uniformly selected 25 locations each for training and testing purposes. Results of the prediction error are shown in box-plot form in Figure \ref{fig:intel_boxplots} and as a time-series in Figure \ref{fig:intel_comp}, note that `Auto' refers to autonomous set up. Here, the cyclic index of $\dualopApprox$ was determined to be $2$, so $\nsamp$ was set to $2$ for the kernel observer with feedback. Note that here, even the autonomous kernel observer outperforms PCLSK and LEIS overall, and the kernel observer with feedback with $\nsamp = 2$ significantly outperforms all other methods, which is why we did not include results with $\nsamp > 2$. 


The second dataset is the Irish wind dataset, consisting of daily average
wind speed % (in knots = 0.542 m/s) 
data collected from year
1961 to 1978 at 12 meteorological stations in the Republic
of Ireland ({\url{http://lib.stat.cmu.edu/datasets/wind.desc}}). The prediction error  is in box-plot form in Figure \ref{fig:irish_boxplots} and as a time-series in Figure \ref{fig:irish_comp}. Again, the cyclic index of $\dualopApprox$ was determined to be $2$. In this case, the autonomous kernel observer's performance is comparable to PCLSK and LEIS, while the kernel observer with feedback with $\nsamp = 2$ again outperforms all other methods. 

Finally, the Ozone dataset measures ozone concentration (in parts per billion) measured at 60 stations by the United States Environmental Protection Agency \cite{li2006spatiotemporal} across USA. Due to missing measurements, we only selected data from
year 1997 to 2013 for training and evaluation. For each station, we averaged ozone concentration over a period of three months, resulting in four quarters per year.
Out of 60 sensor locations, we uniformly selected 30 for training and the remaining locations for testing purposes. The prediction error results are presented in box-plot form in Figure \ref{fig:ozone_boxplots} and as a time-series in Figure \ref{fig:ozone_comp}. Here, the cyclic index of $\dualopApprox$ was determined to be $1$. In this case, the performance of autonomous kernel observer is comparable to PCLSK and LEIS, with kernel observer with feedback with $\nsamp = 1$ performing the best. Table \ref{tab:timing} reports the total training and prediction times associated with PCLSK, LEIS, and the kernel observer. We observed that, 1) the kernel observer is an order of magnitude faster than the competing methods, and 2) even for small sets, competing methods did not scale well.


\begin{table}[h]
	\centering
	\caption{Total training and prediction times for Figs. \ref{intel} and \ref{irish} } \label{tab:timing}
		\begin{tabular}{c|ccc}
		\toprule
			{\bf }  & {\bf Intel } & {\bf Irish } &  {\bf Ozone}  \\
			& Berkeley & Wind & \\
			\midrule
			\emph{Data Size}        & 25-72 & 12-36  & {30-68} \\ 
		    (\emph{bases}-\emph{timesteps})                 &       & & \\ \hline
			Kernel Observer         & 2.1 sec & 0.1 sec & 1.61 sec \\
			PCLSK             & 121.4 sec & 7.0 sec & 91.90 sec \\
			LEIS             & 43.8 sec & 2.8 sec & 37.41 sec\\
		\bottomrule
		\end{tabular}
\end{table}


\subsection{Prediction of Global Ocean Surface Temperature}\label{sec:avhhr}

We analyzed the feasibility of our approach on a very large dataset from the National Oceanographic Data Center: the $4$ km AVHRR Pathfinder project, which is a satellite monitoring global ocean surface temperature (Figure \ref{fig:Rawpathfinder} shows the raw data). This dataset is challenging, with measurements at over $37$ million possible coordinates, but with only around 3-4 million measurements available per day, which means a lot of missing data. The goal was to learn the day and night temperature models on data from the year 2011, and then to monitor the system through the year 2012. Success in monitoring would demonstrate two things: 1) the modeling process can capture spatiotemporal trends that generalize across years, and 2) the observer framework allows us to infer the state using a number of measurements that are an order of magnitude fewer than available. Note that due to the size of the dataset and the high computational requirements of the nonstationary kernel methods, a comparison with them was not pursued. To build the autonomous kernel observer and general kernel observer models, we followed the same procedure outlined in Section ''\nameref{sec:comparison}'', but with $\shCent=\shCentLong$, $c_{\centind}\in\R^{2}, \ |\shCent| = 300$. The Kalman filter for the general kernel observer model  used $\nsamp \in \{250,500,1000\}$ at random locations to track the system state given a random initial condition $\weight_0$. As a fair baseline, the observers are compared to training a sparse GP model (labeled `original')  on approximately $400,000$ measurements per day. %, to get a fair comparison. 
Figure \ref{fig:pathfinder} is an estimate of global ocean surface temperatures obtained using autonomous kernel observer.
Figures \ref{fig:time_series_day} and \ref{fig:time_series_night} compare the autonomous and feedback approach with $1,000$ samples to the baseline GP; here, it can be seen that the autonomous does well in the beginning, but then incurs an unacceptable amount of error when the time series goes into 2012, i.e. where the model has not seen any training data, whereas FKO does well throughout. 
Figures %13(e)%
\ref{fig:pathfinder_errors_boxplots_day} 
and %13(f) %
\ref{fig:pathfinder_errors_boxplots} 
show a  comparison of the RMS error of estimated values from the real data.
This figure shows the trend of the observer getting better and better state estimates as a function of the number of sensing locations $\nsamp$. Note that we checked the performance of training a GP with only $1,000$ samples as a control, but the average error was about 10 Kelvins, i.e. much worse than FKO.
The time required for using the kernel observer is significantly less than retraining the model every time step; see Figures %13(g)-13(h). 
 \ref{fig:pathfinder_tr_times_boxplots_day}-\ref{fig:pathfinder_tr_times_boxplots_night}.
 
\textbf{Weather Anomaly in 2012:} We further investigated the poor performance of the autonomous kernel observer in the year 2012 as observed in Figures \ref{fig:time_series_day} and \ref{fig:time_series_night}. Clearly, the prediction error blows up at the start of May in the year 2012, indicating that the autonomous model trained using the data from 2011 does well in capturing the annual weather dynamics up to the month of May 2012. We turned our attention towards the weather in May 2012, as changes in ocean temperatures are directly related to the weather. As we guessed, severe weather conditions were reported on the east coast of United States in May 2012, and this anomaly continued over the period of May to June 2012. Here, the apparent poor performance of autonomous kernel observer can actually be a useful indicator in detecting the anomalous behavior, as was the case with the ocean temperature in May 2012 which had deviated from the normal weather dynamics observed in the year 2011 in which no severe weather anomalies were reported. Further, we identified the locations at which the prediction error was two standard deviations above the mean error. These error locations are plotted in Figure \ref{fig:anomaly}. Error locations on 6-7th May coincide with the severe weather onset on the east coast of United states and that of 28-29th May were along the track of storm Beryl approaching the eastern coastline. This shows that the autonomous kernel observer model captures the dynamics of spatiotemporal evolution, and has the potential of identifying current behavior as anomalous to that observed in the training set.
 
 
\begin{figure}
\centering
\begin{subfigure}[t]{0.48\textwidth}
	\includegraphics[width=\linewidth]{"Figure 9a.pdf"}
	\caption{Shaded vs. observability}
    	\label{fig:kobs_small}
\end{subfigure}

\begin{subfigure}[t]{0.48\textwidth}
	\includegraphics[width=\linewidth]{"Figure 9b.pdf"}
	\caption{Heuristic vs. random}
	\label{fig:sample_observability}
\end{subfigure}

\caption{Kernel observability results.}
\end{figure} 


\begin{figure}
\centering
\begin{minipage}{0.8\textwidth}
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=\linewidth]{"Figure 10a"} \label{fig:intel_boxplots}
		\caption{Error (boxplot)}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=\linewidth]{"Figure 10b"} \label{fig:intel_comp}
		\caption{Error (time-series)}
	\end{subfigure}
	\caption{Comparison of kernel observer to PCLSK and LEIS methods on Intel Berkeley dataset.}     \label{intel}
\end{minipage}\\

\begin{minipage}{0.8\textwidth}
	
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=\linewidth]{"Figure 11a"} \label{fig:irish_boxplots}
		\caption{Error (boxplot)}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=\linewidth]{Figure 11b} \label{fig:irish_comp}
		\caption{Error (time-series)}
	\end{subfigure}
	\caption{Comparison of kernel observer to PCLSK and LEIS methods on Irish Wind dataset.}\label{irish}
\end{minipage}\\

\begin{minipage}{0.8\textwidth}
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=\linewidth]{"Figure 12a"} \label{fig:ozone_boxplots}
		\caption{Error (boxplot)}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=\linewidth]{"Figure 12b"} \label{fig:ozone_comp}
		\caption{Error (time-series)}
	\end{subfigure}
	\caption{Comparison of kernel observer to PCLSK and LEIS methods on Ozone dataset.}\label{ozone}
\end{minipage}
\end{figure}


\begin{figure}
	\centering
	\captionsetup[subfigure]{aboveskip = -12pt}
	\begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13a"}
		\label{fig:Rawpathfinder}
		\caption{Raw Satellite Data}
	\end{subfigure}
	\begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13b"}
		\label{fig:pathfinder}
		\caption{AKO estimate}
	\end{subfigure}
	\begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13c"}
		\label{fig:time_series_day}
		\caption{Error-day (time-series)}
	\end{subfigure}
	\begin{subfigure}[t]{0.42\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13d"}
		\label{fig:time_series_night}
	 	\caption{Error-night (time-series)}
	\end{subfigure}
	 \begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13e"}
		\label{fig:pathfinder_errors_boxplots_day}
		\caption{Error-day (box-plot)}
	\end{subfigure}
	\begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13f"}
		\label{fig:pathfinder_errors_boxplots}
		\caption{Error-night (box-plot)}
	\end{subfigure}
	\begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13g"}
		\label{fig:pathfinder_tr_times_boxplots_day}
		\caption{Estimation time (day)}
	\end{subfigure}
	\begin{subfigure}[t]{0.41\textwidth}
		\includegraphics[width=\linewidth]{"Figure 13h"}
		\label{fig:pathfinder_tr_times_boxplots_night}
		\caption{Estimation time (night)}
	\end{subfigure}	
	\caption{Performance of the kernel observer over AVVHR satellite 2012 data with different numbers of observation locations.}
\end{figure}

\begin{figure*}
    	\centering
	\captionsetup[subfigure]{aboveskip = -12pt}
    	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\linewidth]{"Figure 14a"}
		\label{fig:May6 }
		\caption{6th May}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\linewidth]{"Figure 14b"}
		\label{fig:May7}
		\caption{7th May}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\linewidth]{"Figure 14c"}
		\label{fig:May28}
		\caption{28th May}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\linewidth]{"Figure 14d"}
		\label{fig:May29}
		\caption{29th May}
	\end{subfigure}
	\caption{Locations of weather anomaly obtained based on the error between the acutual temperature and the prediction of autonomous kernel observer. Landmass is shown in white and the ocean is in green. Locations marked have error greater than two standard deviations above the mean error. }
	\label{fig:anomaly}
\end{figure*}



\subsection{Predicting evolution of weed density in agricultural fields}\label{sec:weed}

As a proof-of-concept in applying our methods for learning dynamics and/or inferring the state of spatiotemporally-evolving systems, we examined the problem of predicting weed growth in agricultural fields.

Past work has presented detailed analysis of weed growth models, in which measurements of seed bank density for various species of weeds were conducted \cite{Nordby2018, schutte2014common, sellers2003comparative, horak2000growth}. In order to generate data upon which to test our methods, we implemented a weed growth simulation model whose rate of seedling emergence agrees with that found in the above research \cite{McAllistar18IROS}. A Poisson process is utilized to simulate the temporal evolution of emergence events. This assumption is reasonable over the short time scales in which robots may fully weed a field.
\vskip 1em
Other work in the field of crop science \cite{mulugeta1997seed, mulugeta1999seasonal} has shown that the spatial variation in the seed bank density for some species of weeds may be modeled via the Gini Coefficient of Concentration (GCC). This model is accurate for common waterhemp (\textit{Amaranthus tuberculatus}), and thus we found it useful in our simulation of the spatial distribution of the seed bank density. For more reading. see \cite{davis2013seed, werle2014predicting, McAllistar18IROS} regarding the relationship between seed bank emergence patterns and environmental conditions such as temperature and moisture.

The weed growth simulation is based on Bernoulli random variables, operating on a matrix of cells, each $0.8$ m$^2$, comprising a gridded field of $0.4$ hectares, or a cellular automata model \cite{chopard1998cellular}. Seeds emerge from a limited seed bank, forming a binomial distribution over time. The parameters used, summarized in Table \ref{tab:weedparams}, are aligned with the growth model for common waterhemp determined in \cite{mulugeta1997seed}. The initial density of the seed bank in each cell is $S_0$ on average (between $600$ and $1560$ seeds per cell). However, at the start of the simulation, the seed bank density in each cell, $S_0(x, y)$, is chosen so that Gini Coefficient of Concentration (GCC) between all the cells, used to ensure the relative density of weeds aligns with that seen in real experiments, is from $0.31$ to $0.35$, as was determined experimentally in \cite{mulugeta1997seed}. The field is first divided into fifty patches of weeds, with centers chosen uniformly at random, and sizes from zero to twenty cells in each dimension. Each cell has an initial density between zero and twenty percent of $S_0$, chosen uniformly at random. Finally, for each patch of weeds, up to an additional $S_0$ weeds are added to each cell within each patch, so that the density of each patch follows a normal distribution. 

\begin{table}[h]
	\centering
	\caption{Seed Bank Density Parameters} \label{tab:weedparams} 
	\begin{center}
		\begin{tabular}{ | l | l | l | l | l |}
			\hline
			\textbf{Parameter} & GCC         & $S_0$ (seeds/cell)       & Num. of Patches & Patch Size (Cells in X and Y)  \\ \hline
			\textbf{Range}     & [0.31,0.35] & [600,1560] & 50  & [0,20]  \\ \hline
		\end{tabular}
	\end{center}
\end{table}


Upon initialization of the simulation, a certain number of days, $d_0$, are allowed to elapse before weeding starts. The number of emerging weeds in each cell, $N_{{\text{emerge}}}$, is a randomly generated Poisson variable with mean, $\lambda \left( {x,y,t} \right) $, such that $90$ percent of the seed bank, $S\left( {x,y,t} \right)$, emerges in $T_\text{total}$, which is two months. This emergence rate is aligned with past work \cite{Nordby2018,schutte2014common, werle2014predicting, sellers2003comparative, horak2000growth},  which all present measurements of the seed bank densities for various species of weeds, and provide an analysis of weed growth models for these species.

The weed density in each cell, $\zeta \left( {x,y,t} \right) $, grows as seeds emerge from the seed bank. The maximum weed height at each cell, $\delta \left( {x,y,t} \right)$, increases from zero height at a fixed rate $\Gamma$ inches per day.

The main challenge with weeding robots is that they only have access to sparse data about weed density and height, and no data about the seedbank. In fact, the robots can only sense the row that they are in and potentially the adjacent rows on either side. They have no information about the field in locations that have not been visited. Hence, the robots have to try and predict the global weed density given sparse information. This is a great application for the Kernel observer techniques studied in this paper. To demonstrate the proof of concept, we trained a kernel observer model on the weed density data generated by our simulations, so that robots in the field can quickly infer the state of the field globally from partial measurements from a few rows.

We used Radial Basis Function (RBF) kernels with a bandwidth approximately 5 cells (4.5 meters) wide. These were centered throughout the domain using the algorithm in \cite{csato2001sparse}. After training a GP on each snapshot of the data, we obtained a weight vector trajectory. We used linear least squares do determine the best linear transition in the weight space for this trajectory. Below we have included images of system as predicted by feeding forward the initial condition through this linear transition, as a comparison with the original data. The model is able to approximate the weed density growth data very well, with percent error averaging 5\%. These results show the feasibility of modeling weed growth using E-GPs. Ongoing work involves a massive field campaign to collect the weed density data required to learn these models. Such datasets are currently not available, and the TerraSentia robots discussed in Sidebar: Key control problems in agriculture are being used to collect this data.

\begin{figure*}[h]
	\centering
	\subfloat[Snapshot 2]{
		\includegraphics[width=0.23\textwidth]{"Figure 15a"}		}
	\subfloat[Snapshot 28]{
		\includegraphics[width=0.23\textwidth]{"Figure 15b"}		}
	\subfloat[Snapshot 54]{
		\includegraphics[width=0.23\textwidth]{"Figure 15c"}		}
	\subfloat[Snapshot 80]{
		\includegraphics[width=0.23\textwidth]{"Figure 15d"}		}\\
	\subfloat[Snapshot 2]{
		\includegraphics[width=0.23\textwidth]{"Figure 15e"}		}
	\subfloat[Snapshot 28]{
		\includegraphics[width=0.23\textwidth]{"Figure 15f"}		}
	\subfloat[Snapshot 54]{
		\includegraphics[width=0.23\textwidth]{"Figure 15g"}		}
	\subfloat[Snapshot 80]{
		\includegraphics[width=0.23\textwidth]{"Figure 15h"}		}
	
	\caption{Visualization of Weed Density Growth over 20 days, original (a-d), E-GP (e-h)}
	\label{fig:weed_egp}
\end{figure*}






\subsection{Comparison of Eigenvalues and Koopman modes with DMD}

In order to empirically verify our theoretical results, we compared the eigenvalues and Koopman modes derived from $\dualopApprox$ in our E-GP model with the eigenvalues and Koopman modes derived by the well-known Dynamic Mode Decomposition (DMD) algorithm using data from fluid flowing past a cylinder at different Reynolds numbers. The results are presented in figures \ref{fig:cfd_100_modes} and \ref{fig:eigenvalues}. As can be seen, the modes generated by E-GP match those generated by DMD at least as well as E-GP predictions match the original data.


\begin{figure*}[h]
	\centering
	\subfloat[0$^\circ$, real component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16a"}		}
	\subfloat[6$^\circ$, real component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16b"}		}
	\subfloat[12$^\circ$, real component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16c"}		}\\
	\subfloat[0$^\circ$, imaginary component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16d"}		}
	\subfloat[6$^\circ$, imaginary component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16e"}		}
	\subfloat[12$^\circ$, imaginary component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16f"}		}\\
	\subfloat[0$^\circ$, real component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16g"}		}
	\subfloat[6$^\circ$, real component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16h"}		}
	\subfloat[12$^\circ$, real component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16i"}		}\\
	\subfloat[0$^\circ$, imaginary component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16j"}		}
	\subfloat[6$^\circ$, imaginary component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16k"}		}
	\subfloat[12$^\circ$, imaginary component]{
		\includegraphics[width=0.30\textwidth]{"Figure 16l"}		}
	\caption{Primary Koopman Modes of a flow past a cylinder at Reynolds number 100. (a-f) E-GP, (g-l) DMD}
	\label{fig:cfd_100_modes}
\end{figure*}

\begin{figure}[!h]
	\centering
	\subfloat[Re=100]{
		\includegraphics[width=0.48\textwidth]{"Figure 17a"}		}
	\subfloat[Re=300]{
		\includegraphics[width=0.48\textwidth]{"Figure 17b"}		}\\
	\subfloat[Re=600]{
		\includegraphics[width=0.48\textwidth]{"Figure 17c"}		}
	\subfloat[Re=800]{
		\includegraphics[width=0.48\textwidth]{"Figure 17d"}		}\\
	\subfloat[Re=1000]{
		\includegraphics[width=0.48\textwidth]{"Figure 17e"}		}
	\caption{Eigenvalue Comparison between E-GP and DMD at different Reynolds numbers}
	\label{fig:eigenvalues}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







%\input{sec_conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}\label{sec:conclusion}
Machine learning techniques such as Gaussian Process (GP) regression and deep learning are providing increasingly more powerful ways of learning predictive models. For all their power, however, since these techniques are limited by the datasets that they are trained with, their predictions are not always reliable when predicting real-world complex spatiotemporally-evolving phenomena with high variability; years' worth of weather data cannot be a reliable predictor of current weather, nor can data from one farm directly relate to another. Because of this, when engineering complex cyber-physical systems such as team of mechanically weeding robots, engineers have devise ways to supplement the predictions of the machine learning models with real measurements. This is not always immediate when one works in the abstract feature spaces utilized in machine learning models. In this tutorial we presented kernel observers and their extension Evolving Gaussian Processes (E-GP), which are formed by embedding a linear dynamical system in the reproducing kernel Hilbert spaces generated by the GP model. The parameters of the linear dynamical system can be trained to approximately predict the evolution. This leads to powerful and generalizable models, as our results demonstrated in predicting solutions to the Navier-Stokes equations. When supplemented with a predict-and-correct strategy, such as a Kalman filter embedded with the linear dynamical system in the RKHS, the dynamical state of the system can be kept on track with real sensor measurements. This creates a very powerful prediction system that is capable of predicting nonlinear evolution using minimal sensor measurements. We showed that the geometric properties of the linear dynamical system can be utilized to determine sensor numbers and locations. Looking forward, it would interesting to extend the idea to include nonlinear dynamical systems in the feature space, which would improve the capability of the E-GP model. At present, our results on fairly complex datasets demonstrate that feedback with sensors creates a robust monitoring system with the predictions with a simple linear model. The theoretical limits of the tradeoff between improving the model versus increasing the sensing in the context of E-GPs is also an interesting avenue of study. Finally, also we note that deep neural networks have also been applied to the spatiotemporal modeling problem with significant empirical success\cite{tran2015learning}, but because these methods are 1) nonlinear in their parameters, and 2) seem to lack the spatial-encoding properties of some types of kernels, generalizing the analysis considered here for those systems is an interesting open question. As sidebar ``\nameref{sb:featspace}'' indicates, there could be very interesting future work that generalizes the idea of embedding controllers and observers in more advanced features spaces considered in machine learning models. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







\section{Software}
To facilitate implementation of the material presented in this paper we have made an open source code repository. A Matlab version is available at \url{http://daslab.illinois.edu/software.html} or at \url{https://github.com/hkingravi/FunctionObservers} with examples and documentation. In addition, a Python version is available on GitHub at \url{https://github.com/hkingravi/funcobspy}.

\section{ACKNOWLEDGMENTS}
The work presented was supported in part by AFOSR \#FA9550-15-1-0146, %NSF SBIR \#1820332, 
and USDA/NSF CPS grant 2018-67007-28379, and USDA/NSF NRI grant 2019-67021-28989.  We thank EarthSense Inc. (www.earthsense.co) for providing us approval to use Figures \ref{fig:cps} and \ref{fig:terrasentia}. The authors also thank Prof. Stephen Long, Prof. Carl Bernacchi, Prof. Michael Gore, and Prof. Edward Buckler on insights about the phenotyping bottleneck and simulation of plants (\textit{crops-in-silico}), Prof. Adam Davis on inputs on the herbicide-resistant weed crisis, and Prof. Sarah Lovell and Dr. Chinmay Soman on sustainable agricultural production systems and perennial polycultures. We also thank the members of the UIUC Center for Digital Agriculture for their inputs.

%\input{sec_supplementary}

%\section{AUTHOR INFORMATION}
%\mX{Please include a short biography of each author. Please include the mailing address,
%email, telephone number, and fax number of the corresponding author only.}

\clearpage
%\XX{many of hte references have ``gaussian'' rather than ``Gaussian''}
\bibliographystyle{unsrt}
%needs gp_tuotrial
\bibliography{BIB/daslab_all,BIB/daslab_pubs,BIB/ACL_all,BIB/ACL_Publications,BIB/bibtex_database_chowdhary_machine_learning,BIB/cybersees,BIB/Robotics}

\processdelayedfloats
\sidebars


\renewcommand{\thealgorithm}{S\arabic{algorithm}} 
\setcounter{algorithm}{0}







\clearpage
%\input {sidebar_summary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section[Nontechnical summary]{Sidebar: Summary}\label{sb:summary}

This article should be useful for anyone interested using robots in large-scale environments that are changing in time and space. We have used the methods presented here to help teams of robots  monitor and destroy weeds within a field of crops. In general, this article is about modeling and monitoring complex systems that vary in both space and time, given a limited number of agents or sensors providing measurements spread out over a large area. We present a novel method for solving this problem, with several tremendously useful properties. First, it can be easily trained and updated even with large, ``dirty'' data collected at many places at many times. Secondly, this model lends itself well to the kinds of analysis familiar to the controls community, which means that several formerly very challenging problems become much easier: how to predict future evolution, deciding how many sensors are needed and where to place them, and what are the basic structures underneath the system dynamics. As far as we know, the methods presented here are unmatched in their scope and power. A graduate-level mathematical background is recommended for this paper, and an open code repository is provided for ease of implementation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\clearpage
%\input{sidebar_ag}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section[How can control engineers help agriculture?]{Sidebar: Key control problems in agriculture}\label{sb:ag}


Shortage of qualified human labor is a key challenge facing farmers \cite{richards2018immigration,hertz2013there}, leading to smaller profit margins, and preventing the adoption of truly sustainable agricultural practices. Lack of timely available labor was a principle reason behind the tens of millions of dollars of unharvested fruits and vegetables that rotted in California farms in 2017 \cite{guthman2017paradoxes,RN4026}.  Labor shortages can be a major barrier to more sustainable agricultural practices that are more labor intensive.

For example, more sustainable alternatives to prevalent methods of agriculture that would not need large amounts of chemicals and other inputs, such as perennial polycultures (mixed species of fruit- and nut-producing trees and shrubs \cite{lovell2017temperate}, see Figure \ref{fig:polycultures}), are currently impractical at scale with current agricultural equipment. Polyculture systems can leverage co-habitation of mutually beneficial plants (and animals, insects, or microbiomes) to create a more sustainable engineered ecosystem. Labor shortage has become a primary barrier to adoption of this sustainable agricultural alternative \cite{RN4017,RN4018}.  


One way to address the challenges of labor shortages in agriculture is by creating new robotic technology that can work in harsh, uncertain, and dynamically changing field environments. 
Here we outline some of the fundamental challenges in autonomy, estimation, and control that the controls community can help overcome to enable the future of agricultural robotics, and relate it with the problem of spatiotemporal function estimation studied in this paper:

\textbf{Persistent multi-agent autonomy under partial observability}:  The digital farm of the future will employ teams of distributed heterogeneous agents to autonomously manage, optimize, and harvest large acres of diverse crops across the entire season without encumbering humans. This level of autonomy in unstructured field environments is out of reach of the current state-of-the-art which requires constant human monitoring and oversight, especially in the presence of change or unforeseen events. Efficient and reliable control will be central to the success of these robots. Small below-canopy robots (such as Figure \ref{fig:terrasentia} \cite{kayacan2018embedded}) will need to provide precision care including pruning, weeding, and re-seeding without damaging plants or causing soil compaction. Deployed at scale, these robots can not only make large scale organic farming practical, but also enable enhanced breeding through  field-scale phenotyping \cite{kayacan2018embedded,mueller2017robotanist,virlet2017field}. \textit{The big controls challenge here is in making decisions over large spatiotemporal scales with information obtained from a few stationary and mobile sensors which can only partially observe the environment at any given time}. The work pursued in this paper lays a foundation towards this problem by enabling a team of agents to estimate the varying state of the environment. 

\begin{figure}
\includegraphics[width=\textwidth]{"Figure S1"}
\caption{The TerraSentia robots developed by Chowdhary's group at UIUC and commercialized by EarthSense inc. Agricultural robots such as these present exciting possibilities for distributed agricultural management with teams of compact, ultra-light, under-canopy robots equipped with advanced autonomy and machine learning. Such robots can fill the niche between large farm equipment and manual labor, as well as enable perennial polycultures, and closer to home,  they could also weed your garden! Advances in persistent multi-agent autonomy in harsh, changing, and uncertain environments driven by the controls community are driving such exciting possibilities of the future of agriculture.}
\label{fig:terrasentia}
\end{figure}


%\textbf{Soft robots}

\textbf{Dexterous and ubiquitous robotics for precise care} : The digital farm of the future will strive to eliminate costly inputs (chemicals, labor, energy, and knowledge) with low-cost, dexterous, and highly autonomous agricultural equipment \cite{pedersen2006agricultural}. Advances in \textit{soft} arms and grippers can enable robots that can have far better reach and dexterity around plants than robots equipped with traditional \textit{hard} industrial robotic arms. Soft arms, which are often actuated with pressurized tubes, can be far less expensive to manufacture and significantly lighter than their hard counterparts. On the other hand, soft arms can be slow to actuate and have limited payloads. To make soft robots practical, optimal feedback control techniques are necessary that work with conformal objects with very large degrees of freedom. In particular, soft arms tend to significantly deform under weight and behave quite differently when loaded with different payloads. Unlike hard arms, encoders are not sufficient to estimate the pose of the arm or the manipulator. Strain and angle sensors need to be positioned judicially to keep costs down, and image based feedback control will be necessary. The evolving Gaussian Process technique and the kernel observer techniques described in this paper could be utilized to create distributed observers for such soft systems.  

The complex interaction between closely-spaced diverse plant species in a polyculture results in both spatial and temporal dynamics as the plants grow and interact with each other. %in polyculture parameters, such as growth rate, plant phenology, and yield. 
Plant growth often exhibits hybrid dynamical systems behavior with rapid thresholded growth bursts followed by slow progression. The triggers for growth bursts are dependent on  environmental factors such as temperature, soil moisture, and sunlight reaching individual and cumulative thresholds, and complex interrelations between neighboring plants, soil chemistry, insects, and soil microbes. 

Simulating individual plant growth is an active area of research with many open questions in modeling and plant biology \cite{zhu2016plants}. Arguably, very high resolution plant growth models may not even be necessary for effective control of polycultures. Yet on the other hand, the  %TThere are many open problems in modeling 
 %Furthermore, plant growth follows sigmoidal phase transitions: even though  However, 
 existing models of plants and interactions with ecosystems \cite{Stehfest2007a,Foley1996a, Kucharik2003a,Friedl2010a, Rodrigues2010a, Nunes2013a} are not well suited for designing and managing polycultures because of the simplifying assumptions that are often made. A good balance could be struck with data driven machine learning models that have sufficient resolution for aggregate prediction over multiple spatiotemporal scales and are lightweight enough for control and decision making. With these models, predictive control strategies can be created that task teams of robots for management tasks. Furthermore, these predictive models can enable quantified mechanisms of design and planning of efficient agroecosystems.  
 Obtaining the required data to train these models and using them to create effective control techniques for managing profitable polycultures remains an exciting direction of future work where the controls community can help.
 
 The discussion in this sidebar was informed by many conversations with  crop scientists at UIUC. In particular, 
\textit{the authors wish to thank Prof. Stephen Long and Prof. Carl Bernacchi for insights on the phenotyping bottleneck and simulation of plants (\textit{crops-in-silico}), Prof. Adam Davis on inputs on the herbicide resistant weed crisis, and Prof. Sarah Lovell on sustainable agricultural production systems and perennial polycultures, as well as the members of the UIUC Center for Digital Agriculture} 

\begin{figure}[tbh]
\includegraphics[width=\textwidth]{"Figure S2"}
\caption{The seven layers of the forest garden. Polyculture agricultural production systems are designed ecosystems that can be more productive and sustainable than traditional monoculture systems. Managing such complex systems requires fundamental advances in robotics, spatiotemporal modeling, and control of complex biological processes, all areas where the control community can help. Figure source \cite{polyculture_fig}  see also \cite{rhodes2012feeding}.}
\label{fig:polycultures}
\end{figure}

\processdelayedfloats

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\clearpage
%\input{sidebar_featspaces}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section[Feature Spaces in Machine Learning]{Sidebar: Feature Spaces in Machine Learning}\label{sb:featspace}
Suppose we have data $\sampSetClass = \sampSetClassLong$, where $x_i\in\domI$ and $y_i\in\domO$. Here, $\domI$ is the input domain, and 
is generally a subset of $\R^D$, although more general sets such as discrete spaces, graphs, or text documents can be considered.
Similarly, $\domO$, the output domain, can be just as general as $\domI$. We wish to solve for functions $f$ in some space 
of functions $\functionSet$ such that $f(x_i) = y_i \ \forall i$. Generally, to restrict the complexity of the space $\functionSet$,
a \emph{loss function} $L(f, \sampSetClass)\mapsto\R$ is chosen, which measures the error between a prediction $f(x_i)$ given a datapoint 
$x_i$, and $y_i$, averaged over the entire dataset $\sampSetClass$, and the optimization problem becomes 
\begin{align}
 f^* = \argmin_{\functionSet}L(f, \sampSetClass) + \la g(f),
\end{align}
where $\la\in\R$, and $g(f)$ represent some constraints on the function $f$, such as smoothness. 
Control theorists are most likely familiar with 
input-output pairs where $x_i\in\R^N$ and $y_i$ is either in $\R$ or $\R^M$ (\emph{regression}). 
In machine learning, the most common task is when the $y_i$ are discrete (\emph{classification}). 
Different combinations of task, loss functions, and spaces $\functionSet$ result in different algorithms to solve these problems,
which can sometimes form entire subfields of machine learning. 

The choice of the function space $\functionSet$ can be critical for the task we want to perform,
similar to how the choice of the state space is in control theory. Let's consider a simple
example. Suppose we have data from two \emph{classes} $\sampSetClass_A = \{(x_1^A, y_1^A), \dots, (x_N^A, y_N^A)\}$ and 
$\sampSetClass_B = \{(x_1^B, y_1^B), \dots, (x_N^B, y_N^B)\}$, where $x_i^{\{A,B\}}\in\R^D$, and $y_i^{\{A,B\}}\in\{-1,+1\}$, shown
in Figure \ref{fig:linsep}. Let $f$ be chosen from the class of linear algorithms, i.e. $f = w^Tx + b$, where $w\in\R^D, b\in\R$. 
We pick a loss $L$ that returns a loss of zero when the prediction is the correct class, and if the prediction is the incorrect class,
returns a higher value for misclassifications that are closer to the boundary. A classical example of such a loss is that used by
the \emph{perceptron algorithm}, which can be written as 
\begin{align}\eqlabel{perc_loss}
 L(f, \sampSetClass) = \frac{1}{\nsamp}\sum_{i=1}^N\max(0, -y_iw^Tx). 
\end{align}
This loss measures how accurate the prediction of the perceptron is on average. The general algorithm is as follows:
\begin{enumerate}
 \item Initialize $\weight\in\R^D$ to all zeros. 
 \item For a fixed number of iterations, or until some stopping criterion is met:
       \begin{enumerate}
        \item For each training example $(x_i, y_i)$,
              \begin{enumerate}
               \item Let $\hat{y}_i=\sgn(\weight^Tx_i)$.
               \item If $y_i\neq\hat{y}_i$, update $\weight \leftarrow \weight + y_ix_i$.
              \end{enumerate}
       \end{enumerate}
\end{enumerate}
%This outline of the algorithm will be referenced later when we examine the nonlinear version of it.
The perceptron was one of the first machine learning models, and the genesis of modern neural networks \cite{rosenblatt1958perceptron}. 
Figure \ref{fig:linsep} shows a visual representation of where the perceptron algorithm can solve for the decision boundary with zero error. 
However, if the structure of the data has some nonlinearities, no solution will be found, as seen in Figure \ref{fig:nlinsep}. In this case,
the original space the data resides in is, in some sense, not a rich enough representation. If we could construct a mapping of the data to a
different space which gives a learning algorithm more degrees of freedom to work with, linear algorithms can still be deployed. 
If we map the same data using a nonlinear map $\phi(x,y):= (x^2, y^2, 2xy)$, the perceptron now finds a solution
in 3 dimensions, as seen in Figure \ref{fig:fmapped}. This example shows why so much of the work in machine learning focuses on 
learning the right representation for the data, for the right representation makes the classification task easy. Two major threads of 
research in the arena of feature maps over the last 40 years are kernel methods, and neural networks, the latter
of which has gained remarkable notoriety in the last 10 years. 
%Decision tree learning methods such as gradient boosting and random forests
%arose from the statistics community and enjoy significant adoption in industry \cite{Wasserman}, but will not be described in this work.  
These lines of research represent distinctly different strategies for generating feature maps from data. 

In Figure \ref{fig:nlinsep}, the data was mapped using an explicit feature map. Kernel methods, of which Gaussian Processes are a great example, utilize an elegant strategy for generating
feature maps from data, using a remarkably simple trick called \emph{the kernel trick}. Given a positive-definite kernel function 
$\kernel(x,y):\dom\times\dom\to\R$, Mercer's theorem guarantees the existence of a feature map $\fmap:\dom\to\fspace$, where $\fspace$
is a \emph{reproducing kernel Hilbert space (RKHS)}, and the map $\fmap$ obeys the property 
\begin{align}\eqlabel{kmap}
 \kernel(x,y) = \l\fmap(x), \fmap(y)\r_{\fspace}.
\end{align}
Recall that since $\fspace$ is an RKHS, given $c\in\dom$, $\kernel(x, c) = \l\fmap(x), \fmap(c)\r_{\fspace}$, 
and $\kernel(x, c) := \fmap_c\in\fspace$. Furthermore, $\Span\{\fmap_x\}_{x\in\dom}$ is dense in $\fspace$. There exist kernels 
that generate $\fspace$s that are extremely high dimensional: for example, the RBF kernel $\kernel(x,y) = e^{-\gamma\|x-y\|^2}$
is infinite-dimensional. This high degree of freedom enables the design of powerful learning algorithms that are linear in $\fspace$,
but nonlinear in the input domain $\dom$. The canonical example of this is the support vector machine (SVM) \cite{cortes1995support},
but a more instructive example for us is the perceptron algorithm. 


Suppose we trained a percetron using $\sampSet=\sampSetLong$, $x_i\in\R^D$ for some $D$, $y_i\in\{-1, 1\}$.
The prediction of the perceptron is $\hat{y}=\sgn(w^Tx)$, where $\weight\in\R^D$. It can be shown that 
$\weight=\sum_{i=1}\alpha_iy_ix_i$, where $\alpha_i$ is the number of times $x_i$ was misclassified. This allows us
to derive the dual version of this algorithm, because
\begin{align*}
 \hat{y} = \sgn(\weight^Tx) = \sgn\sum_{i=1}^n\al_iy_i\l x_i, x\r_{\R^D}.
\end{align*}
The dot product $\l x_i, x\r_{\R^D}$ can be replaced with the kernel, leading to the \emph{kernel perceptron algorithm}:
\begin{enumerate}
 \item Initialize $\alpha\in\R^{\nsamp}$ to all zeros. 
 \item For a fixed number of iterations, or until some stopping criterion is met:
       \begin{enumerate}
        \item For each training example $(x_j, y_j)$,
              \begin{enumerate}
               \item Let $\hat{y}_i=\sgn\sum_{i=1}^n\al_iy_i\kernel(x_i, x_j)$.
               \item If $y_i\neq\hat{y}_i$, update $\alpha_j \leftarrow \alpha_j + 1$.
              \end{enumerate}
       \end{enumerate}
\end{enumerate}
%Note that the computation time associated with these types of algorithms grows with the number of data points $\nsamp$, which
%means they are, in dual form, nonparametric. 
This algorithm is nonlinear in the input domain, but linear in the feature space $\fspace$, which led the deep learning community to,
somewhat pejoratively, label this as an example of a \emph{shallow learning architecture}.
Kernel methods can also be used in a more direct fashion: if we have a subspace $\fspace'\subset\fspace$ with a basis generated
from $\shCent = \shCentLong$, i.e. $\fspace' = \Span\{\fmap_{c_1},\dots,\fmap(c_{\ncent})\}$,
a linear model in $\fspace'$ is again given
by a vector $\weight\in\R^{\ncent}$. Suppose this weight vector represents a boundary in $\fspace'$: 
to compute which side of this boundary a point $x$ would lie on in $\fspace'$,
we simply compute $\sgn(\sum_{i=1}^{\ncent}\weight_i\l\fmap(x), \fmap(c_i) \r_{\fspace}) = \sgn(\sum_{i=1}^{\ncent}\weight_i\kernel(x,c_i))$.
The choice of the kernel and its parameters
depends on the dataset and the loss function. The kernel and the data together form the feature space. Because kernel methods are linear
in their parameters and are restricted to RKHSs, they are amenable to somewhat straightforward mathematical analysis, and are very well
studied because of this. The very recent review of Gaussian processes in control that appeared in IEEE CSM contains further details, examples and pointers to software relating to GPs and their use in control \cite{Liu2018csmtutorial}. We switch our attention now to a different way of obtaining the features: Deep Neural Networks. While GPs build features using positive semidefinite symmetric kernels that compare any two points, DNNs build features using nested nonlinear operations. % combinations of weighted linear functions.

Deep neural networks (DNNs) are models where the representing function $f$ has nested nonlinearities. Fix a width $\ncent\in\mathbb{N}$. Deep nets are
parameterized models with 
weight matrices $W^l\in\R^{\ncent\times\ncent}$, bias vectors $b^l\in\R^{\ncent}$, and a pointwise nonlinearity $\phi:\R\to\R$, 
with $l=1,\dots,L$. Vectors $h^l\in\R^{\ncent}$ are called preactivations, and $x^l\in\R^{\ncent}$ are called postactivations,
each element of which is called a \emph{neuron}. 
Let $h^0\in\R^{\ncent}$ be the input: then the canonical feedforward neural network is given by 
\begin{align*}
 x^l = \phi(h^l), \ h^l = W^lx^{l-1} + b^l.
\end{align*}

Therefore, we have that $f(h^0) = x^l$. 
The individual steps $l$ are called the \emph{layers} of the network, and the nesting property allows these networks to learn much more complicated functions than shallow architectures given the same number of nonlinearities 
\cite{bengio2009learning}. Different choices of nonlinearities, connections, and layer architectures lead to different types of neural networks, which are used for different applications \cite{goodfellow2016deep}. Deep learning has had an enormous impact on both the machine learning literature and industrial applications, and that impact has bled over rapidly to other fields. Due to the nested structure of nonlinearities in DNNs, they are more difficult to analyze using simple mathematical tools, and therefore most of the literature in the field has focused on the empirical performance of these methods, where they significantly outperform competing methods.  The significance of the achievements of machine learning in general and deep learning in particular have been in its ability to simplify the implementation of complex functional representation, essentially, in its ability to make system identification more accessible for difficult problems. However, the feature spaces generated by deep networks are not as well behaved and accessible to analysis as those generated by kernel models. In particular, deep network feature spaces do not naturally have the properties of RKHSs.  This presents one barrier to analyzing and understanding the nature of these models. For the reliable and verifiable inclusion of DNNs in engineering control systems, %to obliterate the obstacles necessary for industrial progress. Control needs to provide 
further insights are necessary into the structure of the feature spaces
these models generate, to restrict certain forms of output, and to shape decision-making. 

\begin{figure}
\centering
    \subfloat[Data from classes $A$ and $B$.]
    {
    \includegraphics[width=0.35\columnwidth]{"Figure S3a.pdf"}
    \label{fig:linsep_data}}
     \subfloat[Linear boundary separating data.]
     {\includegraphics[width=0.35\columnwidth]{"Figure S3b.pdf"}
     \label{fig:lin_sep_bound}}  
    \caption{Example of linearly separable data. Any simple linear learning algorithm e.g. perceptron, finds a solution.}
    \label{fig:linsep}
 \end{figure} 

\begin{figure}
\centering
    \subfloat[Data from classes $A$ and $B$.]
    {
    \includegraphics[width=0.35\columnwidth]{"Figure S4a.pdf"}
    \label{fig:nlinsep_data}}
     \subfloat[Linear boundary fails to separate data.]
     {\includegraphics[width=0.35\columnwidth]{"Figure S4b.pdf"}
     \label{fig:nlin_sep_bound}}  
    \caption{Example of nonlinearly separable data. Perceptron fails to find a solution, and diverges.}
    \label{fig:nlinsep}
\end{figure} 


\begin{figure}
\centering
    \subfloat[Nonlinear mapping of data.]
    {
    \includegraphics[width=0.45\columnwidth]{"Figure S5a.pdf"}
    \label{fig:fmapped_data}}
     \subfloat[Linear boundary in new space.]
     {\includegraphics[width=0.45\columnwidth]{"Figure S5b.jpg"}
     \label{fig:fmapped_bound}}  
    \caption{If we map the same data using a nonlinear map $\phi(x,y):= (x^2, y^2, 2xy)$, the perceptron now finds a solution
             in 3 dimensions.}
    \label{fig:fmapped}
\end{figure} 


\processdelayedfloats
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\clearpage
%\input{sidebar_cfd}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section[Learning Fluid Flows with Evolving Gaussian Processes]{Sidebar: Learning Fluid Flows with Evolving Gaussian Processes}\label{sb:cfd}

2nd order Partial Differential Equations (PDEs) are ubiquitous in practical science and engineering, from mechanics to transport phenomena to electromagnetics. In our view, the Navier-Stokes equations governing fluid dynamics represent most, if not all of the overall complexity of modeling these as (a) it exhibits of hybrid system behavior, such as elliptic-hyperbolic, and (b) the nonlinearity results in the complex spatio-temporal dynamics that are prevalent in many practical situations. 

We demonstrate the Evolving Gaussian Processes method on CFD data of flow over a bluff body (a cylinder) over a range of Reynolds numbers from 100 to 1000 (the Reynold number is a dimensionless flow rate). This deterministic, high-dimensional spatiotemporal dynamical system is well-studied in the fluid dynamics literature, both experimentally and numerically \cite{roshko1954cylinder, braza1986cylinder, rajani1986cylinder}. The conventional wisdom would be to learn a separate model over each Reynolds number, but our results show that the E-GP method is capable of learning the dynamics of all the flow patterns at once. Using the learned dynamics over weights of successive kernel models, E-GP is capable of predicting the future states of functional evolution in a recursive manner. The key advantage of E-GP is that evolution of large function spaces can be transformed into learning the evolution in a relatively smaller Hilbert space which is encoded by the kernels and the associated weight vector. 

In our CFD simulation, we used a 4th-order polynomial expansion with the spectral element method on the incompressible Navier-Stokes equation to generate the cylinder flow data for Re = 100, 300, 600, 800, and 1000. The spatial domain is $\left[-2,10\right]\times\left[-3,3\right]$, excluding the diameter-1 cylinder at the origin.  Neumann boundary conditions are applied to the far-field of the cylinder in the y-direction and the outlet of the flow field; and a Dirichlet boundary condition is applied to the inlet. Each dataset contains at least 200 snapshots with a uniform time step of 0.03 sec. Each snapshot contains 24,000 velocity data points for Re=100 or 95,000 velocity data points for Re=300,600,800,1000. Each dataset took at least 10 hours in a high performance computer cluster to generate. Figures \ref{fig:cfd_100},\ref{fig:cfd_1000}(a-d) visualize the horizontal velocity for Re=100 and Re=1000, with red being the greatest negative velocity and blue the greatest positive velocity. The flow is unstable, periodic, and clearly nonlinear.

\begin{figure*}[h] %{r}{0.5\textwidth}
	\centering
	\subfloat[Snapshot 0]{
		\includegraphics[width=0.23\textwidth]{"Figure S6a"}		}
	\subfloat[Snapshot 10]{
		\includegraphics[width=0.23\textwidth]{"Figure S6b"}		}
	\subfloat[Snapshot 20]{
		\includegraphics[width=0.23\textwidth]{"Figure S6c"}		}
	\subfloat[Snapshot 30]{
		\includegraphics[width=0.23\textwidth]{"Figure S6d"}		}\\
	\subfloat[Snapshot 0]{
		\includegraphics[width=0.23\textwidth]{"Figure S6e"}		}
	\subfloat[Snapshot 10]{
		\includegraphics[width=0.23\textwidth]{"Figure S6f"}		}
	\subfloat[Snapshot 20]{
		\includegraphics[width=0.23\textwidth]{"Figure S6g"}		}
	\subfloat[Snapshot 30]{
		\includegraphics[width=0.23\textwidth]{"Figure S6h"}		}
	
	\caption{Visualization of Fluid Flow at Re = 100, CFD (a-d), E-GP (e-h)}
	\label{fig:cfd_100}
\end{figure*}

\begin{figure*}[h] %{r}{0.5\textwidth}
	\centering
	\subfloat[Snapshot 0]{
		\includegraphics[width=0.23\textwidth]{"Figure S7a"}		}
	\subfloat[Snapshot 5]{
		\includegraphics[width=0.23\textwidth]{"Figure S7b"}		}
	\subfloat[Snapshot 10]{
		\includegraphics[width=0.23\textwidth]{"Figure S7c"}		}
	\subfloat[Snapshot 15]{
		\includegraphics[width=0.23\textwidth]{"Figure S7d"}		}\\
	\subfloat[Snapshot 0]{
		\includegraphics[width=0.23\textwidth]{"Figure S7e"}		}
	\subfloat[Snapshot 5]{
		\includegraphics[width=0.23\textwidth]{"Figure S7f"}		}
	\subfloat[Snapshot 10]{
		\includegraphics[width=0.23\textwidth]{"Figure S7g"}	}
	\subfloat[Snapshot 15]{
		\includegraphics[width=0.23\textwidth]{"Figure S7h"}	}
	\caption{Visualization of Fluid Flow at Re = 1000, CFD (a-d), E-GP (e-h)}
	\label{fig:cfd_1000}
\end{figure*}

We used the Gaussian RBF kernel $\kernel(x,y) = e^{-\|x-y\|^2/2\s^2}$ in our E-GP model, with $\s$ estimated to be 0.4. Using a budget of 600 kernel centers (see Figure \ref{fig:eigen100}-\ref{fig:eigen1000}, and note how they cluster in the most dynamic regions), we find a $600\times600$ matrix $\dualopApprox$ which accurately (Figure \ref{fig:errors}) captures the dynamics of the nonlinear system. We can use this to propagate a single initial condition $\weight_{0}$ forward to make predictions, then compare the predictions to the original training data. We found total percentage errors between 3\% for Re=100 and 7-8\% for Re=1000, as can be seen in the solid lines in Figure \ref{fig:errors}. We define the total percentage errors as
$E_\tindex = \frac{\|y_\tindex-\bar y_\tindex\|_2}{\|\bar y_\tindex\|_2}$
where $\bar y_\tindex$ is the output vector for time $\tindex$ and $y_\tindex$ is the E-GP estimate at that time. Note that \emph{the size of the model has been reduced by almost two orders of magnitude} from the original CFD data. This process takes about 13 minutes in MATLAB for a 200 snapshot by 95,000 point set on an ordinary Intel i7 4.00 GHz processor.

\subsection{One Transition Matrix for Everything}\label{sec:lotr}

To approach the challenge of generalizing across similar spatiotemporally evolving systems, the first question to answer is whether we can find an $\dualopApprox$ matrix that accurately captures the dynamics of multiple similar flows. The answer to that question is \textit{yes}, using the trajectory concatenation method. Amazingly, a single model generated this way works almost as well on all five datasets as do five individual models trained on each dataset separately. This is confirmed by both the total error plots (Figure \ref{fig:errors}), which show only slight increases in each of the total percentage error plots, and visual inspection of the dynamic modes displayed. This result is even more surprising in light of the fact that the rate of vortex shedding for each Reynolds number is different. By taking a Fourier transform of the time evolution of a data point located at (0.5,8), we find that for the original datasets the vortex shedding frequency is 0.448 Hz, 1.260 Hz, 1.380 Hz, 1.388, and 1.401 Hz for Re=100, 300, 600, 800, and 1000 respectively, and for the E-GP models the frequencies are 0.452 Hz, 1.21 Hz, 1.36 Hz, 1.36 Hz, and 1.36 Hz respectively.

\begin{figure*}[h] %{r}{0.5\textwidth}
	\centering
	\subfloat[\small{Universal Generalizer vs Individual Models}]{
		\includegraphics[width=0.7\textwidth]{"Figure S8a"}
		\label{fig:errors}		}\\
	\subfloat[\small{Different Models Tested on Re=800}]{
		\includegraphics[width=0.7\textwidth]{"Figure S8b"}
		\label{fig:errors_boxplot}		}
	\caption{Total Percentage Errors}
\end{figure*}

\subsection{Generalizing from Learned Dynamics to Unknown Dynamics}\label{sec:generalize}

Having seen that it is possible to find a single transition in the weight space that models the dynamics systems over a range of parameters, the next challenge is to be able to model flows with parameters that the model has not been trained on. We derived an $\dualopApprox$ matrix from the Re=100, 300, 600, and 1000 datasets and tested it against the Re=800 dataset. The results are below in Figure \ref{fig:errors_boxplot}. For the first 120 snapshots, the total percentage error remains under 10\%, which is satisfactory. After this, however, the total percentage error curves upwards as the slight errors in the transition matrix compound. Over 800 snapshots, we found an average total percentage error of less than 25\%. 

\subsection{Linear Dynamical Layer Analysis \& Insights}\label{sec:analysis}
Due to the spatial encoding of the weights which the linear transition model operates on, we are able to analyze the dynamics and find physical insights into the process. We demonstrate two techniques: (1) using eigendecomosition of the transition matrix to discover the eigenfunctions and invariant subspaces of system, and (2) visualizing the most significant spatial interactions in the system.

By marking which kernel centers are associated with different invariant subspaces, we can spatially separate the space into multiple dynamic modules. The physical insight is that some areas of the space are dynamically entangled with each other, and other are independent. For those interested in monitoring spatiotemporally evolving systems, the number and location of the invariant subspaces determines how many and where feedback sensors ought to be for robust prediction of the system state.

\begin{figure*}[h] %{r}{0.5\textwidth}
	\centering
	\subfloat[\small{Re = 100, $\varepsilon$ = 0.005}]{
		\includegraphics[width=0.31\textwidth]{"Figure S9a"}
		\label{fig:eigen100}	}
	\subfloat[\small{Re = 1000, $\varepsilon$ = 0.05}]{
		\includegraphics[width=0.31\textwidth]{"Figure S9b"}
		\label{fig:eigen1000}		}
	\subfloat[\small{All Reynolds numbers, $\varepsilon$ =0.069}]{
		\includegraphics[width=0.31\textwidth]{"Figure S9c"}
		\label{fig:eigenall}	}
	\caption{Eigenvector Heat Maps}
\end{figure*}
\begin{figure*}[h] %{r}{0.5\textwidth}
	\centering
	\subfloat[\small{Re = 100, $\varepsilon$ = 0.005}]{
		\includegraphics[width=0.30\textwidth]{"Figure S10a"}}
	\subfloat[\small{Re = 1000, $\varepsilon$ = 0.05}]{
		\includegraphics[width=0.30\textwidth]{"Figure S10b"}}
	\subfloat[\small{All Reynolds numbers, $\varepsilon$ = 0.069}]{
		\includegraphics[width=0.34\textwidth]{"Figure S10c"}}
	\caption{Invariant Subspaces}
	\label{fig:subspaces}
\end{figure*}

\begin{figure*}[h] %{r}{0.5\textwidth}
	\centering
	\subfloat[\small{Re=100}]{
		\includegraphics[width=0.31\textwidth]{"Figure S11a.pdf"}
		\label{fig:haystack100}	}
	\subfloat[\small{Re=1000}]{
		\includegraphics[width=0.31\textwidth]{"Figure S11b.pdf"}
		\label{fig:haystack1000} }
	\subfloat[\small{Trained on all 5 datasets}]{
		\includegraphics[width=0.31\textwidth]{"Figure S11c.pdf"}
		\label{fig:haystackall}	}
	\caption{Visualization of Co-Relations in Transition Matrix}
\end{figure*}

Before attempting a Jordan decomposition of $\dualopApprox$, we zero any elements smaller than some small $\varepsilon$ in order to stabilize the algorithm for matrices with many elements close to zero. Afterwards we visualize the eigenvector matrix using a \emph{logarithmic} color chart, as seen in Figures \ref{fig:eigen100},\ref{fig:eigen1000},\ref{fig:eigenall}. These plots are for models trained individually on Re=100 and Re=1000 with 300 kernels, and on all five with 600 kernels, for comparison. We see three categories of eigenvector in the rows: (1) Rows at the bottom that have exactly one non-zero elements, (2) In the middle, a couple rows with a dozen significant elements, and (3) at the top a number of rows that affect the majority of the kernel centers in the space.

Each eigenvector of (1) spans its own invariant subspace, and is depicted in magenta circles in Figure \ref{fig:subspaces}. Category (3) is one invariant subspace, depicted with black crosses. Category (2) is subsumed in Category (3). The figures show that the dynamics near/around the cylinder and in its wake are so entangled that a single sensor measurement in that area may be sufficient to estimate over that entire subspace. On the other hand, areas far from the core of dynamic excitement are their own independent, invariant subspaces, and thus must be monitored locally.

Another way to visualize the operation of the linear transition matrix is to plot lines between kernel centers that are influencing each other strongly. That is, if we draw a line center $c_j$ to $c_i$ for each of the (relatively) largest elements $a_{ij}$ of $\dualopApprox$, one can see how the system dynamics are coupled spatially (Figures \ref{fig:haystack100},\ref{fig:haystack1000},\ref{fig:haystackall}). We can also plot the magnitude of $a_{ij}$ in a third axis for further insight into the most dominant dynamic connection in the system.


\processdelayedfloats
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\newpage
\section{Author Biography}
%Insert the author bios here.

\noindent \textbf{Joshua E. Whitman} is a PhD student at the University of Illinois in Urbana-Champaign. He received Bachelors of Science degrees in Mechanical Engineering and Mathematics from Oklahoma State University in 2015, and his Masters of Science in Mechanical Engineering from the University of Illinois in 2018. His research is centered in the fields of machine learning, controls, and autonomy, and his work focuses on developing new methods for learning, monitoring, and controlling the dynamics of complex spatiotemporally-evolving systems.

\noindent \textbf{Harshal Maske} completed his PhD in 2018 from the University of Illinois in Urbana-Champaign, he is currently a Research Engineer with Ford Motor Company. Prior to joining Ford, Harshal was a research intern at Mitsubishi Electric Research Laboratory. He had received his Masters and Bachelors integrated degree in Mechanical Engineering from the Indian Institute of Technology Kharagpur, India, in 2009. After completing his masters, he worked for three years at Defense R\&D Organization (2009-2012), India and for one year at John Deere (2012-2013). 

\noindent \textbf{Hassan A. Kingravi}  is a senior data scientist at MailChimp, where he conducts research on machine learning and builds systems for fighting fraud. His research interests revolve around the interplay of control theory, signal processing, and machine learning for spatiotemporal data. He received his PhD in Electrical and Computer Engineering from the Georgia Institute of Technology in 2014 and did a postdoc at Oklahoma State University with Chowdhary's group.

\noindent \textbf{Girish Chowdhary} is an assistant professor and Donald Biggar Willet Faculty fellow at the University of Illinois at Urbana-Champaign and affiliated with Electrical and Computer Engineering, Agricultural and Biological Engineering, Computer Science, Aerospace Engineering, and is a member of the UIUC Coordinated Science Laboratory (CSL). He is the director of the Distributed Autonomous Systems laboratory and the Field Robotics Engineering and Science Hub (FRESH) at UIUC. He holds a PhD (2010) from Georgia Institute of Technology in Aerospace Engineering. He was a postdoc at the Laboratory for Information and Decision Systems (LIDS) of the Massachusetts Institute of Technology for about two years (2011-2013). He was an assistant professor at Oklahoma State University's Mechanical and Aerospace Engineering department (2013-2016). Prior to joining Georgia Tech, he also worked with the German Aerospace Center's (DLR's) Institute of Flight Systems for around three years (2003-2006). His undergraduate institution was the Royal Melbourne Institute of Technology in Australia. Girish's ongoing research interest is in theoretical insights and practical algorithms for adaptive autonomy with applications in field robotics.  


\end{document}
\clearpage
