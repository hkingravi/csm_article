\section{Conclusion}\label{sec:conclusion}
Machine learning techniques such as Gaussian Process regression and deep learning are providing increasingly more powerful ways of learning predictive models. However, these techniques are limited by the datasets that they are trained with. Hence, their predictions are not always reliable when predicting real-world complex spatiotemporally-evolving phenomena with lots of variability. Indeed, years worth of weather data cannot be a reliable predictor of weather, nor can data from one farm directly relate to another. Hence, when engineering complex cyber-physical systems such as team of mechanically weeding robots, engineers have to think of ways to supplement the predictions of the machine learning models with real measurements. However, this is not always immediate when one works in the abstract feature spaces utilized in machine learning models. Here we presented Evolving Gaussian Processes, which are formed by embedding a linear dynamical system in the %showed here that despite their abstract nature,
reproducing kernel Hilbert spaces generated by the Gaussian Process model. The parameters of the linear dynamical system can be trained to approximately predict the evolution. In itself this can lead to powerful and generalizable models, as our results demonstrated in predicting solutions to the Navier-Stokes equations. Furthermore, a Kalman filter can be embedded with the linear dynamical system in the RKHS that can keep the predictions on track with real sensor measurements. This creates a very powerful prediction system that is capable of predicting nonlinear evolution using very few sensor measurements. We showed that the geometric properties of the linear dynamical system can be utilized to determine sensor numbers and locations. Looking forward, it would interesting to extend the idea to include nonlinear dynamical systems in the feature space. Such embeddings could improve the capability of the E-GP model. However, it seems from our results with complex datasets that the feedback with sensors creates a robust monitoring system with the predictions with a simple linear model. The theoretical limits of the tradeoff between improving the model versus increasing the sensing in the context of E-GPs is interesting to study. Finally, also we note that deep neural networks have also been applied to the spatiotemporal modeling problem with significant empirical success\cite{tran2015learning}, but because these methods are 1) nonlinear in their parameters, and 2) seem to lack the spatial-encoding properties of some types of kernels, how to generalize the analysis considered here for those systems is an interesting open question. Indeed, as sidebar ``\nameref{sb:featspace}'' indicates, there could be very interesting future work that generalizes the idea of embedding controllers and observers in features spaces of machine learning models. % that  that closing the loop with measurements leads to a sufficiently robust seems  %can be  with   how the weights kernel based regression models are amenable to embedding of dynamical


% that embedding dynamical systems in the f  interpret ability, We demonstrated that the Evolving Gaussian Process model 
%Evolving-Gaussian Processes and Kernel Observers present an 
