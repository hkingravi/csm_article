\section{Conclusion}\label{sec:conclusion}
Machine learning techniques such as Gaussian Process (GP) regression and deep learning are providing increasingly more powerful ways of learning predictive models. For all their power, however, since these techniques are limited by the datasets that they are trained with, their predictions are not always reliable when predicting real-world complex spatiotemporally-evolving phenomena with high variability; years' worth of weather data cannot be a reliable predictor of current weather, nor can data from one farm directly relate to another. Because of this, when engineering complex cyber-physical systems such as team of mechanically weeding robots, engineers have devise ways to supplement the predictions of the machine learning models with real measurements. This is not always immediate when one works in the abstract feature spaces utilized in machine learning models. In this tutorial we presented kernel observers and their extension Evolving Gaussian Processes (E-GP), which are formed by embedding a linear dynamical system in the %showed here that despite their abstract nature,
reproducing kernel Hilbert spaces generated by the GP model. The parameters of the linear dynamical system can be trained to approximately predict the evolution. This leads to powerful and generalizable models, as our results demonstrated in predicting solutions to the Navier-Stokes equations. When supplemented with a predict-and-correct strategy, such as a Kalman filter embedded with the linear dynamical system in the RKHS, the dynamical state of the system can be kept on track with real sensor measurements. This creates a very powerful prediction system that is capable of predicting nonlinear evolution using minimal sensor measurements. We showed that the geometric properties of the linear dynamical system can be utilized to determine sensor numbers and locations. Looking forward, it would interesting to extend the idea to include nonlinear dynamical systems in the feature space, which would improve the capability of the E-GP model. At present, our results on fairly complex datasets demonstrate that feedback with sensors creates a robust monitoring system with the predictions with a simple linear model. The theoretical limits of the tradeoff between improving the model versus increasing the sensing in the context of E-GPs is also an interesting avenue of study. Finally, also we note that deep neural networks have also been applied to the spatiotemporal modeling problem with significant empirical success\cite{tran2015learning}, but because these methods are 1) nonlinear in their parameters, and 2) seem to lack the spatial-encoding properties of some types of kernels, generalizing the analysis considered here for those systems is an interesting open question. As sidebar ``\nameref{sb:featspace}'' indicates, there could be very interesting future work that generalizes the idea of embedding controllers and observers in more advanced features spaces considered in machine learning models. % that  that closing the loop with measurements leads to a sufficiently robust seems  %can be  with   how the weights kernel based regression models are amenable to embedding of dynamical


% that embedding dynamical systems in the f  interpret ability, We demonstrated that the Evolving Gaussian Process model 
%Evolving-Gaussian Processes and Kernel Observers present an 
