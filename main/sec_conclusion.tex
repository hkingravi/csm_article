\section{Conclusion}\label{sec:conclusion}
This tutorial introduced Gaussian Processes (GP) and Gaussian Process Regression (GPR) from the perspective of Bayesian nonparametric inference for use in control and reinforcement learning problems. It emphasized the key features of GPRs, including: \emph{1)} how they allow for automatic data-driven feature selection, thereby not requiring practitioners to predefine feature numbers and locations; \emph{2)} the way in which GPs offer uncertainty measures of predictions; \emph{3)} how Bayesian inference allows for natural optimization and selection of GP hyperparameters; and \emph{4)} how GPs offer a principled way for performing budgeted online inference. The tutorial provided concrete examples demonstrating how GPR for adaptive control and off-policy reinforcement learning, and also discussed the application of GPs to model value functions in optimal control and planning problems, and to model reward functions in inverse optimal control problems. Moreover, it showed how GPs can be used as the basis of a probabilistic framework capable of modeling system dynamics and measurement functions, with use in model predictive control and state estimation and filtering problems. In addition, the tutorial elaborated the connections between GPR and other widely-used regression techniques, so that  readers and practitioners are able to understand the unique features of GPs and its generality. Finally, the tutorial discussed a few limitations of the basic GPR approach and provided a brief overview of several advanced GP models that overcome such limitations. The discussions presented here are by no means exhaustive; our intention is merely to highlight the key features of Gaussian Processes, through illustrative examples, in order to help interested practitioners to more efficiently explore the relevant literature.

