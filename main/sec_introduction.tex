\section{Introduction} \label{sec:intro}
Modeling of large-scale stochastic phenomena with both spatial and temporal (spatiotemporal) evolution is a fundamental problem in the applied sciences. % Common examples include modeling ocean heat content and acidification in oceanography \cite{barnett2001detection}, %future seismicity \cite{bungum2005postglacial}, 
%land use change in urbanization \cite{deng2009spatio}, and extreme weather events \cite{heaton2011spatio}, among others.
While modeling spatiotemporal phenomena has traditionally been the province of the field of geostatistics, it has in recent years gained more attention in the machine learning community \cite{cressie2011statistics}. The data-driven models developed through machine learning techniques provide a way to capture complex spatiotemporal phenomena which are not easily modeled by first-principles alone. %, such as those described by stochastic partial differential equations with uncertain parameters. %, such as stochastic partial differential equations. 

In the machine learning community, kernel methods represent a class of extremely well-studied and powerful methods for inference in spatial domains; in these techniques, correlations between the input variables are encoded through a covariance kernel, and the model is formed through a linear weighted combination of the kernels \cite{RasmussenWilliams2005,schoelkopf01kernelbased,scholkopf2002learning}. In recent years, kernel methods have been applied to spatiotemporal modeling with varying degrees of success \cite{cressie2011statistics,RasmussenWilliams2005}. Many recent techniques in spatiotemporal modeling have focused on nonstationary covariance kernel design and associated hyperparameter learning algorithms \cite{garg2012AAAI,ma2003nonstationary,plagemann2008nonstationary}. These methods, which focus on the careful design of covariance kernels,  have been proposed as an alternative to the naive approach of  simply including time as an additional input variable in the kernel \cite{Chowdhary13_CDC1}. The careful design/optimization of covariance kernel avoids an explosion in the number of parameters (kernels utilized) of the model which would be inevitable in a model that simply adds time as an additional input variable, and has been shown to better account for spatiotemporal couplings. However, there are two key challenges with existing kernel based approaches: The first is ensuring the scalability of the model to large scale phenomena, which manifests due to the fact that the problem of optimizing the covariance kernel (known as hyperparameter optimization in the ML community) is not convex in general, leading to methods that are difficult to implement especially in online settings, susceptible to getting stuck at local minima, and highly computationally demanding for large datasets. % \cite{sra2012optimization}. 
The second key challenge is in using existing kernel-based machine learning models for analysis and synthesis of observers and controllers for the large scale spatiotemporal phenoemena. While the first challenge can be addressed with increasing computational power for large datasets, addressing the latter (and vastly more fundamental) challenge is particularly important in the design of reliable engineering systems, such as distributed sensor/actuator networks intended for monitoring physical phenomena, autonomous soft-robots, or other physical systems with distributed sensing and actuation.  %Consider in specific the problem of designing an optimal distributed sensor network for ``monitoring'' a spatiotemporally evolving function. 
%Some of the fundamental engineering questions that are of importance here are Given an approximate predictive model of the spatiotemporal phenomena, how can the current latent state of the phenomena be estimated using as few sensor measurements as possible?  
% 
   
%In addition to the challenge of modeling spatiotemporally varying processes, we are interested in addressing the second very important, and widely unaddressed challenge:

%To focus the development of the theory, we posit the challenging problem of ``monitoring'' a spatiotemporal phenoemena: Given an approximate predictive model of the spatiotemporal phenomena, how can the current latent state of the phenomena be estimated using as few sensor measurements as possible? This is called the \emph{monitoring problem}. Monitoring a spatiotemporal phenomenon is concerned with estimating its current state, predicting its future evolution, and inferring the initial conditions utilizing limited sensor measurements. The key challenges here manifest due to the fact that it is typically infeasible or expensive to deploy sensors at a large scale across vast spatial domains. %For example, in monitoring the flux of $CO_2$ over underground $CO_2$ storage sites, the number of sensors and sensing locations are limited due to cost or geography. %In another example, when monitoring the state of dynamically evolving enemy deployment over a contested area, the availability of measurements is limited due to the presence of adversity.
%To minimize the number of sensors deployed, a predictive data-driven model of the spatiotemporal evolution could be learned from historic datasets or through remote sensing  (e.g. satellite, radar) datasets. Then, to monitor the phenomenon, the key problem would boil down to reliably and quickly estimate the evolving latent state of the phenomena utilizing measurements from very few sampling locations.

%The problem of state estimation of a temporally evolving finite-dimensional state-space system has been extensively studied in the dynamical systems and feedback-control community \cite{Gelb74}. Fundamental results in systems observability theory provide sufficient conditions on the structure of the state transition and measurement matrix such that the latent state can be tracked with a measurement-feedback observer using a number of measurements less than the number of states. A highly successful example of such a state estimator is the celebrated Kalman filter, which is a Bayes-optimal filter for estimating the latent states of a finite-dimensional linear state-space model corrupted with Gaussian noise \cite{Gelb74}. Such filters can be extended to the functional domain \cite{mardia1998kriged}, but are typically not studied in a monitoring context. 

In this paper, we present a new perspective to solving the spatiotemporal monitoring problem that brings together kernel-based modeling, systems theory, and Bayesian filtering. We define the monitoring problem as follows: \textit{Given an approximate predictive model of the spatiotemporal phenomena learned using historic data, estimate the current latent state of the phenomena in the presence of uncertainty using as few sensors as possible}. In particular, we argue that when it comes to predictive inference over spatiotemporal phenomena, a Kalman-filter type approach of predicting and correcting with feedback from a set of minimal sensors is a robust way of dealing with real-world uncertainties and inherent modeling errors.  In the context of this specific problem, our \textit{main contributions are two-fold}: first, we demonstrate that spatiotemporal functional evolution can be modeled using stationary kernels with a linear dynamical systems layer on their mixing weights. In particular, in contrast with existing work, this approach does not necessarily require the design of complex spatiotemporal kernels, and can accommodate positive-definite kernels on any domain on which it is possible to define them, which includes non-Euclidean domains such as Riemannian manifolds, strings, graphs and images \cite{Jayasumana_PAMI2015_RBFs}. Second, we show that such a model can be utilized to determine sensing locations that guarantee that the hidden states of functional evolution can be estimated using a Bayesian state-estimator (Kalman filter) with very few measurements. We provide sufficient conditions on the number and location of sensor measurements required and prove non-conservative lower bounds on the minimum number of sampling locations by developing fundamental results on observability of kernel based models. The validity of the presented model and sensing techniques is corroborated using synthetic and large real datasets.

The fundamental idea of building observers and controllers introduced in this paper is generalizable beyond the particular application of spatiotemporal monitoring. Indeed, the significance of the contributions of this paper are in fusing machine learning theory with systems theory to provide a pathway to address major challenges in spatiotemporal monitoring and control. The problem of state estimation of a temporally evolving finite-dimensional state-space system has been extensively studied in the dynamical systems and feedback-control community \cite{Gelb74}. Here, fundamental results in observability/controllability provide sufficient conditions on the structure of the state transition and measurement matrix such that the latent state can be estimated in the presence of measurement and process noise. %A highly successful example of such a state estimator is the celebrated Kalman filter, which is a Bayes-optimal filter for estimating the latent states of a finite-dimensional linear state-space model corrupted with Gaussian noise \cite{Gelb74}. 
Such filters can be naively extended to the functional domain (e.g.\cite{mardia1998kriged}), but have not typically been studied in context of the spatiotemporal monitoring problem studied here. 

The marriage of systems theory with machine learning pursued in this paper is exciting because it can provide a formal way of answering fundamental questions about complex systems, such as: % and seek to develop machine learning models that can be utilized to answer questions such as: 
What is the least number of sensors required to observe a distributed system? Where to place sensors/actuators to guarantee observability/controllability of the system? And how does random sensor placement affect observability/controllability? We expect that follow on work will exploit the framework presented in this paper of utilizing linear models in feature spaces of machine learning models to enable practical and analyzable data-driven engineering systems. To facilitate the development of the theory, we have focused this paper on the problem of monitoring spatiotemporal phenomena. However, the idea can be generalized to any distributed cyber-physical system that is changing with space and time. %As such, we have focused mostly on the fundamental theory and practical algorithms in modeling, estimation, and control, while 
%The excruciating details of how to optimally implement the presented algorithms are omitted\footnote{Instead an open-source code-base is made available in MATLAB on http://daslab.illinois.edu/software.html and in Python on GitHub https://github.com/hkingravi/funcobspy?files=1}.   % that are analyzable.

Elements of the work presented in this paper first appeared in the premier machine learning conference Neural Information Processing Systems (NIPS 2016) (\cite{Kingravi16_NIPS}), IEEE CDC 2015 conference \cite{Kingravi:2015a}, and IEEE ACC 2018 conference \cite{Maske18_ACC}.  This paper presents a comprehensive set of results in a single journal publication, and introduces results on observability in the presence of random sensor placement. As such, we have focused in this article mostly on the fundamental theory and practical algorithms for modeling, estimation, and control, while the excruciating details of how to optimally implement the presented algorithms are omitted\footnote{Instead an open-source code-base is made available in MATLAB on http://daslab.illinois.edu/software.html and in Python on GitHub https://github.com/hkingravi/funcobspy?files=1}. Section \ref{sec:related} summarizes some related work in machine learning in this area. Section \ref{sec:observers} formulates the problem,  introduces kernel observers, and develops the main theoretical and algorithmic results.
Section \ref{sec:random_results} presents a result on the expected number of randomly placed sensors required to monitor a spatiotemporal process in the context of our model. Section \ref{sec:exp} demonstrates the efficacy of the algorithms on several challenging and large real-world datasets. The paper is concluded in Section \ref{sec:conclusion} and proofs of main results are provided in the Appendix. 