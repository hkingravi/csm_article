\subsection{Related Work}\label{sec:related}
There is a large body of literature on spatiotemporal modeling in geostatistics where specific process-dependent kernels can be used \cite{wikle2002kernel,cressie2011statistics}. From the machine learning perspective, a naive approach is to utilize both spatial and temporal variables as inputs to a Mercer kernel \cite{perez2013gaussian}. However, this technique leads to an ever-growing kernel dictionary. %, which is computationally taxing.
Furthermore, constraining the dictionary size or utilizing a moving window will
occlude learning of long-term patterns. Periodic or nonstationary covariance functions and nonlinear transformations have been proposed to address this issue \cite{ma2003nonstationary,RasmussenWilliams2005}. Work focusing on nonseparable and nonstationary covariance kernels seeks to design kernels optimized for environment-specific dynamics, and to tune their hyperparameters in local regions of the input space. Seminal work in \cite{higdon1998process} proposes a process convolution approach for space-time modeling. This model captures nonstationary structure by allowing the convolution kernel to vary across the input space. This approach can be extended to a class of nonstationary covariance functions, thereby allowing the use of a Gaussian process (GP) framework, as shown in \cite{paciorek2004nonstationary}. However,  since this model's hyperparameters are inferred using Markov Chain Monte Carlo (MCMC) integration, its application has been limited to smaller datasets. To overcome this limitation, \cite{plagemann2008nonstationary} proposes to use the mean estimates of a second isotropic GP (defined over latent length scales) to parameterize the nonstationary covariances. Finally, \cite{garg2012AAAI} considers non-isotropic variation across different dimension of input space for the second GP as opposed to isotropic variation by \cite{plagemann2008nonstationary}. Issues with this line of approach include the nonconvexity of the hyperparameter optimization problem and the fact that selection of an appropriate nonstationary covariance function for the task at hand is a nontrivial design decision (as noted in \cite{singh2010modeling}). 

Apart from directly modeling the covariance function using additional latent GPs, there exist several other approaches for specifying nonstationary GP models. One approach maps the nonstationary spatial process into a latent space, in which the problem becomes approximately stationary \cite{schmidt2003bayesian}. Along similar lines, \cite{pfingsten2006nonstationary} extends the input space by adding latent variables, which allows the model to capture  nonstationarity in original space. Both these approaches require MCMC sampling for inference, and as such are subject to the limitations mentioned in the preceding paragraph. 

%The geostatistics community literature has many examples of the dynamical spatiotemporal modeling approach, where the focus is on finding good dynamical transition models on the linear combination of weights in a parameterized model \cite{cressie2011statistics,mardia1998kriged}. 
A geostatistics approach that finds dynamical transition models on the linear combination of weights of a parameterized model \cite{cressie2011statistics,mardia1998kriged} is advantageous when the spatial and temporal dynamics are hierarchically separated, leading to a convex learning problem. As a result complex nonstationary kernels are often not necessary (although they can be accommodated). The approach presented in this paper aligns closely with this vein of work. %The main difference is that we view the problem from the more abstract viewpoint of constructing an observer in a reproducing kernel Hilbert space. 
A systems-theoretic study of this viewpoint enables the fundamental contributions of the paper, which are 1) allowing for inference on more general domains with a larger class of basis functions than those typically considered in the geostatistics community, and 2) quantifying the minimum number of measurements required to estimate the state of the system. 

Lastly, sensor placement optimization is also a well-studied area. Examples include, but are not limited to 1) geometric approaches, which seek to provide a covering of the operating space without making assumptions about the spatiotemporal dynamics \cite{egerstedt:bk:2010}, and 2) information-theoretic approaches, which place their focus on sensor placement optimizing strategies based on mutual information and information entropy for Gaussian process models \cite{Guestrin05_ICML}.
It should be noted that the contribution of the paper concerning sensor placement is to provide \emph{sufficient conditions} for monitoring rather than optimization of the placement locations, and therefore a comparison with these approaches is not considered in the experiments. 

