\subsection{Related Work}\label{sec:related}
\rr{There is a very large amount of literature on Gaussian Processes and spatiotemporal modeling, a complete survey of this literature is beyond the scope of this paper. Since our contributions are in the area of creating a feedback based observer in the feature spaces of GP models, we discuss here related work in three related areas: Spatiotemporal modeling with GPs, Kalman filtering and GP connection, and sensor placement for inference in spatiotemporal domains.}
 
There is a large body of literature on spatiotemporal modeling in geostatistics where specific process-dependent kernels can be used \cite{wikle2002kernel,cressie2011statistics,stroud}. \rr{Other approaches that utilize hierarchy or evolution of kernels have also been used for modeling spatiotemporal functions \cite{Hartikainen, Hartikainen phd, Lindgren, Ho}}. From the machine learning perspective, a naive approach is to utilize both spatial and temporal variables as inputs to a Mercer kernel \cite{perez2013gaussian}. However, this technique leads to an ever-growing kernel dictionary. %, which is computationally taxing.
Furthermore, constraining the dictionary size or utilizing a moving window will
occlude learning of long-term patterns. \rr{A more clever approach is to use state-space representations of time-varying GPs \cite{simo, Hartikainen phd}. In this view point, each GP instance is viewed as a snapshot of an evolving set of weights. We follow in a similar vein here, with added emphasis on understanding the mathematical structures leading to observability and controllability.} Periodic or nonstationary covariance functions and nonlinear transformations have been proposed to address this issue \cite{ma2003nonstationary,RasmussenWilliams2005}. Work focusing on nonseparable and nonstationary covariance kernels seeks to design kernels optimized for environment-specific dynamics, and to tune their hyperparameters in local regions of the input space. Seminal work in \cite{higdon1998process} proposes a process convolution approach for space-time modeling. This model captures nonstationary structure by allowing the convolution kernel to vary across the input space. This approach can be extended to a class of nonstationary covariance functions, thereby allowing the use of a Gaussian process (GP) framework, as shown in \cite{paciorek2004nonstationary}. However,  since this model's hyperparameters are inferred using MCMC integration, its application has been limited to smaller datasets. To overcome this limitation, \cite{plagemann2008nonstationary} proposes to use the mean estimates of a second isotropic GP (defined over latent length scales) to parameterize the nonstationary covariances. Finally, \cite{garg2012AAAI} considers non-isotropic variation across different dimension of input space for the second GP as opposed to isotropic variation by \cite{plagemann2008nonstationary}. Issues with this line of approach include the nonconvexity of the hyperparameter optimization problem and the fact that selection of an appropriate nonstationary covariance function for the task at hand is a nontrivial design decision (as noted in \cite{singh2010modeling}). 

Apart from directly modeling the covariance function using additional latent GPs, there exist several other approaches for specifying nonstationary GP models. One approach maps the nonstationary spatial process into a latent space, in which the problem becomes approximately stationary \cite{schmidt2003bayesian}. Along similar lines, \cite{pfingsten2006nonstationary} extends the input space by adding latent variables, which allows the model to capture  nonstationarity in original space. Both these approaches require MCMC sampling for inference, and as such are subject to the limitations mentioned in the preceding paragraph. 

%The geostatistics community literature has many examples of the dynamical spatiotemporal modeling approach, where the focus is on finding good dynamical transition models on the linear combination of weights in a parameterized model \cite{cressie2011statistics,mardia1998kriged}. 
A geostatistics approach that finds dynamical transition models on the linear combination of weights of a parameterized model \cite{cressie2011statistics,mardia1998kriged} is advantageous when the spatial and temporal dynamics are hierarchically separated, leading to a convex learning problem. \rr{This approach has been utilized previously in MRI imaging \cite{Noh, Noh}}. As a result complex nonstationary kernels are often not necessary (although they can be accommodated). The approach presented in this paper aligns closely with this vein of work. %The main difference is that we view the problem from the more abstract viewpoint of constructing an observer in a reproducing kernel Hilbert space. 
A systems-theoretic study of this viewpoint enables the fundamental contributions of the paper, which are 1) allowing for inference on more general domains with a larger class of basis functions than those typically considered in the geostatistics community, and 2) quantifying the minimum number of measurements required to estimate the state of the system. 

\rr{Kalman filtering in the context of Gaussian processes and Kernel models has also been quite widely studied \cite{Carron, Hartikainen and sarka, Sarka and solin, stroud, miller}.  There is clearly a direct link between the Bayesian approach to inference taken in GPs and its natural extension to Kalman Filters. Our contributions here are in creating explicit connections between feedback observers and inference by deriving conditions of observability in the kernel space. This leads to explicit conditions on the number of sensors required and where to place them.}


Lastly, sensor placement optimization is also a well-studied area. Examples include, but are not limited to 1) geometric approaches, which seek to provide a covering of the operating space without making assumptions about the spatiotemporal dynamics \cite{egerstedt:bk:2010}, and 2) information-theoretic approaches, which place their focus on sensor placement optimizing strategies based on mutual information and information entropy for Gaussian process models \cite{Guestrin05_ICML}.
It should be noted that the contribution of the paper concerning sensor placement is to provide \emph{sufficient conditions} for monitoring rather than optimization of the placement locations, and therefore a comparison with these approaches is not considered in the experiments. 

